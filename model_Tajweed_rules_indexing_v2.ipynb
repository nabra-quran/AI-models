{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3jUJfDKh7ummaZvvH7V9A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1715613938546,"user_tz":-60,"elapsed":3899,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"3f57fceb-7a99-4610-8329-9dea95041258"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE","executionInfo":{"status":"ok","timestamp":1715613947945,"user_tz":-60,"elapsed":9404,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing_v2.csv')"],"metadata":{"id":"WtJVQemz7klg","executionInfo":{"status":"ok","timestamp":1715613962110,"user_tz":-60,"elapsed":14176,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/AI_models_v2'"],"metadata":{"id":"7A9PSizPHQos","executionInfo":{"status":"ok","timestamp":1715613962111,"user_tz":-60,"elapsed":11,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']"],"metadata":{"id":"KoKbTBQr7nY8","executionInfo":{"status":"ok","timestamp":1715613962112,"user_tz":-60,"elapsed":11,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc","executionInfo":{"status":"ok","timestamp":1715613962112,"user_tz":-60,"elapsed":10,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def max_sequence_length_X_Y(data, tajweed_rule):\n","  X_raw = data['mfcc'].astype(str).tolist()\n","  Y_raw = data[tajweed_rule].astype(str).tolist()\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","  max_sequence_length_Y = max(len(seq) for seq in Y)\n","  max_sequence_length_X = max(len(seq) for seq in X)\n","  return max_sequence_length_X, max_sequence_length_Y"],"metadata":{"id":"H950tSVTMxlL","executionInfo":{"status":"ok","timestamp":1715613962113,"user_tz":-60,"elapsed":10,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule, max_X, max_Y):\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = reciter_data['mfcc'].astype(str).tolist()\n","  Y_raw = reciter_data[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data (X)\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","\n","  # Pad sequences in Y and X to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y, padding='post', dtype='int32', value=-1)\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O","executionInfo":{"status":"ok","timestamp":1715613962113,"user_tz":-60,"elapsed":10,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","\n","  max_X, max_Y = max_sequence_length_X_Y(data, tajweed_rule)\n","\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule, max_X, max_Y)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule, max_X, max_Y)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule, max_X, max_Y)\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3)]:\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8","executionInfo":{"status":"ok","timestamp":1715613962113,"user_tz":-60,"elapsed":9,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["tajweed_rules = ['madd_6_Lazim', 'madd_246', 'madd_6', 'madd_2', 'Ikhfaa', 'Idgham', 'tafkhim', 'qalqala', 'imala']"],"metadata":{"id":"qpgV2OY8K09J","executionInfo":{"status":"ok","timestamp":1715613962114,"user_tz":-60,"elapsed":10,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1715615889591,"user_tz":-60,"elapsed":1927486,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"feab79d1-d464-4b2f-8226-bb5bed873613"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","21/21 [==============================] - 3s 100ms/step - loss: 124.1110 - accuracy: 0.1215 - val_loss: 0.8063 - val_accuracy: 0.0000e+00\n","Epoch 2/50\n","21/21 [==============================] - 2s 76ms/step - loss: 13.8679 - accuracy: 0.0140 - val_loss: 0.8112 - val_accuracy: 0.0000e+00\n","Epoch 3/50\n","21/21 [==============================] - 2s 76ms/step - loss: 16.2863 - accuracy: 0.0171 - val_loss: 0.7204 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","21/21 [==============================] - 2s 104ms/step - loss: 9.7023 - accuracy: 0.0156 - val_loss: 1.1689 - val_accuracy: 0.0000e+00\n","Epoch 5/50\n","21/21 [==============================] - 2s 104ms/step - loss: 10.4946 - accuracy: 0.0109 - val_loss: 0.6961 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","21/21 [==============================] - 2s 81ms/step - loss: 8.5568 - accuracy: 0.0109 - val_loss: 0.4305 - val_accuracy: 0.0000e+00\n","Epoch 7/50\n","21/21 [==============================] - 2s 73ms/step - loss: 8.5888 - accuracy: 0.0109 - val_loss: 0.6547 - val_accuracy: 0.0000e+00\n","Epoch 8/50\n","21/21 [==============================] - 2s 72ms/step - loss: 8.4535 - accuracy: 0.0093 - val_loss: 0.4155 - val_accuracy: 0.0000e+00\n","Epoch 9/50\n","21/21 [==============================] - 1s 68ms/step - loss: 8.3970 - accuracy: 0.0093 - val_loss: 0.3417 - val_accuracy: 0.0000e+00\n","Epoch 10/50\n","21/21 [==============================] - 2s 75ms/step - loss: 8.4087 - accuracy: 0.0109 - val_loss: 0.4019 - val_accuracy: 0.0000e+00\n","Epoch 11/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.3741 - accuracy: 0.0109 - val_loss: 0.3446 - val_accuracy: 0.0000e+00\n","Epoch 12/50\n","21/21 [==============================] - 2s 77ms/step - loss: 8.3022 - accuracy: 0.5467 - val_loss: 0.3733 - val_accuracy: 0.1528\n","Epoch 13/50\n","21/21 [==============================] - 3s 154ms/step - loss: 8.2708 - accuracy: 0.5701 - val_loss: 0.2970 - val_accuracy: 0.0694\n","Epoch 14/50\n","21/21 [==============================] - 3s 152ms/step - loss: 8.2540 - accuracy: 0.5639 - val_loss: 0.2779 - val_accuracy: 0.0833\n","Epoch 15/50\n","21/21 [==============================] - 4s 172ms/step - loss: 8.2322 - accuracy: 0.5639 - val_loss: 0.2762 - val_accuracy: 0.0972\n","Epoch 16/50\n","21/21 [==============================] - 2s 77ms/step - loss: 8.2154 - accuracy: 0.5623 - val_loss: 0.3058 - val_accuracy: 0.0417\n","Epoch 17/50\n","21/21 [==============================] - 2s 72ms/step - loss: 8.2010 - accuracy: 0.5607 - val_loss: 0.3438 - val_accuracy: 0.1528\n","Epoch 18/50\n","21/21 [==============================] - 2s 73ms/step - loss: 8.1886 - accuracy: 0.5623 - val_loss: 0.2221 - val_accuracy: 0.0556\n","Epoch 19/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.1737 - accuracy: 0.5623 - val_loss: 0.2619 - val_accuracy: 0.0972\n","Epoch 20/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.1612 - accuracy: 0.5623 - val_loss: 0.2373 - val_accuracy: 0.0972\n","Epoch 21/50\n","21/21 [==============================] - 2s 81ms/step - loss: 8.1544 - accuracy: 0.5623 - val_loss: 0.2381 - val_accuracy: 0.0833\n","Epoch 22/50\n","21/21 [==============================] - 2s 101ms/step - loss: 8.1445 - accuracy: 0.5623 - val_loss: 0.2139 - val_accuracy: 0.0694\n","Epoch 23/50\n","21/21 [==============================] - 2s 95ms/step - loss: 8.1382 - accuracy: 0.5623 - val_loss: 0.2127 - val_accuracy: 0.0556\n","Epoch 24/50\n","21/21 [==============================] - 2s 72ms/step - loss: 8.1314 - accuracy: 0.5623 - val_loss: 0.2124 - val_accuracy: 0.0694\n","Epoch 25/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.1255 - accuracy: 0.5623 - val_loss: 0.2119 - val_accuracy: 0.0694\n","Epoch 26/50\n","21/21 [==============================] - 2s 72ms/step - loss: 8.1195 - accuracy: 0.5623 - val_loss: 0.2053 - val_accuracy: 0.0694\n","Epoch 27/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.1137 - accuracy: 0.5623 - val_loss: 0.2082 - val_accuracy: 0.0694\n","Epoch 28/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.1092 - accuracy: 0.5623 - val_loss: 0.2067 - val_accuracy: 0.0833\n","Epoch 29/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.1053 - accuracy: 0.5623 - val_loss: 0.2073 - val_accuracy: 0.0972\n","Epoch 30/50\n","21/21 [==============================] - 2s 72ms/step - loss: 8.1016 - accuracy: 0.5623 - val_loss: 0.2001 - val_accuracy: 0.0694\n","Epoch 31/50\n","21/21 [==============================] - 2s 97ms/step - loss: 8.0972 - accuracy: 0.5623 - val_loss: 0.2107 - val_accuracy: 0.0833\n","Epoch 32/50\n","21/21 [==============================] - 2s 95ms/step - loss: 8.0949 - accuracy: 0.5623 - val_loss: 0.2146 - val_accuracy: 0.0694\n","Epoch 33/50\n","21/21 [==============================] - 2s 88ms/step - loss: 8.0992 - accuracy: 0.5623 - val_loss: 0.2261 - val_accuracy: 0.1528\n","Epoch 34/50\n","21/21 [==============================] - 1s 67ms/step - loss: 8.1033 - accuracy: 0.5639 - val_loss: 0.1994 - val_accuracy: 0.0972\n","Epoch 35/50\n","21/21 [==============================] - 1s 68ms/step - loss: 8.0926 - accuracy: 0.5639 - val_loss: 0.1983 - val_accuracy: 0.0694\n","Epoch 36/50\n","21/21 [==============================] - 1s 67ms/step - loss: 8.1007 - accuracy: 0.5623 - val_loss: 0.2865 - val_accuracy: 0.2500\n","Epoch 37/50\n","21/21 [==============================] - 1s 67ms/step - loss: 8.1006 - accuracy: 0.5623 - val_loss: 0.3925 - val_accuracy: 0.4028\n","Epoch 38/50\n","21/21 [==============================] - 1s 67ms/step - loss: 8.1204 - accuracy: 0.5639 - val_loss: 0.3046 - val_accuracy: 0.0417\n","Epoch 39/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.1304 - accuracy: 0.5888 - val_loss: 0.1874 - val_accuracy: 0.1528\n","Epoch 40/50\n","21/21 [==============================] - 2s 77ms/step - loss: 8.4096 - accuracy: 0.9673 - val_loss: 0.7487 - val_accuracy: 1.0000\n","Epoch 41/50\n","21/21 [==============================] - 2s 93ms/step - loss: 8.3830 - accuracy: 0.9922 - val_loss: 0.7319 - val_accuracy: 1.0000\n","Epoch 42/50\n","21/21 [==============================] - 2s 92ms/step - loss: 8.3737 - accuracy: 0.9922 - val_loss: 0.7138 - val_accuracy: 1.0000\n","Epoch 43/50\n","21/21 [==============================] - 2s 78ms/step - loss: 8.3836 - accuracy: 0.9922 - val_loss: 0.6971 - val_accuracy: 1.0000\n","Epoch 44/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.3891 - accuracy: 0.9922 - val_loss: 0.6815 - val_accuracy: 1.0000\n","Epoch 45/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.4435 - accuracy: 0.9922 - val_loss: 0.6642 - val_accuracy: 1.0000\n","Epoch 46/50\n","21/21 [==============================] - 1s 68ms/step - loss: 8.8871 - accuracy: 0.9922 - val_loss: 0.6491 - val_accuracy: 1.0000\n","Epoch 47/50\n","21/21 [==============================] - 1s 68ms/step - loss: 11.4838 - accuracy: 0.9891 - val_loss: 10.9970 - val_accuracy: 0.8194\n","Epoch 48/50\n","21/21 [==============================] - 1s 67ms/step - loss: 14.0297 - accuracy: 0.9735 - val_loss: 0.6180 - val_accuracy: 1.0000\n","Epoch 49/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.7146 - accuracy: 0.9922 - val_loss: 0.6002 - val_accuracy: 1.0000\n","Epoch 50/50\n","21/21 [==============================] - 2s 88ms/step - loss: 11.6755 - accuracy: 0.9907 - val_loss: 0.5868 - val_accuracy: 1.0000\n","6/6 [==============================] - 0s 18ms/step\n","6/6 [==============================] - 0s 15ms/step - loss: 1881.5801 - accuracy: 0.9833\n","Test Loss: 1881.5801, Test accuracy : 0.9833\n","Epoch 1/50\n","21/21 [==============================] - 3s 112ms/step - loss: 198.7859 - accuracy: 0.4455 - val_loss: 95.4350 - val_accuracy: 0.9306\n","Epoch 2/50\n","21/21 [==============================] - 2s 75ms/step - loss: 91.8923 - accuracy: 0.7352 - val_loss: 92.4135 - val_accuracy: 0.8611\n","Epoch 3/50\n","21/21 [==============================] - 1s 70ms/step - loss: 73.7099 - accuracy: 0.8474 - val_loss: 103.7057 - val_accuracy: 0.8333\n","Epoch 4/50\n","21/21 [==============================] - 1s 68ms/step - loss: 62.0718 - accuracy: 0.8069 - val_loss: 105.1621 - val_accuracy: 0.3333\n","Epoch 5/50\n","21/21 [==============================] - 1s 70ms/step - loss: 55.0662 - accuracy: 0.8427 - val_loss: 86.9238 - val_accuracy: 0.6944\n","Epoch 6/50\n","21/21 [==============================] - 1s 71ms/step - loss: 51.8151 - accuracy: 0.8271 - val_loss: 78.6999 - val_accuracy: 0.6528\n","Epoch 7/50\n","21/21 [==============================] - 1s 71ms/step - loss: 50.0186 - accuracy: 0.8193 - val_loss: 85.7538 - val_accuracy: 0.6250\n","Epoch 8/50\n","21/21 [==============================] - 1s 71ms/step - loss: 38.3528 - accuracy: 0.8146 - val_loss: 86.1711 - val_accuracy: 0.6111\n","Epoch 9/50\n","21/21 [==============================] - 2s 93ms/step - loss: 33.9746 - accuracy: 0.8022 - val_loss: 91.9992 - val_accuracy: 0.8889\n","Epoch 10/50\n","21/21 [==============================] - 2s 92ms/step - loss: 29.0618 - accuracy: 0.8271 - val_loss: 85.5805 - val_accuracy: 0.7917\n","Epoch 11/50\n","21/21 [==============================] - 2s 93ms/step - loss: 26.3327 - accuracy: 0.8349 - val_loss: 85.2250 - val_accuracy: 0.7500\n","Epoch 12/50\n","21/21 [==============================] - 1s 69ms/step - loss: 24.6685 - accuracy: 0.8396 - val_loss: 82.1417 - val_accuracy: 0.6389\n","Epoch 13/50\n","21/21 [==============================] - 1s 69ms/step - loss: 21.4118 - accuracy: 0.7991 - val_loss: 85.7135 - val_accuracy: 0.6528\n","Epoch 14/50\n","21/21 [==============================] - 1s 70ms/step - loss: 26.5346 - accuracy: 0.8178 - val_loss: 89.2065 - val_accuracy: 0.5139\n","Epoch 15/50\n","21/21 [==============================] - 1s 68ms/step - loss: 20.3335 - accuracy: 0.8146 - val_loss: 82.3060 - val_accuracy: 0.6806\n","Epoch 16/50\n","21/21 [==============================] - 1s 69ms/step - loss: 18.9443 - accuracy: 0.8084 - val_loss: 85.9179 - val_accuracy: 0.7639\n","Epoch 17/50\n","21/21 [==============================] - 1s 71ms/step - loss: 20.0134 - accuracy: 0.8240 - val_loss: 89.7951 - val_accuracy: 0.5972\n","Epoch 18/50\n","21/21 [==============================] - 2s 76ms/step - loss: 19.1390 - accuracy: 0.8022 - val_loss: 110.2424 - val_accuracy: 0.8333\n","Epoch 19/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.2125 - accuracy: 0.8396 - val_loss: 95.3733 - val_accuracy: 0.4722\n","Epoch 20/50\n","21/21 [==============================] - 2s 94ms/step - loss: 16.0107 - accuracy: 0.7960 - val_loss: 88.4099 - val_accuracy: 0.6528\n","Epoch 21/50\n","21/21 [==============================] - 2s 76ms/step - loss: 14.5553 - accuracy: 0.8053 - val_loss: 86.0203 - val_accuracy: 0.5000\n","Epoch 22/50\n","21/21 [==============================] - 1s 68ms/step - loss: 14.3175 - accuracy: 0.8084 - val_loss: 90.8561 - val_accuracy: 0.5972\n","Epoch 23/50\n","21/21 [==============================] - 1s 69ms/step - loss: 13.0575 - accuracy: 0.7913 - val_loss: 90.9475 - val_accuracy: 0.7778\n","Epoch 24/50\n","21/21 [==============================] - 1s 68ms/step - loss: 12.7956 - accuracy: 0.7944 - val_loss: 92.4029 - val_accuracy: 0.6806\n","Epoch 25/50\n","21/21 [==============================] - 1s 71ms/step - loss: 12.2468 - accuracy: 0.8084 - val_loss: 88.6393 - val_accuracy: 0.5417\n","Epoch 26/50\n","21/21 [==============================] - 1s 69ms/step - loss: 12.9732 - accuracy: 0.8255 - val_loss: 94.9240 - val_accuracy: 0.5694\n","Epoch 27/50\n","21/21 [==============================] - 1s 70ms/step - loss: 11.1178 - accuracy: 0.7741 - val_loss: 83.8937 - val_accuracy: 0.6667\n","Epoch 28/50\n","21/21 [==============================] - 2s 92ms/step - loss: 11.3466 - accuracy: 0.7975 - val_loss: 96.7153 - val_accuracy: 0.5556\n","Epoch 29/50\n","21/21 [==============================] - 2s 95ms/step - loss: 10.2816 - accuracy: 0.7928 - val_loss: 88.4279 - val_accuracy: 0.7361\n","Epoch 30/50\n","21/21 [==============================] - 2s 83ms/step - loss: 9.4182 - accuracy: 0.8084 - val_loss: 92.0229 - val_accuracy: 0.5000\n","Epoch 31/50\n","21/21 [==============================] - 1s 71ms/step - loss: 9.6535 - accuracy: 0.7928 - val_loss: 87.7760 - val_accuracy: 0.5972\n","Epoch 32/50\n","21/21 [==============================] - 1s 68ms/step - loss: 8.9243 - accuracy: 0.7866 - val_loss: 89.0942 - val_accuracy: 0.6250\n","Epoch 33/50\n","21/21 [==============================] - 1s 69ms/step - loss: 8.9193 - accuracy: 0.8069 - val_loss: 90.3934 - val_accuracy: 0.6806\n","Epoch 34/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.6278 - accuracy: 0.7960 - val_loss: 95.0217 - val_accuracy: 0.7361\n","Epoch 35/50\n","21/21 [==============================] - 1s 71ms/step - loss: 9.4225 - accuracy: 0.7819 - val_loss: 90.1854 - val_accuracy: 0.7083\n","Epoch 36/50\n","21/21 [==============================] - 1s 70ms/step - loss: 8.4699 - accuracy: 0.7850 - val_loss: 90.9309 - val_accuracy: 0.7361\n","Epoch 37/50\n","21/21 [==============================] - 2s 87ms/step - loss: 25.3952 - accuracy: 0.7586 - val_loss: 90.9689 - val_accuracy: 0.6806\n","Epoch 38/50\n","21/21 [==============================] - 2s 93ms/step - loss: 11.9345 - accuracy: 0.8131 - val_loss: 105.5223 - val_accuracy: 0.3194\n","Epoch 39/50\n","21/21 [==============================] - 2s 93ms/step - loss: 30.4061 - accuracy: 0.8240 - val_loss: 90.9917 - val_accuracy: 0.7917\n","Epoch 40/50\n","21/21 [==============================] - 2s 77ms/step - loss: 16.1850 - accuracy: 0.7975 - val_loss: 96.3574 - val_accuracy: 0.5972\n","Epoch 41/50\n","21/21 [==============================] - 1s 70ms/step - loss: 13.1730 - accuracy: 0.8006 - val_loss: 91.7478 - val_accuracy: 0.6528\n","Epoch 42/50\n","21/21 [==============================] - 1s 70ms/step - loss: 13.0420 - accuracy: 0.8131 - val_loss: 99.1623 - val_accuracy: 0.3750\n","Epoch 43/50\n","21/21 [==============================] - 1s 71ms/step - loss: 16.8632 - accuracy: 0.8131 - val_loss: 113.1664 - val_accuracy: 0.9167\n","Epoch 44/50\n","21/21 [==============================] - 1s 69ms/step - loss: 13.2407 - accuracy: 0.8318 - val_loss: 102.0761 - val_accuracy: 0.4861\n","Epoch 45/50\n","21/21 [==============================] - 1s 70ms/step - loss: 11.9242 - accuracy: 0.8022 - val_loss: 95.7113 - val_accuracy: 0.6250\n","Epoch 46/50\n","21/21 [==============================] - 1s 70ms/step - loss: 10.8620 - accuracy: 0.8318 - val_loss: 92.1671 - val_accuracy: 0.6250\n","Epoch 47/50\n","21/21 [==============================] - 2s 94ms/step - loss: 10.4272 - accuracy: 0.8037 - val_loss: 95.8452 - val_accuracy: 0.7639\n","Epoch 48/50\n","21/21 [==============================] - 2s 93ms/step - loss: 9.9467 - accuracy: 0.7913 - val_loss: 93.0917 - val_accuracy: 0.5833\n","Epoch 49/50\n","21/21 [==============================] - 2s 92ms/step - loss: 9.9945 - accuracy: 0.7960 - val_loss: 94.1912 - val_accuracy: 0.6806\n","Epoch 50/50\n","21/21 [==============================] - 1s 69ms/step - loss: 9.4488 - accuracy: 0.7975 - val_loss: 93.4099 - val_accuracy: 0.7500\n","6/6 [==============================] - 0s 14ms/step\n","6/6 [==============================] - 0s 15ms/step - loss: 1740.2919 - accuracy: 0.9833\n","Test Loss: 1740.2919, Test accuracy : 0.9833\n","Epoch 1/50\n","21/21 [==============================] - 3s 107ms/step - loss: 63.4462 - accuracy: 0.5779 - val_loss: 15.6796 - val_accuracy: 0.4028\n","Epoch 2/50\n","21/21 [==============================] - 2s 95ms/step - loss: 46.2058 - accuracy: 0.7461 - val_loss: 16.9501 - val_accuracy: 0.6667\n","Epoch 3/50\n","21/21 [==============================] - 2s 89ms/step - loss: 44.2694 - accuracy: 0.8146 - val_loss: 15.2637 - val_accuracy: 0.7778\n","Epoch 4/50\n","21/21 [==============================] - 1s 70ms/step - loss: 42.2690 - accuracy: 0.7991 - val_loss: 14.9121 - val_accuracy: 0.7778\n","Epoch 5/50\n","21/21 [==============================] - 1s 68ms/step - loss: 40.7672 - accuracy: 0.8146 - val_loss: 15.2225 - val_accuracy: 0.7361\n","Epoch 6/50\n","21/21 [==============================] - 1s 70ms/step - loss: 39.1828 - accuracy: 0.8271 - val_loss: 19.8066 - val_accuracy: 0.6250\n","Epoch 7/50\n","21/21 [==============================] - 1s 71ms/step - loss: 37.9963 - accuracy: 0.8100 - val_loss: 19.7082 - val_accuracy: 0.6944\n","Epoch 8/50\n","21/21 [==============================] - 1s 69ms/step - loss: 36.2663 - accuracy: 0.8162 - val_loss: 15.5619 - val_accuracy: 0.7639\n","Epoch 9/50\n","21/21 [==============================] - 1s 69ms/step - loss: 34.4097 - accuracy: 0.8349 - val_loss: 16.9700 - val_accuracy: 0.7361\n","Epoch 10/50\n","21/21 [==============================] - 2s 76ms/step - loss: 32.8356 - accuracy: 0.8536 - val_loss: 14.6323 - val_accuracy: 0.8056\n","Epoch 11/50\n","21/21 [==============================] - 2s 96ms/step - loss: 31.2421 - accuracy: 0.8349 - val_loss: 14.5842 - val_accuracy: 0.7917\n","Epoch 12/50\n","21/21 [==============================] - 2s 92ms/step - loss: 30.2537 - accuracy: 0.8660 - val_loss: 21.5104 - val_accuracy: 0.7083\n","Epoch 13/50\n","21/21 [==============================] - 2s 84ms/step - loss: 29.1020 - accuracy: 0.8271 - val_loss: 15.5118 - val_accuracy: 0.7778\n","Epoch 14/50\n","21/21 [==============================] - 1s 69ms/step - loss: 28.1610 - accuracy: 0.8474 - val_loss: 13.8083 - val_accuracy: 0.7917\n","Epoch 15/50\n","21/21 [==============================] - 1s 69ms/step - loss: 26.3842 - accuracy: 0.8520 - val_loss: 14.0793 - val_accuracy: 0.7778\n","Epoch 16/50\n","21/21 [==============================] - 1s 69ms/step - loss: 25.2650 - accuracy: 0.8598 - val_loss: 16.0458 - val_accuracy: 0.7361\n","Epoch 17/50\n","21/21 [==============================] - 1s 69ms/step - loss: 23.5220 - accuracy: 0.8754 - val_loss: 16.4747 - val_accuracy: 0.7500\n","Epoch 18/50\n","21/21 [==============================] - 1s 69ms/step - loss: 22.2893 - accuracy: 0.8785 - val_loss: 18.2948 - val_accuracy: 0.7222\n","Epoch 19/50\n","21/21 [==============================] - 1s 70ms/step - loss: 22.0435 - accuracy: 0.8271 - val_loss: 17.4752 - val_accuracy: 0.7222\n","Epoch 20/50\n","21/21 [==============================] - 2s 84ms/step - loss: 20.5379 - accuracy: 0.8629 - val_loss: 21.1988 - val_accuracy: 0.7361\n","Epoch 21/50\n","21/21 [==============================] - 2s 95ms/step - loss: 20.0875 - accuracy: 0.8474 - val_loss: 13.6869 - val_accuracy: 0.8056\n","Epoch 22/50\n","21/21 [==============================] - 2s 94ms/step - loss: 18.4894 - accuracy: 0.8645 - val_loss: 15.2743 - val_accuracy: 0.7222\n","Epoch 23/50\n","21/21 [==============================] - 2s 72ms/step - loss: 17.3699 - accuracy: 0.8801 - val_loss: 17.5544 - val_accuracy: 0.7500\n","Epoch 24/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.9073 - accuracy: 0.8411 - val_loss: 13.5980 - val_accuracy: 0.8333\n","Epoch 25/50\n","21/21 [==============================] - 1s 71ms/step - loss: 20.7442 - accuracy: 0.8349 - val_loss: 13.1490 - val_accuracy: 0.8194\n","Epoch 26/50\n","21/21 [==============================] - 1s 69ms/step - loss: 17.2314 - accuracy: 0.8645 - val_loss: 15.2224 - val_accuracy: 0.7222\n","Epoch 27/50\n","21/21 [==============================] - 1s 71ms/step - loss: 15.8019 - accuracy: 0.8801 - val_loss: 21.2527 - val_accuracy: 0.7083\n","Epoch 28/50\n","21/21 [==============================] - 2s 71ms/step - loss: 15.0417 - accuracy: 0.8988 - val_loss: 14.8473 - val_accuracy: 0.7639\n","Epoch 29/50\n","21/21 [==============================] - 2s 72ms/step - loss: 14.6364 - accuracy: 0.9221 - val_loss: 13.7270 - val_accuracy: 0.7083\n","Epoch 30/50\n","21/21 [==============================] - 2s 94ms/step - loss: 14.6084 - accuracy: 0.9128 - val_loss: 16.6142 - val_accuracy: 0.7500\n","Epoch 31/50\n","21/21 [==============================] - 2s 92ms/step - loss: 14.2068 - accuracy: 0.9252 - val_loss: 15.2217 - val_accuracy: 0.7222\n","Epoch 32/50\n","21/21 [==============================] - 2s 89ms/step - loss: 14.1032 - accuracy: 0.9252 - val_loss: 15.9196 - val_accuracy: 0.7222\n","Epoch 33/50\n","21/21 [==============================] - 1s 68ms/step - loss: 14.1950 - accuracy: 0.9237 - val_loss: 16.9863 - val_accuracy: 0.7222\n","Epoch 34/50\n","21/21 [==============================] - 1s 69ms/step - loss: 14.8094 - accuracy: 0.9159 - val_loss: 15.1517 - val_accuracy: 0.7222\n","Epoch 35/50\n","21/21 [==============================] - 1s 69ms/step - loss: 14.6893 - accuracy: 0.9252 - val_loss: 15.8024 - val_accuracy: 0.7500\n","Epoch 36/50\n","21/21 [==============================] - 1s 70ms/step - loss: 24.7805 - accuracy: 0.9003 - val_loss: 16.5621 - val_accuracy: 0.7361\n","Epoch 37/50\n","21/21 [==============================] - 1s 71ms/step - loss: 25.0438 - accuracy: 0.8972 - val_loss: 15.4204 - val_accuracy: 0.7500\n","Epoch 38/50\n","21/21 [==============================] - 1s 71ms/step - loss: 25.0024 - accuracy: 0.8956 - val_loss: 14.9873 - val_accuracy: 0.7361\n","Epoch 39/50\n","21/21 [==============================] - 2s 80ms/step - loss: 24.9299 - accuracy: 0.8956 - val_loss: 16.0533 - val_accuracy: 0.7500\n","Epoch 40/50\n","21/21 [==============================] - 2s 94ms/step - loss: 24.8844 - accuracy: 0.8972 - val_loss: 15.7390 - val_accuracy: 0.7361\n","Epoch 41/50\n","21/21 [==============================] - 2s 111ms/step - loss: 24.8544 - accuracy: 0.8956 - val_loss: 15.2859 - val_accuracy: 0.7361\n","Epoch 42/50\n","21/21 [==============================] - 2s 110ms/step - loss: 24.8245 - accuracy: 0.8956 - val_loss: 15.2213 - val_accuracy: 0.7222\n","Epoch 43/50\n","21/21 [==============================] - 2s 95ms/step - loss: 24.7899 - accuracy: 0.8956 - val_loss: 15.1985 - val_accuracy: 0.7222\n","Epoch 44/50\n","21/21 [==============================] - 2s 77ms/step - loss: 24.8009 - accuracy: 0.8894 - val_loss: 14.6549 - val_accuracy: 0.7222\n","Epoch 45/50\n","21/21 [==============================] - 1s 71ms/step - loss: 24.7638 - accuracy: 0.8941 - val_loss: 15.1834 - val_accuracy: 0.7083\n","Epoch 46/50\n","21/21 [==============================] - 1s 71ms/step - loss: 24.7467 - accuracy: 0.8925 - val_loss: 14.7429 - val_accuracy: 0.7222\n","Epoch 47/50\n","21/21 [==============================] - 1s 71ms/step - loss: 24.7006 - accuracy: 0.8847 - val_loss: 15.3566 - val_accuracy: 0.7222\n","Epoch 48/50\n","21/21 [==============================] - 1s 71ms/step - loss: 24.7047 - accuracy: 0.8754 - val_loss: 15.4251 - val_accuracy: 0.7222\n","Epoch 49/50\n","21/21 [==============================] - 2s 95ms/step - loss: 24.6721 - accuracy: 0.8738 - val_loss: 15.1283 - val_accuracy: 0.7083\n","Epoch 50/50\n","21/21 [==============================] - 2s 94ms/step - loss: 24.6618 - accuracy: 0.8738 - val_loss: 15.0813 - val_accuracy: 0.7083\n","6/6 [==============================] - 0s 15ms/step\n","6/6 [==============================] - 0s 15ms/step - loss: 69.4452 - accuracy: 0.8778\n","Test Loss: 69.4452, Test accuracy : 0.8778\n","Epoch 1/50\n","21/21 [==============================] - 2s 82ms/step - loss: 98.0492 - accuracy: 0.3100 - val_loss: 48.4769 - val_accuracy: 0.0417\n","Epoch 2/50\n","21/21 [==============================] - 2s 72ms/step - loss: 50.5968 - accuracy: 0.5280 - val_loss: 46.6704 - val_accuracy: 0.0972\n","Epoch 3/50\n","21/21 [==============================] - 1s 71ms/step - loss: 44.3583 - accuracy: 0.6900 - val_loss: 46.3476 - val_accuracy: 0.1667\n","Epoch 4/50\n","21/21 [==============================] - 1s 71ms/step - loss: 40.2770 - accuracy: 0.7072 - val_loss: 43.2265 - val_accuracy: 0.3611\n","Epoch 5/50\n","21/21 [==============================] - 2s 80ms/step - loss: 36.4821 - accuracy: 0.7290 - val_loss: 41.5470 - val_accuracy: 0.3611\n","Epoch 6/50\n","21/21 [==============================] - 2s 94ms/step - loss: 33.7454 - accuracy: 0.7165 - val_loss: 43.6725 - val_accuracy: 0.3333\n","Epoch 7/50\n","21/21 [==============================] - 2s 91ms/step - loss: 43.1601 - accuracy: 0.8100 - val_loss: 46.8031 - val_accuracy: 0.9444\n","Epoch 8/50\n","21/21 [==============================] - 2s 76ms/step - loss: 34.6687 - accuracy: 0.7586 - val_loss: 46.1398 - val_accuracy: 0.5694\n","Epoch 9/50\n","21/21 [==============================] - 1s 70ms/step - loss: 30.1392 - accuracy: 0.8287 - val_loss: 43.7617 - val_accuracy: 0.4028\n","Epoch 10/50\n","21/21 [==============================] - 1s 70ms/step - loss: 27.5506 - accuracy: 0.8131 - val_loss: 41.9887 - val_accuracy: 0.5139\n","Epoch 11/50\n","21/21 [==============================] - 1s 71ms/step - loss: 25.9175 - accuracy: 0.8442 - val_loss: 41.3463 - val_accuracy: 0.8472\n","Epoch 12/50\n","21/21 [==============================] - 1s 71ms/step - loss: 24.4316 - accuracy: 0.9206 - val_loss: 42.5649 - val_accuracy: 0.9167\n","Epoch 13/50\n","21/21 [==============================] - 1s 70ms/step - loss: 24.9590 - accuracy: 0.9252 - val_loss: 41.6243 - val_accuracy: 0.9583\n","Epoch 14/50\n","21/21 [==============================] - 1s 70ms/step - loss: 23.5765 - accuracy: 0.9299 - val_loss: 40.5104 - val_accuracy: 0.9444\n","Epoch 15/50\n","21/21 [==============================] - 2s 91ms/step - loss: 21.9670 - accuracy: 0.9486 - val_loss: 39.2198 - val_accuracy: 0.9583\n","Epoch 16/50\n","21/21 [==============================] - 2s 91ms/step - loss: 20.6988 - accuracy: 0.9548 - val_loss: 40.3158 - val_accuracy: 0.9306\n","Epoch 17/50\n","21/21 [==============================] - 2s 87ms/step - loss: 19.7340 - accuracy: 0.9377 - val_loss: 39.2527 - val_accuracy: 0.9444\n","Epoch 18/50\n","21/21 [==============================] - 1s 69ms/step - loss: 19.0950 - accuracy: 0.9424 - val_loss: 40.6420 - val_accuracy: 1.0000\n","Epoch 19/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.6550 - accuracy: 0.9424 - val_loss: 39.4530 - val_accuracy: 0.9444\n","Epoch 20/50\n","21/21 [==============================] - 1s 71ms/step - loss: 17.6361 - accuracy: 0.9424 - val_loss: 37.8945 - val_accuracy: 0.9861\n","Epoch 21/50\n","21/21 [==============================] - 2s 72ms/step - loss: 17.0231 - accuracy: 0.9424 - val_loss: 37.6383 - val_accuracy: 0.9861\n","Epoch 22/50\n","21/21 [==============================] - 1s 72ms/step - loss: 16.4961 - accuracy: 0.9424 - val_loss: 36.6827 - val_accuracy: 1.0000\n","Epoch 23/50\n","21/21 [==============================] - 1s 70ms/step - loss: 16.3552 - accuracy: 0.9439 - val_loss: 37.8760 - val_accuracy: 0.9583\n","Epoch 24/50\n","21/21 [==============================] - 2s 86ms/step - loss: 16.1288 - accuracy: 0.9439 - val_loss: 35.8128 - val_accuracy: 0.9861\n","Epoch 25/50\n","21/21 [==============================] - 2s 92ms/step - loss: 15.5320 - accuracy: 0.9486 - val_loss: 36.9164 - val_accuracy: 0.9583\n","Epoch 26/50\n","21/21 [==============================] - 2s 94ms/step - loss: 14.8379 - accuracy: 0.9517 - val_loss: 35.3108 - val_accuracy: 1.0000\n","Epoch 27/50\n","21/21 [==============================] - 2s 76ms/step - loss: 14.4757 - accuracy: 0.9486 - val_loss: 35.9342 - val_accuracy: 1.0000\n","Epoch 28/50\n","21/21 [==============================] - 1s 70ms/step - loss: 14.7017 - accuracy: 0.9517 - val_loss: 41.0732 - val_accuracy: 0.9861\n","Epoch 29/50\n","21/21 [==============================] - 1s 70ms/step - loss: 15.8488 - accuracy: 0.9470 - val_loss: 51.8031 - val_accuracy: 0.8750\n","Epoch 30/50\n","21/21 [==============================] - 1s 71ms/step - loss: 21.0068 - accuracy: 0.9486 - val_loss: 37.3060 - val_accuracy: 0.9861\n","Epoch 31/50\n","21/21 [==============================] - 1s 72ms/step - loss: 19.3085 - accuracy: 0.9642 - val_loss: 38.3393 - val_accuracy: 0.9861\n","Epoch 32/50\n","21/21 [==============================] - 1s 69ms/step - loss: 14.7645 - accuracy: 0.9502 - val_loss: 36.4918 - val_accuracy: 0.9861\n","Epoch 33/50\n","21/21 [==============================] - 2s 73ms/step - loss: 14.4431 - accuracy: 0.9673 - val_loss: 37.0831 - val_accuracy: 0.9861\n","Epoch 34/50\n","21/21 [==============================] - 2s 92ms/step - loss: 13.9502 - accuracy: 0.9642 - val_loss: 37.0211 - val_accuracy: 0.9861\n","Epoch 35/50\n","21/21 [==============================] - 2s 92ms/step - loss: 13.7812 - accuracy: 0.9673 - val_loss: 37.1597 - val_accuracy: 0.9861\n","Epoch 36/50\n","21/21 [==============================] - 2s 93ms/step - loss: 13.6674 - accuracy: 0.9611 - val_loss: 37.0448 - val_accuracy: 0.9861\n","Epoch 37/50\n","21/21 [==============================] - 1s 70ms/step - loss: 13.5342 - accuracy: 0.9673 - val_loss: 37.3772 - val_accuracy: 0.9861\n","Epoch 38/50\n","21/21 [==============================] - 2s 72ms/step - loss: 13.4994 - accuracy: 0.9673 - val_loss: 36.9795 - val_accuracy: 0.9861\n","Epoch 39/50\n","21/21 [==============================] - 1s 71ms/step - loss: 13.5281 - accuracy: 0.9657 - val_loss: 36.7643 - val_accuracy: 0.9861\n","Epoch 40/50\n","21/21 [==============================] - 1s 70ms/step - loss: 13.5326 - accuracy: 0.9673 - val_loss: 36.1598 - val_accuracy: 0.9861\n","Epoch 41/50\n","21/21 [==============================] - 1s 68ms/step - loss: 13.3753 - accuracy: 0.9704 - val_loss: 36.6843 - val_accuracy: 0.9861\n","Epoch 42/50\n","21/21 [==============================] - 1s 72ms/step - loss: 13.6227 - accuracy: 0.9642 - val_loss: 37.0672 - val_accuracy: 0.9861\n","Epoch 43/50\n","21/21 [==============================] - 2s 78ms/step - loss: 13.8810 - accuracy: 0.9704 - val_loss: 37.0168 - val_accuracy: 0.9861\n","Epoch 44/50\n","21/21 [==============================] - 2s 91ms/step - loss: 15.1027 - accuracy: 0.9673 - val_loss: 36.3665 - val_accuracy: 0.9861\n","Epoch 45/50\n","21/21 [==============================] - 2s 96ms/step - loss: 16.5800 - accuracy: 0.9673 - val_loss: 37.0680 - val_accuracy: 0.9861\n","Epoch 46/50\n","21/21 [==============================] - 2s 74ms/step - loss: 15.6141 - accuracy: 0.9642 - val_loss: 36.7144 - val_accuracy: 0.9861\n","Epoch 47/50\n","21/21 [==============================] - 1s 69ms/step - loss: 14.4624 - accuracy: 0.9642 - val_loss: 37.1918 - val_accuracy: 0.9861\n","Epoch 48/50\n","21/21 [==============================] - 1s 70ms/step - loss: 14.0555 - accuracy: 0.9642 - val_loss: 36.8820 - val_accuracy: 0.9861\n","Epoch 49/50\n","21/21 [==============================] - 2s 73ms/step - loss: 14.4721 - accuracy: 0.9642 - val_loss: 37.5082 - val_accuracy: 0.9861\n","Epoch 50/50\n","21/21 [==============================] - 1s 70ms/step - loss: 15.4900 - accuracy: 0.9688 - val_loss: 36.7771 - val_accuracy: 0.9861\n","6/6 [==============================] - 0s 14ms/step\n","6/6 [==============================] - 0s 14ms/step - loss: 153.3978 - accuracy: 1.0000\n","Test Loss: 153.3978, Test accuracy : 1.0000\n","Epoch 1/50\n","21/21 [==============================] - 2s 83ms/step - loss: 93.0896 - accuracy: 0.2165 - val_loss: 58.0150 - val_accuracy: 0.4861\n","Epoch 2/50\n","21/21 [==============================] - 2s 79ms/step - loss: 55.8514 - accuracy: 0.1963 - val_loss: 61.7440 - val_accuracy: 0.2917\n","Epoch 3/50\n","21/21 [==============================] - 2s 95ms/step - loss: 51.5039 - accuracy: 0.2072 - val_loss: 52.5537 - val_accuracy: 0.3472\n","Epoch 4/50\n","21/21 [==============================] - 2s 94ms/step - loss: 45.5791 - accuracy: 0.2040 - val_loss: 55.9273 - val_accuracy: 0.2639\n","Epoch 5/50\n","21/21 [==============================] - 2s 78ms/step - loss: 44.0325 - accuracy: 0.1667 - val_loss: 54.5729 - val_accuracy: 0.3194\n","Epoch 6/50\n","21/21 [==============================] - 1s 69ms/step - loss: 37.8043 - accuracy: 0.1900 - val_loss: 60.1435 - val_accuracy: 0.2500\n","Epoch 7/50\n","21/21 [==============================] - 1s 71ms/step - loss: 34.7489 - accuracy: 0.2118 - val_loss: 55.3795 - val_accuracy: 0.2222\n","Epoch 8/50\n","21/21 [==============================] - 1s 71ms/step - loss: 33.5515 - accuracy: 0.2648 - val_loss: 54.5063 - val_accuracy: 0.3056\n","Epoch 9/50\n","21/21 [==============================] - 2s 72ms/step - loss: 29.3400 - accuracy: 0.3349 - val_loss: 50.8588 - val_accuracy: 0.4028\n","Epoch 10/50\n","21/21 [==============================] - 1s 70ms/step - loss: 29.5358 - accuracy: 0.3224 - val_loss: 49.0524 - val_accuracy: 0.3472\n","Epoch 11/50\n","21/21 [==============================] - 1s 71ms/step - loss: 26.9190 - accuracy: 0.5436 - val_loss: 52.4165 - val_accuracy: 0.5694\n","Epoch 12/50\n","21/21 [==============================] - 2s 96ms/step - loss: 24.5923 - accuracy: 0.6386 - val_loss: 48.8320 - val_accuracy: 0.5972\n","Epoch 13/50\n","21/21 [==============================] - 2s 95ms/step - loss: 24.0979 - accuracy: 0.6386 - val_loss: 48.3552 - val_accuracy: 0.6111\n","Epoch 14/50\n","21/21 [==============================] - 2s 88ms/step - loss: 23.2738 - accuracy: 0.6604 - val_loss: 49.6073 - val_accuracy: 0.5833\n","Epoch 15/50\n","21/21 [==============================] - 1s 71ms/step - loss: 23.1898 - accuracy: 0.6667 - val_loss: 47.9038 - val_accuracy: 0.6111\n","Epoch 16/50\n","21/21 [==============================] - 1s 72ms/step - loss: 21.6434 - accuracy: 0.6495 - val_loss: 49.7682 - val_accuracy: 0.6250\n","Epoch 17/50\n","21/21 [==============================] - 2s 80ms/step - loss: 20.9980 - accuracy: 0.6604 - val_loss: 48.0173 - val_accuracy: 0.6250\n","Epoch 18/50\n","21/21 [==============================] - 2s 90ms/step - loss: 20.2155 - accuracy: 0.6807 - val_loss: 47.6418 - val_accuracy: 0.6111\n","Epoch 19/50\n","21/21 [==============================] - 1s 71ms/step - loss: 19.7515 - accuracy: 0.6667 - val_loss: 49.5771 - val_accuracy: 0.5972\n","Epoch 20/50\n","21/21 [==============================] - 2s 72ms/step - loss: 19.4039 - accuracy: 0.6916 - val_loss: 47.2894 - val_accuracy: 0.6111\n","Epoch 21/50\n","21/21 [==============================] - 2s 92ms/step - loss: 19.1716 - accuracy: 0.6822 - val_loss: 48.8138 - val_accuracy: 0.6111\n","Epoch 22/50\n","21/21 [==============================] - 2s 94ms/step - loss: 19.2910 - accuracy: 0.6854 - val_loss: 48.5303 - val_accuracy: 0.5417\n","Epoch 23/50\n","21/21 [==============================] - 2s 81ms/step - loss: 19.1360 - accuracy: 0.6838 - val_loss: 48.7404 - val_accuracy: 0.6111\n","Epoch 24/50\n","21/21 [==============================] - 1s 71ms/step - loss: 18.9559 - accuracy: 0.6838 - val_loss: 48.0982 - val_accuracy: 0.6111\n","Epoch 25/50\n","21/21 [==============================] - 1s 71ms/step - loss: 18.7608 - accuracy: 0.6745 - val_loss: 47.9569 - val_accuracy: 0.6111\n","Epoch 26/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.7072 - accuracy: 0.6760 - val_loss: 49.6962 - val_accuracy: 0.5972\n","Epoch 27/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.5107 - accuracy: 0.6807 - val_loss: 51.2399 - val_accuracy: 0.6250\n","Epoch 28/50\n","21/21 [==============================] - 1s 70ms/step - loss: 19.8465 - accuracy: 0.6651 - val_loss: 51.7332 - val_accuracy: 0.6250\n","Epoch 29/50\n","21/21 [==============================] - 2s 72ms/step - loss: 18.7975 - accuracy: 0.6869 - val_loss: 51.3645 - val_accuracy: 0.6389\n","Epoch 30/50\n","21/21 [==============================] - 2s 89ms/step - loss: 18.4836 - accuracy: 0.6745 - val_loss: 48.3746 - val_accuracy: 0.6250\n","Epoch 31/50\n","21/21 [==============================] - 2s 93ms/step - loss: 18.5090 - accuracy: 0.6713 - val_loss: 50.0424 - val_accuracy: 0.5833\n","Epoch 32/50\n","21/21 [==============================] - 2s 93ms/step - loss: 18.4865 - accuracy: 0.6713 - val_loss: 49.0016 - val_accuracy: 0.6111\n","Epoch 33/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.3920 - accuracy: 0.6698 - val_loss: 48.2946 - val_accuracy: 0.5972\n","Epoch 34/50\n","21/21 [==============================] - 1s 71ms/step - loss: 18.3835 - accuracy: 0.6698 - val_loss: 48.5011 - val_accuracy: 0.5972\n","Epoch 35/50\n","21/21 [==============================] - 2s 74ms/step - loss: 18.4923 - accuracy: 0.6791 - val_loss: 50.1842 - val_accuracy: 0.5694\n","Epoch 36/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.8993 - accuracy: 0.6807 - val_loss: 49.6309 - val_accuracy: 0.6250\n","Epoch 37/50\n","21/21 [==============================] - 2s 73ms/step - loss: 22.7640 - accuracy: 0.6745 - val_loss: 50.9068 - val_accuracy: 0.6111\n","Epoch 38/50\n","21/21 [==============================] - 1s 71ms/step - loss: 21.7100 - accuracy: 0.6573 - val_loss: 53.6156 - val_accuracy: 0.6111\n","Epoch 39/50\n","21/21 [==============================] - 2s 86ms/step - loss: 20.5327 - accuracy: 0.6713 - val_loss: 51.7473 - val_accuracy: 0.6111\n","Epoch 40/50\n","21/21 [==============================] - 2s 92ms/step - loss: 19.2234 - accuracy: 0.6589 - val_loss: 52.5121 - val_accuracy: 0.5417\n","Epoch 41/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.2292 - accuracy: 0.6636 - val_loss: 50.9942 - val_accuracy: 0.5556\n","Epoch 42/50\n","21/21 [==============================] - 2s 76ms/step - loss: 19.4441 - accuracy: 0.6604 - val_loss: 49.8727 - val_accuracy: 0.5694\n","Epoch 43/50\n","21/21 [==============================] - 1s 71ms/step - loss: 19.4079 - accuracy: 0.6589 - val_loss: 51.1794 - val_accuracy: 0.5417\n","Epoch 44/50\n","21/21 [==============================] - 2s 72ms/step - loss: 19.3196 - accuracy: 0.6511 - val_loss: 51.8561 - val_accuracy: 0.5556\n","Epoch 45/50\n","21/21 [==============================] - 2s 73ms/step - loss: 19.0709 - accuracy: 0.6651 - val_loss: 49.6208 - val_accuracy: 0.5278\n","Epoch 46/50\n","21/21 [==============================] - 2s 72ms/step - loss: 18.9519 - accuracy: 0.6636 - val_loss: 53.1214 - val_accuracy: 0.5833\n","Epoch 47/50\n","21/21 [==============================] - 1s 72ms/step - loss: 19.1880 - accuracy: 0.6558 - val_loss: 51.4707 - val_accuracy: 0.5417\n","Epoch 48/50\n","21/21 [==============================] - 2s 76ms/step - loss: 18.8617 - accuracy: 0.6636 - val_loss: 50.8367 - val_accuracy: 0.5694\n","Epoch 49/50\n","21/21 [==============================] - 2s 94ms/step - loss: 18.5821 - accuracy: 0.6682 - val_loss: 50.7860 - val_accuracy: 0.5833\n","Epoch 50/50\n","21/21 [==============================] - 2s 93ms/step - loss: 18.4101 - accuracy: 0.6651 - val_loss: 52.4765 - val_accuracy: 0.5833\n","6/6 [==============================] - 0s 14ms/step\n","6/6 [==============================] - 0s 14ms/step - loss: 397.7799 - accuracy: 0.9889\n","Test Loss: 397.7799, Test accuracy : 0.9889\n","Epoch 1/50\n","21/21 [==============================] - 2s 86ms/step - loss: 59.1498 - accuracy: 0.2523 - val_loss: 44.5256 - val_accuracy: 0.2083\n","Epoch 2/50\n","21/21 [==============================] - 2s 73ms/step - loss: 37.7037 - accuracy: 0.1511 - val_loss: 46.5901 - val_accuracy: 0.4583\n","Epoch 3/50\n","21/21 [==============================] - 1s 71ms/step - loss: 35.6454 - accuracy: 0.1916 - val_loss: 48.6407 - val_accuracy: 0.4028\n","Epoch 4/50\n","21/21 [==============================] - 2s 72ms/step - loss: 35.3517 - accuracy: 0.1885 - val_loss: 45.2164 - val_accuracy: 0.1250\n","Epoch 5/50\n","21/21 [==============================] - 2s 87ms/step - loss: 31.5318 - accuracy: 0.1573 - val_loss: 45.7368 - val_accuracy: 0.1528\n","Epoch 6/50\n","21/21 [==============================] - 2s 94ms/step - loss: 29.4718 - accuracy: 0.1511 - val_loss: 44.3102 - val_accuracy: 0.1389\n","Epoch 7/50\n","21/21 [==============================] - 2s 100ms/step - loss: 28.7023 - accuracy: 0.1745 - val_loss: 45.1503 - val_accuracy: 0.1528\n","Epoch 8/50\n","21/21 [==============================] - 2s 75ms/step - loss: 27.4818 - accuracy: 0.1573 - val_loss: 47.5084 - val_accuracy: 0.1528\n","Epoch 9/50\n","21/21 [==============================] - 2s 73ms/step - loss: 28.5791 - accuracy: 0.1916 - val_loss: 44.1091 - val_accuracy: 0.1667\n","Epoch 10/50\n","21/21 [==============================] - 1s 71ms/step - loss: 26.3646 - accuracy: 0.3925 - val_loss: 43.4280 - val_accuracy: 0.5139\n","Epoch 11/50\n","21/21 [==============================] - 2s 72ms/step - loss: 27.7042 - accuracy: 0.6636 - val_loss: 45.0482 - val_accuracy: 0.5972\n","Epoch 12/50\n","21/21 [==============================] - 2s 72ms/step - loss: 24.7831 - accuracy: 0.6916 - val_loss: 43.9258 - val_accuracy: 0.6944\n","Epoch 13/50\n","21/21 [==============================] - 1s 70ms/step - loss: 23.8488 - accuracy: 0.6978 - val_loss: 44.2459 - val_accuracy: 0.5972\n","Epoch 14/50\n","21/21 [==============================] - 2s 80ms/step - loss: 23.0663 - accuracy: 0.7165 - val_loss: 43.3629 - val_accuracy: 0.5278\n","Epoch 15/50\n","21/21 [==============================] - 2s 95ms/step - loss: 22.3745 - accuracy: 0.7150 - val_loss: 44.6720 - val_accuracy: 0.6389\n","Epoch 16/50\n","21/21 [==============================] - 2s 101ms/step - loss: 21.7653 - accuracy: 0.7196 - val_loss: 43.7820 - val_accuracy: 0.6667\n","Epoch 17/50\n","21/21 [==============================] - 2s 76ms/step - loss: 21.4096 - accuracy: 0.7648 - val_loss: 43.6706 - val_accuracy: 0.6667\n","Epoch 18/50\n","21/21 [==============================] - 2s 72ms/step - loss: 21.4298 - accuracy: 0.7414 - val_loss: 44.2320 - val_accuracy: 0.7500\n","Epoch 19/50\n","21/21 [==============================] - 2s 72ms/step - loss: 20.6437 - accuracy: 0.7850 - val_loss: 42.9349 - val_accuracy: 0.7083\n","Epoch 20/50\n","21/21 [==============================] - 2s 72ms/step - loss: 20.2199 - accuracy: 0.7757 - val_loss: 44.1175 - val_accuracy: 0.7500\n","Epoch 21/50\n","21/21 [==============================] - 2s 72ms/step - loss: 19.9523 - accuracy: 0.7757 - val_loss: 44.0912 - val_accuracy: 0.7361\n","Epoch 22/50\n","21/21 [==============================] - 1s 71ms/step - loss: 19.6858 - accuracy: 0.7882 - val_loss: 44.3082 - val_accuracy: 0.6667\n","Epoch 23/50\n","21/21 [==============================] - 2s 76ms/step - loss: 19.6483 - accuracy: 0.7695 - val_loss: 43.3528 - val_accuracy: 0.6667\n","Epoch 24/50\n","21/21 [==============================] - 2s 92ms/step - loss: 19.6064 - accuracy: 0.7710 - val_loss: 43.5702 - val_accuracy: 0.7222\n","Epoch 25/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.0314 - accuracy: 0.7399 - val_loss: 44.0041 - val_accuracy: 0.6667\n","Epoch 26/50\n","21/21 [==============================] - 2s 89ms/step - loss: 18.7248 - accuracy: 0.7710 - val_loss: 44.2652 - val_accuracy: 0.5972\n","Epoch 27/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.7073 - accuracy: 0.7523 - val_loss: 46.0897 - val_accuracy: 0.7639\n","Epoch 28/50\n","21/21 [==============================] - 2s 72ms/step - loss: 17.3171 - accuracy: 0.7445 - val_loss: 44.0140 - val_accuracy: 0.7222\n","Epoch 29/50\n","21/21 [==============================] - 1s 72ms/step - loss: 16.9010 - accuracy: 0.7757 - val_loss: 44.5937 - val_accuracy: 0.6944\n","Epoch 30/50\n","21/21 [==============================] - 2s 72ms/step - loss: 16.4761 - accuracy: 0.7555 - val_loss: 44.7688 - val_accuracy: 0.7639\n","Epoch 31/50\n","21/21 [==============================] - 2s 73ms/step - loss: 15.8090 - accuracy: 0.7523 - val_loss: 44.5059 - val_accuracy: 0.6667\n","Epoch 32/50\n","21/21 [==============================] - 2s 74ms/step - loss: 15.3040 - accuracy: 0.7975 - val_loss: 44.7363 - val_accuracy: 0.6944\n","Epoch 33/50\n","21/21 [==============================] - 2s 87ms/step - loss: 15.3151 - accuracy: 0.7882 - val_loss: 45.1260 - val_accuracy: 0.7361\n","Epoch 34/50\n","21/21 [==============================] - 2s 94ms/step - loss: 14.9971 - accuracy: 0.7913 - val_loss: 45.4681 - val_accuracy: 0.6111\n","Epoch 35/50\n","21/21 [==============================] - 2s 96ms/step - loss: 15.6298 - accuracy: 0.7741 - val_loss: 44.8599 - val_accuracy: 0.5139\n","Epoch 36/50\n","21/21 [==============================] - 2s 82ms/step - loss: 15.4626 - accuracy: 0.7648 - val_loss: 45.5539 - val_accuracy: 0.7917\n","Epoch 37/50\n","21/21 [==============================] - 2s 73ms/step - loss: 14.5417 - accuracy: 0.7819 - val_loss: 44.7517 - val_accuracy: 0.7083\n","Epoch 38/50\n","21/21 [==============================] - 2s 73ms/step - loss: 14.2717 - accuracy: 0.8006 - val_loss: 45.1736 - val_accuracy: 0.6389\n","Epoch 39/50\n","21/21 [==============================] - 2s 73ms/step - loss: 14.0160 - accuracy: 0.8037 - val_loss: 44.8513 - val_accuracy: 0.7083\n","Epoch 40/50\n","21/21 [==============================] - 1s 71ms/step - loss: 13.9030 - accuracy: 0.8069 - val_loss: 44.2433 - val_accuracy: 0.7361\n","Epoch 41/50\n","21/21 [==============================] - 2s 73ms/step - loss: 13.8687 - accuracy: 0.8146 - val_loss: 43.9122 - val_accuracy: 0.6667\n","Epoch 42/50\n","21/21 [==============================] - 2s 73ms/step - loss: 13.8625 - accuracy: 0.8115 - val_loss: 44.3380 - val_accuracy: 0.6667\n","Epoch 43/50\n","21/21 [==============================] - 2s 96ms/step - loss: 13.4605 - accuracy: 0.8100 - val_loss: 43.7965 - val_accuracy: 0.6806\n","Epoch 44/50\n","21/21 [==============================] - 2s 97ms/step - loss: 13.1742 - accuracy: 0.8193 - val_loss: 44.4703 - val_accuracy: 0.6944\n","Epoch 45/50\n","21/21 [==============================] - 2s 97ms/step - loss: 13.1068 - accuracy: 0.8162 - val_loss: 43.7613 - val_accuracy: 0.7361\n","Epoch 46/50\n","21/21 [==============================] - 2s 73ms/step - loss: 12.9911 - accuracy: 0.8162 - val_loss: 44.0359 - val_accuracy: 0.7222\n","Epoch 47/50\n","21/21 [==============================] - 2s 74ms/step - loss: 12.8822 - accuracy: 0.8178 - val_loss: 43.8158 - val_accuracy: 0.7083\n","Epoch 48/50\n","21/21 [==============================] - 2s 73ms/step - loss: 12.8414 - accuracy: 0.8193 - val_loss: 43.8843 - val_accuracy: 0.6944\n","Epoch 49/50\n","21/21 [==============================] - 2s 74ms/step - loss: 12.8168 - accuracy: 0.8193 - val_loss: 43.9475 - val_accuracy: 0.7222\n","Epoch 50/50\n","21/21 [==============================] - 2s 73ms/step - loss: 12.8340 - accuracy: 0.8178 - val_loss: 43.8453 - val_accuracy: 0.6944\n","6/6 [==============================] - 0s 15ms/step\n","6/6 [==============================] - 0s 16ms/step - loss: 224.8968 - accuracy: 0.9167\n","Test Loss: 224.8968, Test accuracy : 0.9167\n","Epoch 1/50\n","21/21 [==============================] - 3s 111ms/step - loss: 71.3879 - accuracy: 0.0903 - val_loss: 58.7584 - val_accuracy: 0.0139\n","Epoch 2/50\n","21/21 [==============================] - 2s 74ms/step - loss: 61.1776 - accuracy: 0.0903 - val_loss: 56.1918 - val_accuracy: 0.1250\n","Epoch 3/50\n","21/21 [==============================] - 2s 73ms/step - loss: 55.8577 - accuracy: 0.1791 - val_loss: 52.7608 - val_accuracy: 0.2361\n","Epoch 4/50\n","21/21 [==============================] - 2s 72ms/step - loss: 51.1871 - accuracy: 0.2118 - val_loss: 52.6422 - val_accuracy: 0.0556\n","Epoch 5/50\n","21/21 [==============================] - 2s 75ms/step - loss: 48.8780 - accuracy: 0.2290 - val_loss: 50.9129 - val_accuracy: 0.0139\n","Epoch 6/50\n","21/21 [==============================] - 2s 72ms/step - loss: 44.1706 - accuracy: 0.2710 - val_loss: 50.1824 - val_accuracy: 0.0972\n","Epoch 7/50\n","21/21 [==============================] - 2s 74ms/step - loss: 40.3829 - accuracy: 0.2586 - val_loss: 48.4298 - val_accuracy: 0.2083\n","Epoch 8/50\n","21/21 [==============================] - 2s 96ms/step - loss: 36.6213 - accuracy: 0.3037 - val_loss: 53.2363 - val_accuracy: 0.2083\n","Epoch 9/50\n","21/21 [==============================] - 2s 95ms/step - loss: 36.7311 - accuracy: 0.2477 - val_loss: 49.3388 - val_accuracy: 0.2778\n","Epoch 10/50\n","21/21 [==============================] - 2s 93ms/step - loss: 33.2993 - accuracy: 0.2944 - val_loss: 51.2417 - val_accuracy: 0.2500\n","Epoch 11/50\n","21/21 [==============================] - 2s 75ms/step - loss: 31.4546 - accuracy: 0.2835 - val_loss: 50.9290 - val_accuracy: 0.2083\n","Epoch 12/50\n","21/21 [==============================] - 2s 75ms/step - loss: 29.7874 - accuracy: 0.2601 - val_loss: 48.6915 - val_accuracy: 0.2222\n","Epoch 13/50\n","21/21 [==============================] - 2s 75ms/step - loss: 28.4019 - accuracy: 0.3069 - val_loss: 48.8414 - val_accuracy: 0.3333\n","Epoch 14/50\n","21/21 [==============================] - 2s 72ms/step - loss: 27.0740 - accuracy: 0.2944 - val_loss: 50.3420 - val_accuracy: 0.2639\n","Epoch 15/50\n","21/21 [==============================] - 2s 73ms/step - loss: 25.8467 - accuracy: 0.2850 - val_loss: 47.9260 - val_accuracy: 0.3194\n","Epoch 16/50\n","21/21 [==============================] - 2s 73ms/step - loss: 24.7842 - accuracy: 0.3006 - val_loss: 49.4169 - val_accuracy: 0.2500\n","Epoch 17/50\n","21/21 [==============================] - 2s 91ms/step - loss: 24.1838 - accuracy: 0.3536 - val_loss: 49.5104 - val_accuracy: 0.2917\n","Epoch 18/50\n","21/21 [==============================] - 2s 94ms/step - loss: 23.3337 - accuracy: 0.3474 - val_loss: 51.7456 - val_accuracy: 0.2778\n","Epoch 19/50\n","21/21 [==============================] - 2s 99ms/step - loss: 24.3684 - accuracy: 0.3458 - val_loss: 50.8069 - val_accuracy: 0.2778\n","Epoch 20/50\n","21/21 [==============================] - 2s 73ms/step - loss: 22.4827 - accuracy: 0.3583 - val_loss: 49.1236 - val_accuracy: 0.2639\n","Epoch 21/50\n","21/21 [==============================] - 2s 73ms/step - loss: 21.4650 - accuracy: 0.3614 - val_loss: 49.2194 - val_accuracy: 0.3194\n","Epoch 22/50\n","21/21 [==============================] - 2s 72ms/step - loss: 20.9070 - accuracy: 0.3660 - val_loss: 49.1221 - val_accuracy: 0.3333\n","Epoch 23/50\n","21/21 [==============================] - 2s 72ms/step - loss: 20.1249 - accuracy: 0.3754 - val_loss: 50.9452 - val_accuracy: 0.2361\n","Epoch 24/50\n","21/21 [==============================] - 2s 74ms/step - loss: 20.0188 - accuracy: 0.3676 - val_loss: 49.0700 - val_accuracy: 0.2639\n","Epoch 25/50\n","21/21 [==============================] - 2s 75ms/step - loss: 19.7066 - accuracy: 0.3816 - val_loss: 53.1607 - val_accuracy: 0.3333\n","Epoch 26/50\n","21/21 [==============================] - 2s 86ms/step - loss: 20.9558 - accuracy: 0.3801 - val_loss: 52.0845 - val_accuracy: 0.3056\n","Epoch 27/50\n","21/21 [==============================] - 2s 96ms/step - loss: 19.7511 - accuracy: 0.3816 - val_loss: 51.4011 - val_accuracy: 0.3056\n","Epoch 28/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.8115 - accuracy: 0.4143 - val_loss: 47.8987 - val_accuracy: 0.3194\n","Epoch 29/50\n","21/21 [==============================] - 2s 81ms/step - loss: 19.5056 - accuracy: 0.4034 - val_loss: 48.3864 - val_accuracy: 0.2500\n","Epoch 30/50\n","21/21 [==============================] - 2s 74ms/step - loss: 19.0539 - accuracy: 0.4268 - val_loss: 48.2988 - val_accuracy: 0.2917\n","Epoch 31/50\n","21/21 [==============================] - 2s 74ms/step - loss: 18.9315 - accuracy: 0.4190 - val_loss: 51.9710 - val_accuracy: 0.3194\n","Epoch 32/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.8302 - accuracy: 0.4377 - val_loss: 50.0011 - val_accuracy: 0.2917\n","Epoch 33/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.0875 - accuracy: 0.4408 - val_loss: 50.4903 - val_accuracy: 0.2778\n","Epoch 34/50\n","21/21 [==============================] - 2s 73ms/step - loss: 17.7130 - accuracy: 0.4470 - val_loss: 50.4150 - val_accuracy: 0.2917\n","Epoch 35/50\n","21/21 [==============================] - 2s 78ms/step - loss: 17.4588 - accuracy: 0.4439 - val_loss: 50.1343 - val_accuracy: 0.3194\n","Epoch 36/50\n","21/21 [==============================] - 2s 96ms/step - loss: 17.3343 - accuracy: 0.4626 - val_loss: 50.3062 - val_accuracy: 0.2222\n","Epoch 37/50\n","21/21 [==============================] - 2s 95ms/step - loss: 17.4432 - accuracy: 0.4704 - val_loss: 50.1344 - val_accuracy: 0.2500\n","Epoch 38/50\n","21/21 [==============================] - 2s 90ms/step - loss: 17.6602 - accuracy: 0.4735 - val_loss: 52.5735 - val_accuracy: 0.3056\n","Epoch 39/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.2557 - accuracy: 0.4611 - val_loss: 51.1428 - val_accuracy: 0.2639\n","Epoch 40/50\n","21/21 [==============================] - 2s 72ms/step - loss: 18.9576 - accuracy: 0.4657 - val_loss: 51.9165 - val_accuracy: 0.2639\n","Epoch 41/50\n","21/21 [==============================] - 2s 74ms/step - loss: 18.4044 - accuracy: 0.4517 - val_loss: 52.9562 - val_accuracy: 0.2639\n","Epoch 42/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.8112 - accuracy: 0.3956 - val_loss: 51.3406 - val_accuracy: 0.3472\n","Epoch 43/50\n","21/21 [==============================] - 2s 74ms/step - loss: 19.2216 - accuracy: 0.3536 - val_loss: 56.2037 - val_accuracy: 0.2639\n","Epoch 44/50\n","21/21 [==============================] - 2s 74ms/step - loss: 21.2379 - accuracy: 0.3645 - val_loss: 54.6778 - val_accuracy: 0.2778\n","Epoch 45/50\n","21/21 [==============================] - 2s 89ms/step - loss: 20.7474 - accuracy: 0.3240 - val_loss: 52.1954 - val_accuracy: 0.3194\n","Epoch 46/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.9141 - accuracy: 0.3598 - val_loss: 54.2617 - val_accuracy: 0.2778\n","Epoch 47/50\n","21/21 [==============================] - 2s 95ms/step - loss: 19.4768 - accuracy: 0.3458 - val_loss: 54.6703 - val_accuracy: 0.2639\n","Epoch 48/50\n","21/21 [==============================] - 2s 81ms/step - loss: 19.3575 - accuracy: 0.3769 - val_loss: 51.9280 - val_accuracy: 0.3472\n","Epoch 49/50\n","21/21 [==============================] - 2s 75ms/step - loss: 18.5415 - accuracy: 0.3738 - val_loss: 51.4218 - val_accuracy: 0.2639\n","Epoch 50/50\n","21/21 [==============================] - 2s 73ms/step - loss: 18.0801 - accuracy: 0.3879 - val_loss: 50.5106 - val_accuracy: 0.2639\n","6/6 [==============================] - 0s 19ms/step\n","6/6 [==============================] - 0s 25ms/step - loss: 627.7892 - accuracy: 0.7833\n","Test Loss: 627.7892, Test accuracy : 0.7833\n","Epoch 1/50\n","21/21 [==============================] - 3s 99ms/step - loss: 134.3084 - accuracy: 0.3006 - val_loss: 45.1417 - val_accuracy: 0.0139\n","Epoch 2/50\n","21/21 [==============================] - 2s 99ms/step - loss: 69.6462 - accuracy: 0.4751 - val_loss: 38.5493 - val_accuracy: 0.8194\n","Epoch 3/50\n","21/21 [==============================] - 2s 97ms/step - loss: 67.7396 - accuracy: 0.6277 - val_loss: 40.1902 - val_accuracy: 0.4444\n","Epoch 4/50\n","21/21 [==============================] - 2s 81ms/step - loss: 64.4983 - accuracy: 0.6869 - val_loss: 39.5553 - val_accuracy: 0.5694\n","Epoch 5/50\n","21/21 [==============================] - 2s 73ms/step - loss: 63.3075 - accuracy: 0.6729 - val_loss: 39.4552 - val_accuracy: 0.6944\n","Epoch 6/50\n","21/21 [==============================] - 2s 75ms/step - loss: 60.9669 - accuracy: 0.6262 - val_loss: 42.2702 - val_accuracy: 0.2778\n","Epoch 7/50\n","21/21 [==============================] - 2s 76ms/step - loss: 57.6411 - accuracy: 0.6168 - val_loss: 44.0874 - val_accuracy: 0.2083\n","Epoch 8/50\n","21/21 [==============================] - 2s 74ms/step - loss: 55.6868 - accuracy: 0.6199 - val_loss: 39.3256 - val_accuracy: 0.6250\n","Epoch 9/50\n","21/21 [==============================] - 1s 71ms/step - loss: 53.6996 - accuracy: 0.6620 - val_loss: 39.3227 - val_accuracy: 0.5972\n","Epoch 10/50\n","21/21 [==============================] - 2s 81ms/step - loss: 52.0993 - accuracy: 0.7103 - val_loss: 39.3559 - val_accuracy: 0.5833\n","Epoch 11/50\n","21/21 [==============================] - 2s 94ms/step - loss: 49.4453 - accuracy: 0.6713 - val_loss: 39.7100 - val_accuracy: 0.5972\n","Epoch 12/50\n","21/21 [==============================] - 2s 97ms/step - loss: 49.0038 - accuracy: 0.7305 - val_loss: 39.0401 - val_accuracy: 0.6389\n","Epoch 13/50\n","21/21 [==============================] - 2s 83ms/step - loss: 46.7121 - accuracy: 0.7492 - val_loss: 45.3305 - val_accuracy: 0.4861\n","Epoch 14/50\n","21/21 [==============================] - 2s 72ms/step - loss: 44.8742 - accuracy: 0.7430 - val_loss: 43.3448 - val_accuracy: 0.5417\n","Epoch 15/50\n","21/21 [==============================] - 2s 73ms/step - loss: 43.0563 - accuracy: 0.7710 - val_loss: 43.7780 - val_accuracy: 0.5417\n","Epoch 16/50\n","21/21 [==============================] - 2s 74ms/step - loss: 41.0088 - accuracy: 0.7695 - val_loss: 41.8703 - val_accuracy: 0.6806\n","Epoch 17/50\n","21/21 [==============================] - 2s 74ms/step - loss: 37.8641 - accuracy: 0.8022 - val_loss: 42.4959 - val_accuracy: 0.6250\n","Epoch 18/50\n","21/21 [==============================] - 2s 73ms/step - loss: 34.5638 - accuracy: 0.8224 - val_loss: 47.2003 - val_accuracy: 0.8056\n","Epoch 19/50\n","21/21 [==============================] - 2s 75ms/step - loss: 32.6155 - accuracy: 0.7960 - val_loss: 43.7143 - val_accuracy: 0.8194\n","Epoch 20/50\n","21/21 [==============================] - 2s 93ms/step - loss: 30.5215 - accuracy: 0.8162 - val_loss: 42.8943 - val_accuracy: 0.6528\n","Epoch 21/50\n","21/21 [==============================] - 2s 95ms/step - loss: 34.3102 - accuracy: 0.8100 - val_loss: 58.9530 - val_accuracy: 0.6528\n","Epoch 22/50\n","21/21 [==============================] - 2s 93ms/step - loss: 31.5846 - accuracy: 0.8069 - val_loss: 41.6557 - val_accuracy: 0.6667\n","Epoch 23/50\n","21/21 [==============================] - 2s 73ms/step - loss: 27.4804 - accuracy: 0.8131 - val_loss: 40.8355 - val_accuracy: 0.7500\n","Epoch 24/50\n","21/21 [==============================] - 2s 74ms/step - loss: 25.6839 - accuracy: 0.8022 - val_loss: 42.3265 - val_accuracy: 0.7083\n","Epoch 25/50\n","21/21 [==============================] - 2s 74ms/step - loss: 24.3550 - accuracy: 0.8037 - val_loss: 44.6873 - val_accuracy: 0.5833\n","Epoch 26/50\n","21/21 [==============================] - 2s 73ms/step - loss: 22.1566 - accuracy: 0.8022 - val_loss: 41.5308 - val_accuracy: 0.7639\n","Epoch 27/50\n","21/21 [==============================] - 2s 74ms/step - loss: 21.4941 - accuracy: 0.8131 - val_loss: 48.6899 - val_accuracy: 0.8056\n","Epoch 28/50\n","21/21 [==============================] - 2s 74ms/step - loss: 21.0575 - accuracy: 0.8037 - val_loss: 63.3232 - val_accuracy: 0.8056\n","Epoch 29/50\n","21/21 [==============================] - 2s 83ms/step - loss: 26.8278 - accuracy: 0.7975 - val_loss: 40.1452 - val_accuracy: 0.7083\n","Epoch 30/50\n","21/21 [==============================] - 2s 96ms/step - loss: 24.7858 - accuracy: 0.8193 - val_loss: 39.3070 - val_accuracy: 0.7500\n","Epoch 31/50\n","21/21 [==============================] - 2s 99ms/step - loss: 24.8300 - accuracy: 0.8193 - val_loss: 43.0241 - val_accuracy: 0.7500\n","Epoch 32/50\n","21/21 [==============================] - 2s 80ms/step - loss: 23.2543 - accuracy: 0.8100 - val_loss: 44.5341 - val_accuracy: 0.7500\n","Epoch 33/50\n","21/21 [==============================] - 2s 73ms/step - loss: 22.6961 - accuracy: 0.8100 - val_loss: 46.8791 - val_accuracy: 0.7222\n","Epoch 34/50\n","21/21 [==============================] - 2s 73ms/step - loss: 22.7848 - accuracy: 0.8069 - val_loss: 40.9161 - val_accuracy: 0.7500\n","Epoch 35/50\n","21/21 [==============================] - 2s 72ms/step - loss: 22.2633 - accuracy: 0.8069 - val_loss: 45.4537 - val_accuracy: 0.6944\n","Epoch 36/50\n","21/21 [==============================] - 2s 74ms/step - loss: 22.8203 - accuracy: 0.7819 - val_loss: 44.4004 - val_accuracy: 0.7083\n","Epoch 37/50\n","21/21 [==============================] - 2s 75ms/step - loss: 19.9907 - accuracy: 0.7991 - val_loss: 41.4327 - val_accuracy: 0.7500\n","Epoch 38/50\n","21/21 [==============================] - 2s 79ms/step - loss: 18.0286 - accuracy: 0.8037 - val_loss: 39.2270 - val_accuracy: 0.7361\n","Epoch 39/50\n","21/21 [==============================] - 2s 97ms/step - loss: 17.5637 - accuracy: 0.8037 - val_loss: 38.4964 - val_accuracy: 0.7917\n","Epoch 40/50\n","21/21 [==============================] - 2s 97ms/step - loss: 17.1547 - accuracy: 0.8006 - val_loss: 37.2321 - val_accuracy: 0.7917\n","Epoch 41/50\n","21/21 [==============================] - 2s 91ms/step - loss: 16.9739 - accuracy: 0.8006 - val_loss: 39.5522 - val_accuracy: 0.7361\n","Epoch 42/50\n","21/21 [==============================] - 2s 72ms/step - loss: 17.2201 - accuracy: 0.7975 - val_loss: 39.2551 - val_accuracy: 0.7778\n","Epoch 43/50\n","21/21 [==============================] - 2s 74ms/step - loss: 16.6699 - accuracy: 0.7975 - val_loss: 39.1518 - val_accuracy: 0.7917\n","Epoch 44/50\n","21/21 [==============================] - 2s 75ms/step - loss: 16.3154 - accuracy: 0.7944 - val_loss: 37.5565 - val_accuracy: 0.7778\n","Epoch 45/50\n","21/21 [==============================] - 2s 72ms/step - loss: 16.0692 - accuracy: 0.7975 - val_loss: 38.8270 - val_accuracy: 0.7500\n","Epoch 46/50\n","21/21 [==============================] - 2s 74ms/step - loss: 15.9503 - accuracy: 0.7975 - val_loss: 39.0653 - val_accuracy: 0.7500\n","Epoch 47/50\n","21/21 [==============================] - 2s 75ms/step - loss: 15.9824 - accuracy: 0.7960 - val_loss: 38.3051 - val_accuracy: 0.7500\n","Epoch 48/50\n","21/21 [==============================] - 2s 93ms/step - loss: 15.8174 - accuracy: 0.7960 - val_loss: 38.3321 - val_accuracy: 0.7639\n","Epoch 49/50\n","21/21 [==============================] - 2s 93ms/step - loss: 15.7044 - accuracy: 0.8006 - val_loss: 38.6954 - val_accuracy: 0.7500\n","Epoch 50/50\n","21/21 [==============================] - 2s 95ms/step - loss: 15.5937 - accuracy: 0.7991 - val_loss: 38.7577 - val_accuracy: 0.7639\n","6/6 [==============================] - 0s 16ms/step\n","6/6 [==============================] - 0s 16ms/step - loss: 195.0730 - accuracy: 1.0000\n","Test Loss: 195.0730, Test accuracy : 1.0000\n","Epoch 1/50\n","21/21 [==============================] - 2s 84ms/step - loss: 88.9969 - accuracy: 0.4034 - val_loss: 96.4242 - val_accuracy: 0.6250\n","Epoch 2/50\n","21/21 [==============================] - 2s 96ms/step - loss: 44.2436 - accuracy: 0.5202 - val_loss: 99.6926 - val_accuracy: 0.4306\n","Epoch 3/50\n","21/21 [==============================] - 2s 98ms/step - loss: 38.9006 - accuracy: 0.4735 - val_loss: 99.7180 - val_accuracy: 0.6667\n","Epoch 4/50\n","21/21 [==============================] - 2s 90ms/step - loss: 37.4144 - accuracy: 0.5530 - val_loss: 99.7499 - val_accuracy: 0.6944\n","Epoch 5/50\n","21/21 [==============================] - 2s 74ms/step - loss: 32.5551 - accuracy: 0.5249 - val_loss: 99.3149 - val_accuracy: 0.6667\n","Epoch 6/50\n","21/21 [==============================] - 2s 74ms/step - loss: 30.8500 - accuracy: 0.4673 - val_loss: 91.6561 - val_accuracy: 0.4028\n","Epoch 7/50\n","21/21 [==============================] - 2s 75ms/step - loss: 27.0035 - accuracy: 0.4564 - val_loss: 88.6434 - val_accuracy: 0.6111\n","Epoch 8/50\n","21/21 [==============================] - 2s 75ms/step - loss: 23.4430 - accuracy: 0.4969 - val_loss: 82.9038 - val_accuracy: 0.4583\n","Epoch 9/50\n","21/21 [==============================] - 2s 75ms/step - loss: 20.9302 - accuracy: 0.5841 - val_loss: 86.4158 - val_accuracy: 0.5972\n","Epoch 10/50\n","21/21 [==============================] - 2s 74ms/step - loss: 18.0608 - accuracy: 0.5218 - val_loss: 87.7520 - val_accuracy: 0.6528\n","Epoch 11/50\n","21/21 [==============================] - 2s 93ms/step - loss: 17.3081 - accuracy: 0.5483 - val_loss: 88.2222 - val_accuracy: 0.6389\n","Epoch 12/50\n","21/21 [==============================] - 2s 95ms/step - loss: 15.2524 - accuracy: 0.5763 - val_loss: 85.9160 - val_accuracy: 0.5972\n","Epoch 13/50\n","21/21 [==============================] - 2s 97ms/step - loss: 14.0238 - accuracy: 0.3816 - val_loss: 80.0488 - val_accuracy: 0.1944\n","Epoch 14/50\n","21/21 [==============================] - 2s 76ms/step - loss: 13.4580 - accuracy: 0.1994 - val_loss: 83.5327 - val_accuracy: 0.1944\n","Epoch 15/50\n","21/21 [==============================] - 2s 77ms/step - loss: 12.4679 - accuracy: 0.1807 - val_loss: 81.2029 - val_accuracy: 0.2083\n","Epoch 16/50\n","21/21 [==============================] - 2s 74ms/step - loss: 11.7553 - accuracy: 0.1838 - val_loss: 86.6442 - val_accuracy: 0.1944\n","Epoch 17/50\n","21/21 [==============================] - 2s 75ms/step - loss: 13.4114 - accuracy: 0.1807 - val_loss: 89.9073 - val_accuracy: 0.1944\n","Epoch 18/50\n","21/21 [==============================] - 2s 73ms/step - loss: 13.6251 - accuracy: 0.2009 - val_loss: 84.0878 - val_accuracy: 0.1944\n","Epoch 19/50\n","21/21 [==============================] - 2s 76ms/step - loss: 12.5194 - accuracy: 0.1745 - val_loss: 83.8695 - val_accuracy: 0.1944\n","Epoch 20/50\n","21/21 [==============================] - 2s 88ms/step - loss: 11.1878 - accuracy: 0.2150 - val_loss: 83.0972 - val_accuracy: 0.1944\n","Epoch 21/50\n","21/21 [==============================] - 2s 95ms/step - loss: 10.5697 - accuracy: 0.1838 - val_loss: 81.9476 - val_accuracy: 0.1944\n","Epoch 22/50\n","21/21 [==============================] - 2s 102ms/step - loss: 10.4067 - accuracy: 0.1776 - val_loss: 82.7501 - val_accuracy: 0.1944\n","Epoch 23/50\n","21/21 [==============================] - 2s 81ms/step - loss: 10.0063 - accuracy: 0.1698 - val_loss: 81.0237 - val_accuracy: 0.2083\n","Epoch 24/50\n","21/21 [==============================] - 2s 73ms/step - loss: 10.0051 - accuracy: 0.1698 - val_loss: 83.7054 - val_accuracy: 0.2083\n","Epoch 25/50\n","21/21 [==============================] - 2s 75ms/step - loss: 9.7166 - accuracy: 0.1449 - val_loss: 85.1742 - val_accuracy: 0.2083\n","Epoch 26/50\n","21/21 [==============================] - 2s 75ms/step - loss: 9.5710 - accuracy: 0.1511 - val_loss: 83.9365 - val_accuracy: 0.2083\n","Epoch 27/50\n","21/21 [==============================] - 2s 74ms/step - loss: 9.4530 - accuracy: 0.1636 - val_loss: 84.6883 - val_accuracy: 0.2639\n","Epoch 28/50\n","21/21 [==============================] - 2s 74ms/step - loss: 9.4853 - accuracy: 0.1931 - val_loss: 87.2279 - val_accuracy: 0.2500\n","Epoch 29/50\n","21/21 [==============================] - 2s 83ms/step - loss: 9.3099 - accuracy: 0.1994 - val_loss: 86.2851 - val_accuracy: 0.3194\n","Epoch 30/50\n","21/21 [==============================] - 2s 98ms/step - loss: 9.2376 - accuracy: 0.2165 - val_loss: 84.8538 - val_accuracy: 0.3472\n","Epoch 31/50\n","21/21 [==============================] - 2s 99ms/step - loss: 9.2015 - accuracy: 0.1931 - val_loss: 86.2111 - val_accuracy: 0.3056\n","Epoch 32/50\n","21/21 [==============================] - 2s 81ms/step - loss: 9.0862 - accuracy: 0.1542 - val_loss: 86.8232 - val_accuracy: 0.3056\n","Epoch 33/50\n","21/21 [==============================] - 2s 73ms/step - loss: 9.0544 - accuracy: 0.1838 - val_loss: 87.1441 - val_accuracy: 0.2917\n","Epoch 34/50\n","21/21 [==============================] - 2s 75ms/step - loss: 9.0343 - accuracy: 0.2227 - val_loss: 86.1724 - val_accuracy: 0.3194\n","Epoch 35/50\n","21/21 [==============================] - 2s 73ms/step - loss: 9.2583 - accuracy: 0.1745 - val_loss: 87.3169 - val_accuracy: 0.2639\n","Epoch 36/50\n","21/21 [==============================] - 2s 76ms/step - loss: 9.5223 - accuracy: 0.1636 - val_loss: 86.8349 - val_accuracy: 0.3611\n","Epoch 37/50\n","21/21 [==============================] - 2s 75ms/step - loss: 9.3545 - accuracy: 0.1885 - val_loss: 86.5014 - val_accuracy: 0.3194\n","Epoch 38/50\n","21/21 [==============================] - 2s 83ms/step - loss: 9.1814 - accuracy: 0.1760 - val_loss: 85.6806 - val_accuracy: 0.3611\n","Epoch 39/50\n","21/21 [==============================] - 2s 96ms/step - loss: 9.0895 - accuracy: 0.1760 - val_loss: 87.4836 - val_accuracy: 0.3194\n","Epoch 40/50\n","21/21 [==============================] - 2s 100ms/step - loss: 9.1338 - accuracy: 0.2461 - val_loss: 88.6036 - val_accuracy: 0.2639\n","Epoch 41/50\n","21/21 [==============================] - 2s 83ms/step - loss: 9.3922 - accuracy: 0.2243 - val_loss: 86.3462 - val_accuracy: 0.3611\n","Epoch 42/50\n","21/21 [==============================] - 2s 74ms/step - loss: 9.2208 - accuracy: 0.2648 - val_loss: 86.4270 - val_accuracy: 0.3889\n","Epoch 43/50\n","21/21 [==============================] - 2s 73ms/step - loss: 9.1425 - accuracy: 0.2523 - val_loss: 87.5243 - val_accuracy: 0.3056\n","Epoch 44/50\n","21/21 [==============================] - 2s 75ms/step - loss: 9.1106 - accuracy: 0.2321 - val_loss: 86.6198 - val_accuracy: 0.3194\n","Epoch 45/50\n","21/21 [==============================] - 2s 74ms/step - loss: 9.0133 - accuracy: 0.3178 - val_loss: 85.5307 - val_accuracy: 0.3750\n","Epoch 46/50\n","21/21 [==============================] - 2s 76ms/step - loss: 8.9972 - accuracy: 0.3863 - val_loss: 85.8847 - val_accuracy: 0.3750\n","Epoch 47/50\n","21/21 [==============================] - 2s 80ms/step - loss: 8.9347 - accuracy: 0.4221 - val_loss: 86.0312 - val_accuracy: 0.3889\n","Epoch 48/50\n","21/21 [==============================] - 2s 98ms/step - loss: 8.9041 - accuracy: 0.4439 - val_loss: 86.2114 - val_accuracy: 0.4306\n","Epoch 49/50\n","21/21 [==============================] - 2s 100ms/step - loss: 8.8971 - accuracy: 0.4455 - val_loss: 84.2720 - val_accuracy: 0.4028\n","Epoch 50/50\n","21/21 [==============================] - 2s 87ms/step - loss: 8.9320 - accuracy: 0.4299 - val_loss: 85.4323 - val_accuracy: 0.3750\n","6/6 [==============================] - 0s 15ms/step\n","6/6 [==============================] - 0s 19ms/step - loss: 515.7960 - accuracy: 0.5056\n","Test Loss: 515.7960, Test accuracy : 0.5056\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU","executionInfo":{"status":"ok","timestamp":1715615889591,"user_tz":-60,"elapsed":17,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1715615895984,"user_tz":-60,"elapsed":6409,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca51a169-8dc8-4b62-86a9-01c73f8e203f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten (Flatten)           (None, 81471)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                5214208   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 5214338 (19.89 MB)\n","Trainable params: 5214338 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 5214403 (19.89 MB)\n","Trainable params: 5214403 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_5 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 5214533 (19.89 MB)\n","Trainable params: 5214533 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_9 (Dense)             (None, 9)                 585       \n","                                                                 \n","=================================================================\n","Total params: 5214793 (19.89 MB)\n","Trainable params: 5214793 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_11 (Dense)            (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 5215053 (19.89 MB)\n","Trainable params: 5215053 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_12 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_13 (Dense)            (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 5215768 (19.90 MB)\n","Trainable params: 5215768 (19.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_15 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_17 (Dense)            (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 5214663 (19.89 MB)\n","Trainable params: 5214663 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw","executionInfo":{"status":"ok","timestamp":1715615895985,"user_tz":-60,"elapsed":32,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1715615895985,"user_tz":-60,"elapsed":31,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d60f1d49-23a8-4194-f6da-2e20a7953953"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                238                60   \n","1   madd_6_Lazim  Yassin Al Jazaery                238                60   \n","2   madd_6_Lazim   Ibrahim_Aldosary                238                60   \n","3   madd_6_Lazim       all reciters                714               180   \n","4       madd_246        Abdul Basit                238                60   \n","5       madd_246  Yassin Al Jazaery                238                60   \n","6       madd_246   Ibrahim_Aldosary                238                60   \n","7       madd_246       all reciters                714               180   \n","8         madd_6        Abdul Basit                238                60   \n","9         madd_6  Yassin Al Jazaery                238                60   \n","10        madd_6   Ibrahim_Aldosary                238                60   \n","11        madd_6       all reciters                714               180   \n","12        madd_2        Abdul Basit                238                60   \n","13        madd_2  Yassin Al Jazaery                238                60   \n","14        madd_2   Ibrahim_Aldosary                238                60   \n","15        madd_2       all reciters                714               180   \n","16        Ikhfaa        Abdul Basit                238                60   \n","17        Ikhfaa  Yassin Al Jazaery                238                60   \n","18        Ikhfaa   Ibrahim_Aldosary                238                60   \n","19        Ikhfaa       all reciters                714               180   \n","20        Idgham        Abdul Basit                238                60   \n","21        Idgham  Yassin Al Jazaery                238                60   \n","22        Idgham   Ibrahim_Aldosary                238                60   \n","23        Idgham       all reciters                714               180   \n","24       tafkhim        Abdul Basit                238                60   \n","25       tafkhim  Yassin Al Jazaery                238                60   \n","26       tafkhim   Ibrahim_Aldosary                238                60   \n","27       tafkhim       all reciters                714               180   \n","28       qalqala        Abdul Basit                238                60   \n","29       qalqala  Yassin Al Jazaery                238                60   \n","30       qalqala   Ibrahim_Aldosary                238                60   \n","31       qalqala       all reciters                714               180   \n","32         imala        Abdul Basit                238                60   \n","33         imala  Yassin Al Jazaery                238                60   \n","34         imala   Ibrahim_Aldosary                238                60   \n","35         imala       all reciters                714               180   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                 238                60  \n","1                 238                60  \n","2                 238                60  \n","3                 714               180  \n","4                 238                60  \n","5                 238                60  \n","6                 238                60  \n","7                 714               180  \n","8                 238                60  \n","9                 238                60  \n","10                238                60  \n","11                714               180  \n","12                238                60  \n","13                238                60  \n","14                238                60  \n","15                714               180  \n","16                238                60  \n","17                238                60  \n","18                238                60  \n","19                714               180  \n","20                238                60  \n","21                238                60  \n","22                238                60  \n","23                714               180  \n","24                238                60  \n","25                238                60  \n","26                238                60  \n","27                714               180  \n","28                238                60  \n","29                238                60  \n","30                238                60  \n","31                714               180  \n","32                238                60  \n","33                238                60  \n","34                238                60  \n","35                714               180  "],"text/html":["\n","  <div id=\"df-62e9f4c1-7dc7-478c-b0f7-759a98d10cd9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>714</td>\n","      <td>180</td>\n","      <td>714</td>\n","      <td>180</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62e9f4c1-7dc7-478c-b0f7-759a98d10cd9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-62e9f4c1-7dc7-478c-b0f7-759a98d10cd9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-62e9f4c1-7dc7-478c-b0f7-759a98d10cd9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-84d241bf-849a-42ab-ac83-dcdaaf5e3fcf\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84d241bf-849a-42ab-ac83-dcdaaf5e3fcf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-84d241bf-849a-42ab-ac83-dcdaaf5e3fcf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Yassin Al Jazaery\",\n          \"all reciters\",\n          \"Abdul Basit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"714\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"180\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"714\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"180\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1715615895986,"user_tz":-60,"elapsed":15,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"5bfdef7b-183d-43e0-ed2d-aff38392abb2"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model       Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model  1881.5801   0.9833      98.33   \n","1      madd_246_tajweed_rule_model  1740.2919   0.9833      98.33   \n","2        madd_6_tajweed_rule_model    69.4452   0.8778      87.78   \n","3        madd_2_tajweed_rule_model   153.3978   1.0000     100.00   \n","4        Ikhfaa_tajweed_rule_model   397.7799   0.9889      98.89   \n","5        Idgham_tajweed_rule_model   224.8968   0.9167      91.67   \n","6       tafkhim_tajweed_rule_model   627.7892   0.7833      78.33   \n","7       qalqala_tajweed_rule_model   195.0730   1.0000     100.00   \n","8         imala_tajweed_rule_model   515.7960   0.5056      50.56   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","1  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","2  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","3  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","4  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","5  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","6  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","7  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  \n","8  /content/drive/My Drive/M2 GL/PFE/AI_models_v2...  "],"text/html":["\n","  <div id=\"df-7c9e48e9-0d95-4de9-8832-50d26ac1bd76\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>1881.5801</td>\n","      <td>0.9833</td>\n","      <td>98.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>1740.2919</td>\n","      <td>0.9833</td>\n","      <td>98.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>69.4452</td>\n","      <td>0.8778</td>\n","      <td>87.78</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>153.3978</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>397.7799</td>\n","      <td>0.9889</td>\n","      <td>98.89</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>224.8968</td>\n","      <td>0.9167</td>\n","      <td>91.67</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>627.7892</td>\n","      <td>0.7833</td>\n","      <td>78.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>195.0730</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>515.7960</td>\n","      <td>0.5056</td>\n","      <td>50.56</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c9e48e9-0d95-4de9-8832-50d26ac1bd76')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7c9e48e9-0d95-4de9-8832-50d26ac1bd76 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7c9e48e9-0d95-4de9-8832-50d26ac1bd76');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-23209495-e1ea-4649-937b-9feca5aae96d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23209495-e1ea-4649-937b-9feca5aae96d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-23209495-e1ea-4649-937b-9feca5aae96d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"195.0730\",\n          \"1740.2919\",\n          \"224.8968\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"0.9833\",\n          \"0.8778\",\n          \"0.7833\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"98.33\",\n          \"87.78\",\n          \"78.33\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v2/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v2/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v2/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]}]}