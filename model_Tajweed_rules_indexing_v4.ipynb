{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOj02wlICUD/OsAPiVhBNhN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1715954043616,"user_tz":-60,"elapsed":28524,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"ab844664-73c9-4553-c813-7527a7acd78f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE","executionInfo":{"status":"ok","timestamp":1715954048870,"user_tz":-60,"elapsed":5261,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing_v2.csv')\n","safa_data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/safa_hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing.csv')"],"metadata":{"id":"WtJVQemz7klg","executionInfo":{"status":"ok","timestamp":1715954062109,"user_tz":-60,"elapsed":13288,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/AI_models_v4'"],"metadata":{"id":"7A9PSizPHQos","executionInfo":{"status":"ok","timestamp":1715954062110,"user_tz":-60,"elapsed":51,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']"],"metadata":{"id":"KoKbTBQr7nY8","executionInfo":{"status":"ok","timestamp":1715954062110,"user_tz":-60,"elapsed":48,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc","executionInfo":{"status":"ok","timestamp":1715954062110,"user_tz":-60,"elapsed":44,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def max_sequence_length_X_Y(data, tajweed_rule):\n","  X_raw = data['mfcc'].astype(str).tolist()\n","  Y_raw = data[tajweed_rule].astype(str).tolist()\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","  max_sequence_length_Y = max(len(seq) for seq in Y)\n","  max_sequence_length_X = max(len(seq) for seq in X)\n","  return max_sequence_length_X, max_sequence_length_Y"],"metadata":{"id":"H950tSVTMxlL","executionInfo":{"status":"ok","timestamp":1715954062111,"user_tz":-60,"elapsed":44,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule, max_X, max_Y):\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = reciter_data['mfcc'].astype(str).tolist()\n","  Y_raw = reciter_data[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data (X)\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","\n","  # Pad sequences in Y and X to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y, padding='post', dtype='int32', value=-1)\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O","executionInfo":{"status":"ok","timestamp":1715954062111,"user_tz":-60,"elapsed":43,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, not_exp, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","\n","  max_X, max_Y = max_sequence_length_X_Y(data, tajweed_rule)\n","\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule, max_X, max_Y)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule, max_X, max_Y)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule, max_X, max_Y)\n","  not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test = data_preparation(not_exp, tajweed_rule, max_X, max_Y)\n","\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3),\n","      (not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test, not_exp)]:\n","\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train, not_exp_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train, not_exp_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test, not_exp_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test, not_exp_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8","executionInfo":{"status":"ok","timestamp":1715954062111,"user_tz":-60,"elapsed":42,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["tajweed_rules = ['madd_6_Lazim', 'madd_246', 'madd_6', 'madd_2', 'Ikhfaa', 'Idgham', 'tafkhim', 'qalqala', 'imala']"],"metadata":{"id":"qpgV2OY8K09J","executionInfo":{"status":"ok","timestamp":1715954062112,"user_tz":-60,"elapsed":42,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, safa_data, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1715956396543,"user_tz":-60,"elapsed":2252854,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"d3aed0d9-23e9-4550-cb72-99a91ad92ee1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","27/27 [==============================] - 3s 86ms/step - loss: 89.8977 - accuracy: 0.8692 - val_loss: 2.9006 - val_accuracy: 0.9271\n","Epoch 2/50\n","27/27 [==============================] - 3s 117ms/step - loss: 11.7493 - accuracy: 0.9743 - val_loss: 2.8917 - val_accuracy: 0.9688\n","Epoch 3/50\n","27/27 [==============================] - 3s 115ms/step - loss: 10.0221 - accuracy: 0.9918 - val_loss: 2.8844 - val_accuracy: 0.9896\n","Epoch 4/50\n","27/27 [==============================] - 2s 73ms/step - loss: 9.7275 - accuracy: 0.9930 - val_loss: 2.8760 - val_accuracy: 0.9896\n","Epoch 5/50\n","27/27 [==============================] - 2s 73ms/step - loss: 9.6827 - accuracy: 0.9930 - val_loss: 2.8662 - val_accuracy: 0.9896\n","Epoch 6/50\n","27/27 [==============================] - 2s 72ms/step - loss: 9.6042 - accuracy: 0.9930 - val_loss: 2.8569 - val_accuracy: 0.9896\n","Epoch 7/50\n","27/27 [==============================] - 2s 71ms/step - loss: 9.5427 - accuracy: 0.9930 - val_loss: 2.8450 - val_accuracy: 0.9896\n","Epoch 8/50\n","27/27 [==============================] - 2s 72ms/step - loss: 9.5031 - accuracy: 0.9930 - val_loss: 2.8341 - val_accuracy: 0.9896\n","Epoch 9/50\n","27/27 [==============================] - 3s 97ms/step - loss: 9.4863 - accuracy: 0.9930 - val_loss: 2.8216 - val_accuracy: 0.9896\n","Epoch 10/50\n","27/27 [==============================] - 3s 99ms/step - loss: 9.4300 - accuracy: 0.9930 - val_loss: 2.8093 - val_accuracy: 0.9896\n","Epoch 11/50\n","27/27 [==============================] - 2s 78ms/step - loss: 9.3851 - accuracy: 0.9930 - val_loss: 2.7964 - val_accuracy: 0.9896\n","Epoch 12/50\n","27/27 [==============================] - 2s 71ms/step - loss: 9.4212 - accuracy: 0.9930 - val_loss: 2.7830 - val_accuracy: 0.9896\n","Epoch 13/50\n","27/27 [==============================] - 2s 70ms/step - loss: 9.6739 - accuracy: 0.9930 - val_loss: 2.7701 - val_accuracy: 0.9896\n","Epoch 14/50\n","27/27 [==============================] - 2s 72ms/step - loss: 10.1733 - accuracy: 0.9895 - val_loss: 2.7551 - val_accuracy: 0.9896\n","Epoch 15/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.6163 - accuracy: 0.9918 - val_loss: 2.7408 - val_accuracy: 0.9896\n","Epoch 16/50\n","27/27 [==============================] - 2s 92ms/step - loss: 11.6050 - accuracy: 0.9918 - val_loss: 2.7300 - val_accuracy: 0.9896\n","Epoch 17/50\n","27/27 [==============================] - 3s 107ms/step - loss: 11.5948 - accuracy: 0.9918 - val_loss: 2.7171 - val_accuracy: 0.9896\n","Epoch 18/50\n","27/27 [==============================] - 2s 80ms/step - loss: 11.5839 - accuracy: 0.9918 - val_loss: 2.7039 - val_accuracy: 0.9896\n","Epoch 19/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.5732 - accuracy: 0.9918 - val_loss: 2.6905 - val_accuracy: 0.9896\n","Epoch 20/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.5619 - accuracy: 0.9918 - val_loss: 2.6780 - val_accuracy: 0.9896\n","Epoch 21/50\n","27/27 [==============================] - 2s 74ms/step - loss: 11.5516 - accuracy: 0.9918 - val_loss: 2.6641 - val_accuracy: 0.9896\n","Epoch 22/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.5406 - accuracy: 0.9918 - val_loss: 2.6512 - val_accuracy: 0.9896\n","Epoch 23/50\n","27/27 [==============================] - 3s 100ms/step - loss: 11.5301 - accuracy: 0.9918 - val_loss: 2.6393 - val_accuracy: 0.9896\n","Epoch 24/50\n","27/27 [==============================] - 3s 103ms/step - loss: 11.5198 - accuracy: 0.9918 - val_loss: 2.6264 - val_accuracy: 0.9896\n","Epoch 25/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.5096 - accuracy: 0.9918 - val_loss: 2.6131 - val_accuracy: 0.9896\n","Epoch 26/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.4991 - accuracy: 0.9918 - val_loss: 2.6008 - val_accuracy: 0.9896\n","Epoch 27/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.4890 - accuracy: 0.9918 - val_loss: 2.5884 - val_accuracy: 0.9896\n","Epoch 28/50\n","27/27 [==============================] - 2s 74ms/step - loss: 11.4792 - accuracy: 0.9918 - val_loss: 2.5776 - val_accuracy: 0.9896\n","Epoch 29/50\n","27/27 [==============================] - 2s 72ms/step - loss: 11.4700 - accuracy: 0.9918 - val_loss: 2.5646 - val_accuracy: 0.9896\n","Epoch 30/50\n","27/27 [==============================] - 3s 94ms/step - loss: 11.4598 - accuracy: 0.9918 - val_loss: 2.5540 - val_accuracy: 0.9896\n","Epoch 31/50\n","27/27 [==============================] - 3s 118ms/step - loss: 11.4510 - accuracy: 0.9918 - val_loss: 2.5414 - val_accuracy: 0.9896\n","Epoch 32/50\n","27/27 [==============================] - 2s 78ms/step - loss: 11.4417 - accuracy: 0.9918 - val_loss: 2.5306 - val_accuracy: 0.9896\n","Epoch 33/50\n","27/27 [==============================] - 2s 74ms/step - loss: 11.4331 - accuracy: 0.9918 - val_loss: 2.5190 - val_accuracy: 0.9896\n","Epoch 34/50\n","27/27 [==============================] - 2s 71ms/step - loss: 11.4240 - accuracy: 0.9918 - val_loss: 2.5085 - val_accuracy: 0.9896\n","Epoch 35/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.4158 - accuracy: 0.9918 - val_loss: 2.4971 - val_accuracy: 0.9896\n","Epoch 36/50\n","27/27 [==============================] - 2s 71ms/step - loss: 11.4072 - accuracy: 0.9918 - val_loss: 2.4875 - val_accuracy: 0.9896\n","Epoch 37/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.3993 - accuracy: 0.9918 - val_loss: 2.4774 - val_accuracy: 0.9896\n","Epoch 38/50\n","27/27 [==============================] - 3s 103ms/step - loss: 11.3916 - accuracy: 0.9918 - val_loss: 2.4668 - val_accuracy: 0.9896\n","Epoch 39/50\n","27/27 [==============================] - 2s 77ms/step - loss: 11.3840 - accuracy: 0.9918 - val_loss: 2.4593 - val_accuracy: 0.9896\n","Epoch 40/50\n","27/27 [==============================] - 2s 72ms/step - loss: 11.3768 - accuracy: 0.9918 - val_loss: 2.4486 - val_accuracy: 0.9896\n","Epoch 41/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.3690 - accuracy: 0.9918 - val_loss: 2.4400 - val_accuracy: 0.9896\n","Epoch 42/50\n","27/27 [==============================] - 2s 75ms/step - loss: 11.3624 - accuracy: 0.9918 - val_loss: 2.4298 - val_accuracy: 0.9896\n","Epoch 43/50\n","27/27 [==============================] - 2s 72ms/step - loss: 11.3554 - accuracy: 0.9918 - val_loss: 2.4208 - val_accuracy: 0.9896\n","Epoch 44/50\n","27/27 [==============================] - 3s 95ms/step - loss: 11.3486 - accuracy: 0.9918 - val_loss: 2.4127 - val_accuracy: 0.9896\n","Epoch 45/50\n","27/27 [==============================] - 3s 104ms/step - loss: 11.3424 - accuracy: 0.9918 - val_loss: 2.4037 - val_accuracy: 0.9896\n","Epoch 46/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.3359 - accuracy: 0.9918 - val_loss: 2.3960 - val_accuracy: 0.9896\n","Epoch 47/50\n","27/27 [==============================] - 2s 72ms/step - loss: 11.3303 - accuracy: 0.9918 - val_loss: 2.3892 - val_accuracy: 0.9896\n","Epoch 48/50\n","27/27 [==============================] - 2s 71ms/step - loss: 11.3257 - accuracy: 0.9918 - val_loss: 2.3786 - val_accuracy: 0.9896\n","Epoch 49/50\n","27/27 [==============================] - 2s 71ms/step - loss: 11.3183 - accuracy: 0.9918 - val_loss: 2.3731 - val_accuracy: 0.9896\n","Epoch 50/50\n","27/27 [==============================] - 2s 71ms/step - loss: 11.3136 - accuracy: 0.9918 - val_loss: 2.3662 - val_accuracy: 0.9896\n","8/8 [==============================] - 0s 24ms/step\n","8/8 [==============================] - 0s 21ms/step - loss: 116.9364 - accuracy: 1.0000\n","Test Loss: 116.9364, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 4s 102ms/step - loss: 158.3073 - accuracy: 0.6659 - val_loss: 111.2556 - val_accuracy: 0.9375\n","Epoch 2/50\n","27/27 [==============================] - 2s 76ms/step - loss: 100.3785 - accuracy: 0.9498 - val_loss: 111.0061 - val_accuracy: 0.7188\n","Epoch 3/50\n","27/27 [==============================] - 2s 74ms/step - loss: 90.0979 - accuracy: 0.9124 - val_loss: 111.5812 - val_accuracy: 0.5417\n","Epoch 4/50\n","27/27 [==============================] - 2s 72ms/step - loss: 81.0025 - accuracy: 0.8890 - val_loss: 106.3673 - val_accuracy: 0.8333\n","Epoch 5/50\n","27/27 [==============================] - 2s 75ms/step - loss: 63.6251 - accuracy: 0.9229 - val_loss: 110.1436 - val_accuracy: 0.9583\n","Epoch 6/50\n","27/27 [==============================] - 3s 101ms/step - loss: 55.1689 - accuracy: 0.9252 - val_loss: 107.9017 - val_accuracy: 0.9271\n","Epoch 7/50\n","27/27 [==============================] - 3s 110ms/step - loss: 45.0546 - accuracy: 0.9100 - val_loss: 104.7060 - val_accuracy: 0.9583\n","Epoch 8/50\n","27/27 [==============================] - 2s 72ms/step - loss: 38.9705 - accuracy: 0.9334 - val_loss: 98.5956 - val_accuracy: 0.9479\n","Epoch 9/50\n","27/27 [==============================] - 2s 72ms/step - loss: 32.3027 - accuracy: 0.9171 - val_loss: 107.6350 - val_accuracy: 0.9583\n","Epoch 10/50\n","27/27 [==============================] - 2s 73ms/step - loss: 27.1862 - accuracy: 0.9357 - val_loss: 109.5470 - val_accuracy: 0.9583\n","Epoch 11/50\n","27/27 [==============================] - 2s 72ms/step - loss: 24.1206 - accuracy: 0.9252 - val_loss: 108.5745 - val_accuracy: 0.9583\n","Epoch 12/50\n","27/27 [==============================] - 2s 71ms/step - loss: 22.8602 - accuracy: 0.9206 - val_loss: 109.6728 - val_accuracy: 0.9479\n","Epoch 13/50\n","27/27 [==============================] - 3s 98ms/step - loss: 20.7926 - accuracy: 0.9252 - val_loss: 108.4490 - val_accuracy: 0.9583\n","Epoch 14/50\n","27/27 [==============================] - 3s 104ms/step - loss: 20.6265 - accuracy: 0.9112 - val_loss: 107.7266 - val_accuracy: 0.9479\n","Epoch 15/50\n","27/27 [==============================] - 2s 74ms/step - loss: 15.8719 - accuracy: 0.9171 - val_loss: 110.5501 - val_accuracy: 0.9271\n","Epoch 16/50\n","27/27 [==============================] - 2s 74ms/step - loss: 15.1508 - accuracy: 0.9171 - val_loss: 104.9979 - val_accuracy: 0.8958\n","Epoch 17/50\n","27/27 [==============================] - 2s 74ms/step - loss: 12.7163 - accuracy: 0.9030 - val_loss: 107.0653 - val_accuracy: 0.9375\n","Epoch 18/50\n","27/27 [==============================] - 2s 72ms/step - loss: 11.4014 - accuracy: 0.8995 - val_loss: 106.6958 - val_accuracy: 0.9375\n","Epoch 19/50\n","27/27 [==============================] - 2s 71ms/step - loss: 10.5711 - accuracy: 0.9054 - val_loss: 105.4419 - val_accuracy: 0.9062\n","Epoch 20/50\n","27/27 [==============================] - 4s 138ms/step - loss: 9.8647 - accuracy: 0.8890 - val_loss: 105.3870 - val_accuracy: 0.9375\n","Epoch 21/50\n","27/27 [==============================] - 4s 156ms/step - loss: 9.3315 - accuracy: 0.9042 - val_loss: 105.9327 - val_accuracy: 0.9271\n","Epoch 22/50\n","27/27 [==============================] - 3s 118ms/step - loss: 8.9194 - accuracy: 0.8995 - val_loss: 105.0471 - val_accuracy: 0.9479\n","Epoch 23/50\n","27/27 [==============================] - 2s 73ms/step - loss: 8.6411 - accuracy: 0.8925 - val_loss: 106.2290 - val_accuracy: 0.9479\n","Epoch 24/50\n","27/27 [==============================] - 2s 73ms/step - loss: 8.4826 - accuracy: 0.9136 - val_loss: 107.3785 - val_accuracy: 0.9271\n","Epoch 25/50\n","27/27 [==============================] - 2s 86ms/step - loss: 8.3276 - accuracy: 0.9007 - val_loss: 105.8409 - val_accuracy: 0.9479\n","Epoch 26/50\n","27/27 [==============================] - 3s 101ms/step - loss: 8.0967 - accuracy: 0.9030 - val_loss: 104.7106 - val_accuracy: 0.9271\n","Epoch 27/50\n","27/27 [==============================] - 3s 93ms/step - loss: 8.1888 - accuracy: 0.9030 - val_loss: 103.6520 - val_accuracy: 0.9271\n","Epoch 28/50\n","27/27 [==============================] - 2s 73ms/step - loss: 8.3025 - accuracy: 0.9147 - val_loss: 105.9270 - val_accuracy: 0.9271\n","Epoch 29/50\n","27/27 [==============================] - 2s 73ms/step - loss: 8.0960 - accuracy: 0.9065 - val_loss: 107.9209 - val_accuracy: 0.9479\n","Epoch 30/50\n","27/27 [==============================] - 2s 73ms/step - loss: 7.4734 - accuracy: 0.9077 - val_loss: 103.4818 - val_accuracy: 0.9479\n","Epoch 31/50\n","27/27 [==============================] - 2s 75ms/step - loss: 7.3544 - accuracy: 0.9206 - val_loss: 102.6380 - val_accuracy: 0.9271\n","Epoch 32/50\n","27/27 [==============================] - 2s 84ms/step - loss: 7.5393 - accuracy: 0.9007 - val_loss: 106.1858 - val_accuracy: 0.9479\n","Epoch 33/50\n","27/27 [==============================] - 3s 106ms/step - loss: 8.5276 - accuracy: 0.9241 - val_loss: 102.5349 - val_accuracy: 0.9479\n","Epoch 34/50\n","27/27 [==============================] - 3s 96ms/step - loss: 7.6608 - accuracy: 0.8960 - val_loss: 105.7927 - val_accuracy: 0.9479\n","Epoch 35/50\n","27/27 [==============================] - 2s 73ms/step - loss: 8.9845 - accuracy: 0.9112 - val_loss: 104.6764 - val_accuracy: 0.8854\n","Epoch 36/50\n","27/27 [==============================] - 2s 76ms/step - loss: 8.4446 - accuracy: 0.8960 - val_loss: 108.7244 - val_accuracy: 0.9583\n","Epoch 37/50\n","27/27 [==============================] - 2s 73ms/step - loss: 7.8815 - accuracy: 0.9229 - val_loss: 105.9819 - val_accuracy: 0.9375\n","Epoch 38/50\n","27/27 [==============================] - 2s 74ms/step - loss: 7.4512 - accuracy: 0.9007 - val_loss: 109.2271 - val_accuracy: 0.9479\n","Epoch 39/50\n","27/27 [==============================] - 2s 83ms/step - loss: 7.3229 - accuracy: 0.9042 - val_loss: 106.2075 - val_accuracy: 0.9479\n","Epoch 40/50\n","27/27 [==============================] - 3s 104ms/step - loss: 7.5851 - accuracy: 0.8972 - val_loss: 105.8176 - val_accuracy: 0.9375\n","Epoch 41/50\n","27/27 [==============================] - 2s 90ms/step - loss: 8.0892 - accuracy: 0.9019 - val_loss: 105.3255 - val_accuracy: 0.9479\n","Epoch 42/50\n","27/27 [==============================] - 2s 73ms/step - loss: 7.8056 - accuracy: 0.9065 - val_loss: 106.1271 - val_accuracy: 0.9479\n","Epoch 43/50\n","27/27 [==============================] - 2s 72ms/step - loss: 7.7882 - accuracy: 0.9182 - val_loss: 109.4373 - val_accuracy: 0.9375\n","Epoch 44/50\n","27/27 [==============================] - 2s 73ms/step - loss: 6.7782 - accuracy: 0.9124 - val_loss: 107.4628 - val_accuracy: 0.9479\n","Epoch 45/50\n","27/27 [==============================] - 2s 74ms/step - loss: 6.7452 - accuracy: 0.8995 - val_loss: 105.8434 - val_accuracy: 0.8750\n","Epoch 46/50\n","27/27 [==============================] - 2s 86ms/step - loss: 6.7580 - accuracy: 0.8902 - val_loss: 107.9351 - val_accuracy: 0.9479\n","Epoch 47/50\n","27/27 [==============================] - 3s 98ms/step - loss: 7.4425 - accuracy: 0.9159 - val_loss: 109.1694 - val_accuracy: 0.9479\n","Epoch 48/50\n","27/27 [==============================] - 3s 93ms/step - loss: 6.6411 - accuracy: 0.9030 - val_loss: 106.3208 - val_accuracy: 0.9375\n","Epoch 49/50\n","27/27 [==============================] - 2s 74ms/step - loss: 6.5285 - accuracy: 0.9147 - val_loss: 106.8901 - val_accuracy: 0.9479\n","Epoch 50/50\n","27/27 [==============================] - 2s 74ms/step - loss: 6.6201 - accuracy: 0.8960 - val_loss: 108.9316 - val_accuracy: 0.9479\n","8/8 [==============================] - 0s 17ms/step\n","8/8 [==============================] - 0s 15ms/step - loss: 654.1515 - accuracy: 0.9917\n","Test Loss: 654.1515, Test accuracy : 0.9917\n","Epoch 1/50\n","27/27 [==============================] - 3s 83ms/step - loss: 71.4101 - accuracy: 0.1659 - val_loss: 16.6644 - val_accuracy: 0.1354\n","Epoch 2/50\n","27/27 [==============================] - 2s 74ms/step - loss: 26.5269 - accuracy: 0.1519 - val_loss: 16.4442 - val_accuracy: 0.1250\n","Epoch 3/50\n","27/27 [==============================] - 2s 88ms/step - loss: 22.0691 - accuracy: 0.1706 - val_loss: 16.4353 - val_accuracy: 0.1146\n","Epoch 4/50\n","27/27 [==============================] - 3s 104ms/step - loss: 19.0284 - accuracy: 0.1495 - val_loss: 16.9295 - val_accuracy: 0.1771\n","Epoch 5/50\n","27/27 [==============================] - 3s 92ms/step - loss: 17.8117 - accuracy: 0.1519 - val_loss: 16.5668 - val_accuracy: 0.1667\n","Epoch 6/50\n","27/27 [==============================] - 2s 74ms/step - loss: 17.7035 - accuracy: 0.1449 - val_loss: 16.6523 - val_accuracy: 0.1562\n","Epoch 7/50\n","27/27 [==============================] - 2s 74ms/step - loss: 17.1358 - accuracy: 0.1414 - val_loss: 16.3244 - val_accuracy: 0.1771\n","Epoch 8/50\n","27/27 [==============================] - 2s 73ms/step - loss: 15.0799 - accuracy: 0.1367 - val_loss: 24.0205 - val_accuracy: 0.0938\n","Epoch 9/50\n","27/27 [==============================] - 2s 73ms/step - loss: 15.2761 - accuracy: 0.1402 - val_loss: 15.8541 - val_accuracy: 0.1771\n","Epoch 10/50\n","27/27 [==============================] - 3s 95ms/step - loss: 14.7141 - accuracy: 0.1565 - val_loss: 15.6167 - val_accuracy: 0.2083\n","Epoch 11/50\n","27/27 [==============================] - 3s 128ms/step - loss: 16.1318 - accuracy: 0.1355 - val_loss: 17.4352 - val_accuracy: 0.1771\n","Epoch 12/50\n","27/27 [==============================] - 4s 142ms/step - loss: 17.3249 - accuracy: 0.1320 - val_loss: 17.7158 - val_accuracy: 0.1042\n","Epoch 13/50\n","27/27 [==============================] - 2s 73ms/step - loss: 24.4799 - accuracy: 0.1343 - val_loss: 16.1653 - val_accuracy: 0.1771\n","Epoch 14/50\n","27/27 [==============================] - 2s 73ms/step - loss: 22.4597 - accuracy: 0.1332 - val_loss: 16.6248 - val_accuracy: 0.1875\n","Epoch 15/50\n","27/27 [==============================] - 2s 73ms/step - loss: 18.5471 - accuracy: 0.1262 - val_loss: 16.5922 - val_accuracy: 0.1771\n","Epoch 16/50\n","27/27 [==============================] - 2s 75ms/step - loss: 16.7370 - accuracy: 0.1449 - val_loss: 16.5961 - val_accuracy: 0.1771\n","Epoch 17/50\n","27/27 [==============================] - 2s 88ms/step - loss: 14.3449 - accuracy: 0.1379 - val_loss: 16.1980 - val_accuracy: 0.2188\n","Epoch 18/50\n","27/27 [==============================] - 3s 109ms/step - loss: 17.3238 - accuracy: 0.1273 - val_loss: 16.5306 - val_accuracy: 0.1771\n","Epoch 19/50\n","27/27 [==============================] - 3s 94ms/step - loss: 14.8972 - accuracy: 0.1308 - val_loss: 16.2166 - val_accuracy: 0.1771\n","Epoch 20/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.2382 - accuracy: 0.1180 - val_loss: 16.4926 - val_accuracy: 0.1771\n","Epoch 21/50\n","27/27 [==============================] - 2s 76ms/step - loss: 16.0625 - accuracy: 0.1285 - val_loss: 16.4727 - val_accuracy: 0.1771\n","Epoch 22/50\n","27/27 [==============================] - 2s 75ms/step - loss: 11.0042 - accuracy: 0.1273 - val_loss: 16.5223 - val_accuracy: 0.1771\n","Epoch 23/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.7010 - accuracy: 0.1379 - val_loss: 16.5280 - val_accuracy: 0.1771\n","Epoch 24/50\n","27/27 [==============================] - 2s 90ms/step - loss: 12.3220 - accuracy: 0.1484 - val_loss: 16.4676 - val_accuracy: 0.1771\n","Epoch 25/50\n","27/27 [==============================] - 3s 107ms/step - loss: 11.7960 - accuracy: 0.1355 - val_loss: 16.6269 - val_accuracy: 0.1771\n","Epoch 26/50\n","27/27 [==============================] - 2s 85ms/step - loss: 11.1524 - accuracy: 0.1390 - val_loss: 16.3995 - val_accuracy: 0.1771\n","Epoch 27/50\n","27/27 [==============================] - 2s 74ms/step - loss: 10.8761 - accuracy: 0.5654 - val_loss: 16.5194 - val_accuracy: 0.7604\n","Epoch 28/50\n","27/27 [==============================] - 2s 75ms/step - loss: 10.7805 - accuracy: 0.8703 - val_loss: 16.3741 - val_accuracy: 0.8021\n","Epoch 29/50\n","27/27 [==============================] - 2s 75ms/step - loss: 10.6867 - accuracy: 0.8586 - val_loss: 16.9269 - val_accuracy: 0.7292\n","Epoch 30/50\n","27/27 [==============================] - 2s 75ms/step - loss: 10.5626 - accuracy: 0.8610 - val_loss: 16.3535 - val_accuracy: 0.7917\n","Epoch 31/50\n","27/27 [==============================] - 2s 93ms/step - loss: 11.6121 - accuracy: 0.8563 - val_loss: 16.7330 - val_accuracy: 0.7188\n","Epoch 32/50\n","27/27 [==============================] - 3s 104ms/step - loss: 13.7310 - accuracy: 0.8481 - val_loss: 16.3318 - val_accuracy: 0.8021\n","Epoch 33/50\n","27/27 [==============================] - 2s 81ms/step - loss: 14.7441 - accuracy: 0.8563 - val_loss: 15.4221 - val_accuracy: 0.8021\n","Epoch 34/50\n","27/27 [==============================] - 2s 72ms/step - loss: 12.7317 - accuracy: 0.8470 - val_loss: 16.2183 - val_accuracy: 0.8021\n","Epoch 35/50\n","27/27 [==============================] - 2s 73ms/step - loss: 11.5996 - accuracy: 0.8493 - val_loss: 15.9052 - val_accuracy: 0.8021\n","Epoch 36/50\n","27/27 [==============================] - 2s 74ms/step - loss: 10.0778 - accuracy: 0.8540 - val_loss: 15.2291 - val_accuracy: 0.7708\n","Epoch 37/50\n","27/27 [==============================] - 2s 74ms/step - loss: 9.6417 - accuracy: 0.8914 - val_loss: 15.4542 - val_accuracy: 0.8021\n","Epoch 38/50\n","27/27 [==============================] - 3s 94ms/step - loss: 9.1187 - accuracy: 0.8715 - val_loss: 15.7417 - val_accuracy: 0.7812\n","Epoch 39/50\n","27/27 [==============================] - 3s 105ms/step - loss: 8.6898 - accuracy: 0.8762 - val_loss: 15.6534 - val_accuracy: 0.8229\n","Epoch 40/50\n","27/27 [==============================] - 2s 78ms/step - loss: 8.9819 - accuracy: 0.8808 - val_loss: 15.6208 - val_accuracy: 0.7188\n","Epoch 41/50\n","27/27 [==============================] - 2s 76ms/step - loss: 8.9897 - accuracy: 0.8937 - val_loss: 15.5747 - val_accuracy: 0.8229\n","Epoch 42/50\n","27/27 [==============================] - 2s 75ms/step - loss: 9.0461 - accuracy: 0.9112 - val_loss: 15.5513 - val_accuracy: 0.8125\n","Epoch 43/50\n","27/27 [==============================] - 2s 75ms/step - loss: 8.2889 - accuracy: 0.9054 - val_loss: 15.6277 - val_accuracy: 0.7917\n","Epoch 44/50\n","27/27 [==============================] - 2s 75ms/step - loss: 8.0138 - accuracy: 0.9217 - val_loss: 15.6313 - val_accuracy: 0.8021\n","Epoch 45/50\n","27/27 [==============================] - 3s 104ms/step - loss: 8.5598 - accuracy: 0.9089 - val_loss: 15.6486 - val_accuracy: 0.7917\n","Epoch 46/50\n","27/27 [==============================] - 3s 106ms/step - loss: 8.3983 - accuracy: 0.9100 - val_loss: 15.5638 - val_accuracy: 0.8125\n","Epoch 47/50\n","27/27 [==============================] - 2s 77ms/step - loss: 7.9865 - accuracy: 0.9159 - val_loss: 15.5274 - val_accuracy: 0.7917\n","Epoch 48/50\n","27/27 [==============================] - 2s 75ms/step - loss: 7.9258 - accuracy: 0.9112 - val_loss: 15.5532 - val_accuracy: 0.8125\n","Epoch 49/50\n","27/27 [==============================] - 2s 74ms/step - loss: 7.7389 - accuracy: 0.9241 - val_loss: 15.4409 - val_accuracy: 0.7812\n","Epoch 50/50\n","27/27 [==============================] - 2s 73ms/step - loss: 7.7729 - accuracy: 0.9159 - val_loss: 15.5303 - val_accuracy: 0.8021\n","8/8 [==============================] - 0s 19ms/step\n","8/8 [==============================] - 0s 14ms/step - loss: 126.5052 - accuracy: 0.9625\n","Test Loss: 126.5052, Test accuracy : 0.9625\n","Epoch 1/50\n","27/27 [==============================] - 3s 82ms/step - loss: 100.6211 - accuracy: 0.4147 - val_loss: 34.6226 - val_accuracy: 0.5729\n","Epoch 2/50\n","27/27 [==============================] - 2s 91ms/step - loss: 56.1341 - accuracy: 0.7208 - val_loss: 32.4991 - val_accuracy: 0.7292\n","Epoch 3/50\n","27/27 [==============================] - 3s 104ms/step - loss: 47.7586 - accuracy: 0.7535 - val_loss: 35.5447 - val_accuracy: 0.8750\n","Epoch 4/50\n","27/27 [==============================] - 2s 85ms/step - loss: 43.5409 - accuracy: 0.7792 - val_loss: 33.4078 - val_accuracy: 0.6042\n","Epoch 5/50\n","27/27 [==============================] - 2s 75ms/step - loss: 39.9894 - accuracy: 0.9299 - val_loss: 31.6118 - val_accuracy: 0.9792\n","Epoch 6/50\n","27/27 [==============================] - 2s 76ms/step - loss: 35.0333 - accuracy: 0.9241 - val_loss: 29.5509 - val_accuracy: 0.9583\n","Epoch 7/50\n","27/27 [==============================] - 2s 77ms/step - loss: 31.6127 - accuracy: 0.9428 - val_loss: 28.9932 - val_accuracy: 0.9583\n","Epoch 8/50\n","27/27 [==============================] - 2s 77ms/step - loss: 29.5512 - accuracy: 0.9416 - val_loss: 30.0509 - val_accuracy: 0.9792\n","Epoch 9/50\n","27/27 [==============================] - 3s 101ms/step - loss: 27.6331 - accuracy: 0.9217 - val_loss: 30.7171 - val_accuracy: 0.9583\n","Epoch 10/50\n","27/27 [==============================] - 3s 106ms/step - loss: 24.8430 - accuracy: 0.9568 - val_loss: 28.9019 - val_accuracy: 0.9792\n","Epoch 11/50\n","27/27 [==============================] - 2s 80ms/step - loss: 22.8723 - accuracy: 0.9509 - val_loss: 29.1435 - val_accuracy: 0.9792\n","Epoch 12/50\n","27/27 [==============================] - 2s 75ms/step - loss: 21.7872 - accuracy: 0.9416 - val_loss: 29.0053 - val_accuracy: 0.9792\n","Epoch 13/50\n","27/27 [==============================] - 2s 76ms/step - loss: 20.0684 - accuracy: 0.9626 - val_loss: 28.4233 - val_accuracy: 0.9792\n","Epoch 14/50\n","27/27 [==============================] - 2s 77ms/step - loss: 19.1149 - accuracy: 0.9498 - val_loss: 27.9163 - val_accuracy: 0.9792\n","Epoch 15/50\n","27/27 [==============================] - 2s 75ms/step - loss: 17.8064 - accuracy: 0.9451 - val_loss: 28.8289 - val_accuracy: 0.9792\n","Epoch 16/50\n","27/27 [==============================] - 3s 100ms/step - loss: 16.7175 - accuracy: 0.9591 - val_loss: 27.6467 - val_accuracy: 0.9792\n","Epoch 17/50\n","27/27 [==============================] - 3s 111ms/step - loss: 16.2704 - accuracy: 0.9486 - val_loss: 31.5385 - val_accuracy: 0.9792\n","Epoch 18/50\n","27/27 [==============================] - 2s 81ms/step - loss: 16.1920 - accuracy: 0.9568 - val_loss: 27.6066 - val_accuracy: 0.9792\n","Epoch 19/50\n","27/27 [==============================] - 2s 75ms/step - loss: 15.7174 - accuracy: 0.9533 - val_loss: 30.0596 - val_accuracy: 0.9792\n","Epoch 20/50\n","27/27 [==============================] - 2s 77ms/step - loss: 15.2793 - accuracy: 0.9579 - val_loss: 26.3332 - val_accuracy: 0.9792\n","Epoch 21/50\n","27/27 [==============================] - 2s 92ms/step - loss: 15.6588 - accuracy: 0.9603 - val_loss: 27.3078 - val_accuracy: 0.9792\n","Epoch 22/50\n","27/27 [==============================] - 3s 94ms/step - loss: 14.5167 - accuracy: 0.9439 - val_loss: 34.8716 - val_accuracy: 0.9792\n","Epoch 23/50\n","27/27 [==============================] - 3s 111ms/step - loss: 17.8238 - accuracy: 0.9509 - val_loss: 33.0798 - val_accuracy: 0.9792\n","Epoch 24/50\n","27/27 [==============================] - 3s 98ms/step - loss: 15.7790 - accuracy: 0.9591 - val_loss: 27.9311 - val_accuracy: 0.9792\n","Epoch 25/50\n","27/27 [==============================] - 2s 74ms/step - loss: 15.0578 - accuracy: 0.9591 - val_loss: 30.8490 - val_accuracy: 0.9792\n","Epoch 26/50\n","27/27 [==============================] - 2s 76ms/step - loss: 14.8769 - accuracy: 0.9626 - val_loss: 29.4685 - val_accuracy: 0.9792\n","Epoch 27/50\n","27/27 [==============================] - 2s 74ms/step - loss: 14.2217 - accuracy: 0.9720 - val_loss: 31.1310 - val_accuracy: 0.9792\n","Epoch 28/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.9095 - accuracy: 0.9673 - val_loss: 28.0438 - val_accuracy: 0.9792\n","Epoch 29/50\n","27/27 [==============================] - 2s 87ms/step - loss: 13.3566 - accuracy: 0.9743 - val_loss: 30.9547 - val_accuracy: 0.9792\n","Epoch 30/50\n","27/27 [==============================] - 3s 107ms/step - loss: 13.3516 - accuracy: 0.9638 - val_loss: 27.7741 - val_accuracy: 0.9792\n","Epoch 31/50\n","27/27 [==============================] - 2s 89ms/step - loss: 13.0905 - accuracy: 0.9708 - val_loss: 29.2940 - val_accuracy: 0.9792\n","Epoch 32/50\n","27/27 [==============================] - 2s 77ms/step - loss: 12.7164 - accuracy: 0.9755 - val_loss: 28.9297 - val_accuracy: 0.9792\n","Epoch 33/50\n","27/27 [==============================] - 2s 74ms/step - loss: 12.8574 - accuracy: 0.9755 - val_loss: 29.3657 - val_accuracy: 0.9792\n","Epoch 34/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.1992 - accuracy: 0.9743 - val_loss: 28.2880 - val_accuracy: 0.9792\n","Epoch 35/50\n","27/27 [==============================] - 2s 74ms/step - loss: 13.2839 - accuracy: 0.9696 - val_loss: 28.6600 - val_accuracy: 0.9792\n","Epoch 36/50\n","27/27 [==============================] - 2s 92ms/step - loss: 12.3685 - accuracy: 0.9731 - val_loss: 28.5442 - val_accuracy: 0.9792\n","Epoch 37/50\n","27/27 [==============================] - 3s 105ms/step - loss: 12.2393 - accuracy: 0.9708 - val_loss: 29.0223 - val_accuracy: 0.9792\n","Epoch 38/50\n","27/27 [==============================] - 2s 87ms/step - loss: 12.1780 - accuracy: 0.9731 - val_loss: 28.4708 - val_accuracy: 0.9792\n","Epoch 39/50\n","27/27 [==============================] - 2s 74ms/step - loss: 12.3238 - accuracy: 0.9661 - val_loss: 29.2786 - val_accuracy: 0.9792\n","Epoch 40/50\n","27/27 [==============================] - 2s 76ms/step - loss: 12.3268 - accuracy: 0.9731 - val_loss: 28.6353 - val_accuracy: 0.9792\n","Epoch 41/50\n","27/27 [==============================] - 2s 74ms/step - loss: 12.5190 - accuracy: 0.9685 - val_loss: 31.3693 - val_accuracy: 0.9792\n","Epoch 42/50\n","27/27 [==============================] - 2s 73ms/step - loss: 12.5422 - accuracy: 0.9755 - val_loss: 29.1727 - val_accuracy: 0.9792\n","Epoch 43/50\n","27/27 [==============================] - 3s 100ms/step - loss: 12.7835 - accuracy: 0.9696 - val_loss: 28.2637 - val_accuracy: 0.9792\n","Epoch 44/50\n","27/27 [==============================] - 3s 107ms/step - loss: 13.0532 - accuracy: 0.9743 - val_loss: 27.6157 - val_accuracy: 0.9792\n","Epoch 45/50\n","27/27 [==============================] - 2s 80ms/step - loss: 14.0025 - accuracy: 0.9766 - val_loss: 28.5413 - val_accuracy: 0.9792\n","Epoch 46/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.9644 - accuracy: 0.9743 - val_loss: 29.2011 - val_accuracy: 0.9792\n","Epoch 47/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.2667 - accuracy: 0.9731 - val_loss: 28.5324 - val_accuracy: 0.9792\n","Epoch 48/50\n","27/27 [==============================] - 2s 75ms/step - loss: 13.1544 - accuracy: 0.9720 - val_loss: 29.8610 - val_accuracy: 0.9792\n","Epoch 49/50\n","27/27 [==============================] - 2s 89ms/step - loss: 13.1375 - accuracy: 0.9731 - val_loss: 29.4048 - val_accuracy: 0.9896\n","Epoch 50/50\n","27/27 [==============================] - 5s 170ms/step - loss: 13.7078 - accuracy: 0.9731 - val_loss: 29.1967 - val_accuracy: 0.9792\n","8/8 [==============================] - 0s 21ms/step\n","8/8 [==============================] - 0s 28ms/step - loss: 45.7938 - accuracy: 1.0000\n","Test Loss: 45.7938, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 4s 120ms/step - loss: 89.0907 - accuracy: 0.1939 - val_loss: 63.4601 - val_accuracy: 0.4062\n","Epoch 2/50\n","27/27 [==============================] - 3s 101ms/step - loss: 57.6434 - accuracy: 0.4638 - val_loss: 62.8523 - val_accuracy: 0.3750\n","Epoch 3/50\n","27/27 [==============================] - 2s 73ms/step - loss: 53.7776 - accuracy: 0.4369 - val_loss: 62.0637 - val_accuracy: 0.4896\n","Epoch 4/50\n","27/27 [==============================] - 2s 76ms/step - loss: 52.1034 - accuracy: 0.5479 - val_loss: 61.9895 - val_accuracy: 0.6042\n","Epoch 5/50\n","27/27 [==============================] - 2s 76ms/step - loss: 46.8077 - accuracy: 0.5526 - val_loss: 61.0400 - val_accuracy: 0.6458\n","Epoch 6/50\n","27/27 [==============================] - 2s 74ms/step - loss: 42.3489 - accuracy: 0.5841 - val_loss: 60.8715 - val_accuracy: 0.6354\n","Epoch 7/50\n","27/27 [==============================] - 2s 80ms/step - loss: 38.1670 - accuracy: 0.5993 - val_loss: 60.3485 - val_accuracy: 0.6458\n","Epoch 8/50\n","27/27 [==============================] - 3s 104ms/step - loss: 35.0233 - accuracy: 0.6180 - val_loss: 59.8724 - val_accuracy: 0.6562\n","Epoch 9/50\n","27/27 [==============================] - 3s 100ms/step - loss: 32.1274 - accuracy: 0.6472 - val_loss: 57.6904 - val_accuracy: 0.6354\n","Epoch 10/50\n","27/27 [==============================] - 2s 75ms/step - loss: 30.0135 - accuracy: 0.6414 - val_loss: 58.3786 - val_accuracy: 0.6458\n","Epoch 11/50\n","27/27 [==============================] - 2s 76ms/step - loss: 29.0324 - accuracy: 0.6519 - val_loss: 58.4817 - val_accuracy: 0.6354\n","Epoch 12/50\n","27/27 [==============================] - 2s 76ms/step - loss: 27.6985 - accuracy: 0.6425 - val_loss: 57.8613 - val_accuracy: 0.6458\n","Epoch 13/50\n","27/27 [==============================] - 2s 75ms/step - loss: 27.4313 - accuracy: 0.6425 - val_loss: 58.3269 - val_accuracy: 0.6458\n","Epoch 14/50\n","27/27 [==============================] - 2s 82ms/step - loss: 25.6696 - accuracy: 0.6647 - val_loss: 58.0115 - val_accuracy: 0.6458\n","Epoch 15/50\n","27/27 [==============================] - 3s 105ms/step - loss: 24.5989 - accuracy: 0.6612 - val_loss: 59.4623 - val_accuracy: 0.6458\n","Epoch 16/50\n","27/27 [==============================] - 3s 95ms/step - loss: 24.2021 - accuracy: 0.6612 - val_loss: 58.5489 - val_accuracy: 0.6458\n","Epoch 17/50\n","27/27 [==============================] - 2s 75ms/step - loss: 24.0441 - accuracy: 0.6554 - val_loss: 58.3694 - val_accuracy: 0.6458\n","Epoch 18/50\n","27/27 [==============================] - 2s 74ms/step - loss: 22.7615 - accuracy: 0.6694 - val_loss: 58.3252 - val_accuracy: 0.6458\n","Epoch 19/50\n","27/27 [==============================] - 2s 73ms/step - loss: 22.5268 - accuracy: 0.6729 - val_loss: 58.2947 - val_accuracy: 0.6458\n","Epoch 20/50\n","27/27 [==============================] - 2s 74ms/step - loss: 22.4064 - accuracy: 0.6624 - val_loss: 58.2252 - val_accuracy: 0.6458\n","Epoch 21/50\n","27/27 [==============================] - 2s 87ms/step - loss: 21.8029 - accuracy: 0.6647 - val_loss: 58.2644 - val_accuracy: 0.6458\n","Epoch 22/50\n","27/27 [==============================] - 3s 110ms/step - loss: 21.6343 - accuracy: 0.6659 - val_loss: 58.2367 - val_accuracy: 0.6458\n","Epoch 23/50\n","27/27 [==============================] - 3s 95ms/step - loss: 21.4471 - accuracy: 0.6624 - val_loss: 57.6592 - val_accuracy: 0.6458\n","Epoch 24/50\n","27/27 [==============================] - 2s 74ms/step - loss: 21.0792 - accuracy: 0.6624 - val_loss: 57.7595 - val_accuracy: 0.6458\n","Epoch 25/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.0801 - accuracy: 0.6682 - val_loss: 57.6315 - val_accuracy: 0.6458\n","Epoch 26/50\n","27/27 [==============================] - 2s 75ms/step - loss: 21.4635 - accuracy: 0.6741 - val_loss: 58.1804 - val_accuracy: 0.6458\n","Epoch 27/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.7140 - accuracy: 0.6729 - val_loss: 58.0610 - val_accuracy: 0.6458\n","Epoch 28/50\n","27/27 [==============================] - 2s 91ms/step - loss: 20.9922 - accuracy: 0.6659 - val_loss: 58.5310 - val_accuracy: 0.6458\n","Epoch 29/50\n","27/27 [==============================] - 3s 106ms/step - loss: 20.7478 - accuracy: 0.6706 - val_loss: 58.1704 - val_accuracy: 0.6458\n","Epoch 30/50\n","27/27 [==============================] - 3s 93ms/step - loss: 20.4166 - accuracy: 0.6776 - val_loss: 58.4243 - val_accuracy: 0.6458\n","Epoch 31/50\n","27/27 [==============================] - 2s 74ms/step - loss: 20.3670 - accuracy: 0.6764 - val_loss: 57.2067 - val_accuracy: 0.6458\n","Epoch 32/50\n","27/27 [==============================] - 2s 74ms/step - loss: 20.1518 - accuracy: 0.6776 - val_loss: 58.5240 - val_accuracy: 0.6458\n","Epoch 33/50\n","27/27 [==============================] - 2s 73ms/step - loss: 20.7987 - accuracy: 0.6869 - val_loss: 57.7358 - val_accuracy: 0.6458\n","Epoch 34/50\n","27/27 [==============================] - 2s 75ms/step - loss: 22.0712 - accuracy: 0.6904 - val_loss: 61.4469 - val_accuracy: 0.6458\n","Epoch 35/50\n","27/27 [==============================] - 2s 87ms/step - loss: 22.5539 - accuracy: 0.6834 - val_loss: 56.1191 - val_accuracy: 0.6354\n","Epoch 36/50\n","27/27 [==============================] - 3s 105ms/step - loss: 22.4477 - accuracy: 0.6857 - val_loss: 61.7754 - val_accuracy: 0.6458\n","Epoch 37/50\n","27/27 [==============================] - 3s 99ms/step - loss: 22.3660 - accuracy: 0.6822 - val_loss: 57.0246 - val_accuracy: 0.6458\n","Epoch 38/50\n","27/27 [==============================] - 2s 75ms/step - loss: 21.7057 - accuracy: 0.6857 - val_loss: 58.7082 - val_accuracy: 0.6458\n","Epoch 39/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.2805 - accuracy: 0.6682 - val_loss: 58.1428 - val_accuracy: 0.5938\n","Epoch 40/50\n","27/27 [==============================] - 2s 76ms/step - loss: 20.4067 - accuracy: 0.6682 - val_loss: 57.7714 - val_accuracy: 0.6458\n","Epoch 41/50\n","27/27 [==============================] - 2s 74ms/step - loss: 19.9539 - accuracy: 0.6694 - val_loss: 58.9608 - val_accuracy: 0.6250\n","Epoch 42/50\n","27/27 [==============================] - 2s 88ms/step - loss: 19.3178 - accuracy: 0.6811 - val_loss: 58.4959 - val_accuracy: 0.6458\n","Epoch 43/50\n","27/27 [==============================] - 3s 117ms/step - loss: 19.4141 - accuracy: 0.6752 - val_loss: 58.4023 - val_accuracy: 0.6458\n","Epoch 44/50\n","27/27 [==============================] - 3s 97ms/step - loss: 19.1390 - accuracy: 0.6741 - val_loss: 58.3192 - val_accuracy: 0.6458\n","Epoch 45/50\n","27/27 [==============================] - 2s 76ms/step - loss: 18.9771 - accuracy: 0.6811 - val_loss: 57.9026 - val_accuracy: 0.6458\n","Epoch 46/50\n","27/27 [==============================] - 2s 74ms/step - loss: 18.7353 - accuracy: 0.6822 - val_loss: 58.3385 - val_accuracy: 0.6458\n","Epoch 47/50\n","27/27 [==============================] - 2s 75ms/step - loss: 18.6362 - accuracy: 0.6822 - val_loss: 57.8502 - val_accuracy: 0.6354\n","Epoch 48/50\n","27/27 [==============================] - 2s 74ms/step - loss: 18.5708 - accuracy: 0.6799 - val_loss: 58.1422 - val_accuracy: 0.6458\n","Epoch 49/50\n","27/27 [==============================] - 2s 87ms/step - loss: 18.5695 - accuracy: 0.6799 - val_loss: 57.8133 - val_accuracy: 0.6458\n","Epoch 50/50\n","27/27 [==============================] - 3s 104ms/step - loss: 18.5053 - accuracy: 0.6776 - val_loss: 58.1991 - val_accuracy: 0.6250\n","8/8 [==============================] - 0s 16ms/step\n","8/8 [==============================] - 0s 20ms/step - loss: 507.0646 - accuracy: 0.9833\n","Test Loss: 507.0646, Test accuracy : 0.9833\n","Epoch 1/50\n","27/27 [==============================] - 3s 82ms/step - loss: 59.3110 - accuracy: 0.2500 - val_loss: 38.2773 - val_accuracy: 0.1146\n","Epoch 2/50\n","27/27 [==============================] - 2s 77ms/step - loss: 35.8116 - accuracy: 0.3341 - val_loss: 37.6874 - val_accuracy: 0.1146\n","Epoch 3/50\n","27/27 [==============================] - 2s 85ms/step - loss: 34.9883 - accuracy: 0.3318 - val_loss: 37.6812 - val_accuracy: 0.1042\n","Epoch 4/50\n","27/27 [==============================] - 3s 107ms/step - loss: 33.2315 - accuracy: 0.3750 - val_loss: 37.6077 - val_accuracy: 0.1146\n","Epoch 5/50\n","27/27 [==============================] - 3s 103ms/step - loss: 31.8582 - accuracy: 0.3306 - val_loss: 36.9825 - val_accuracy: 0.1146\n","Epoch 6/50\n","27/27 [==============================] - 2s 77ms/step - loss: 30.6907 - accuracy: 0.3879 - val_loss: 37.1611 - val_accuracy: 0.1042\n","Epoch 7/50\n","27/27 [==============================] - 2s 75ms/step - loss: 29.7755 - accuracy: 0.3972 - val_loss: 36.8792 - val_accuracy: 0.1146\n","Epoch 8/50\n","27/27 [==============================] - 2s 76ms/step - loss: 28.9500 - accuracy: 0.4871 - val_loss: 35.4685 - val_accuracy: 0.7604\n","Epoch 9/50\n","27/27 [==============================] - 2s 76ms/step - loss: 27.3134 - accuracy: 0.6963 - val_loss: 34.3085 - val_accuracy: 0.7083\n","Epoch 10/50\n","27/27 [==============================] - 2s 81ms/step - loss: 25.5632 - accuracy: 0.6834 - val_loss: 33.2386 - val_accuracy: 0.7083\n","Epoch 11/50\n","27/27 [==============================] - 3s 104ms/step - loss: 24.5294 - accuracy: 0.7161 - val_loss: 32.3623 - val_accuracy: 0.5521\n","Epoch 12/50\n","27/27 [==============================] - 3s 99ms/step - loss: 23.5624 - accuracy: 0.6998 - val_loss: 33.3136 - val_accuracy: 0.7292\n","Epoch 13/50\n","27/27 [==============================] - 2s 78ms/step - loss: 23.0603 - accuracy: 0.7161 - val_loss: 34.8871 - val_accuracy: 0.7500\n","Epoch 14/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.9493 - accuracy: 0.7687 - val_loss: 32.4426 - val_accuracy: 0.6354\n","Epoch 15/50\n","27/27 [==============================] - 2s 74ms/step - loss: 21.1858 - accuracy: 0.7605 - val_loss: 33.1961 - val_accuracy: 0.6354\n","Epoch 16/50\n","27/27 [==============================] - 2s 77ms/step - loss: 20.5659 - accuracy: 0.7687 - val_loss: 33.1088 - val_accuracy: 0.6146\n","Epoch 17/50\n","27/27 [==============================] - 2s 92ms/step - loss: 20.2635 - accuracy: 0.7722 - val_loss: 32.7937 - val_accuracy: 0.6562\n","Epoch 18/50\n","27/27 [==============================] - 3s 110ms/step - loss: 20.0037 - accuracy: 0.7850 - val_loss: 32.7219 - val_accuracy: 0.6458\n","Epoch 19/50\n","27/27 [==============================] - 3s 96ms/step - loss: 19.6560 - accuracy: 0.7839 - val_loss: 32.9035 - val_accuracy: 0.6562\n","Epoch 20/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.4359 - accuracy: 0.7839 - val_loss: 32.8400 - val_accuracy: 0.6667\n","Epoch 21/50\n","27/27 [==============================] - 2s 78ms/step - loss: 19.3003 - accuracy: 0.7944 - val_loss: 32.4578 - val_accuracy: 0.6771\n","Epoch 22/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.2476 - accuracy: 0.7979 - val_loss: 32.6195 - val_accuracy: 0.6875\n","Epoch 23/50\n","27/27 [==============================] - 2s 73ms/step - loss: 19.0921 - accuracy: 0.8002 - val_loss: 32.3258 - val_accuracy: 0.7396\n","Epoch 24/50\n","27/27 [==============================] - 3s 95ms/step - loss: 19.0401 - accuracy: 0.8072 - val_loss: 32.6099 - val_accuracy: 0.7396\n","Epoch 25/50\n","27/27 [==============================] - 3s 98ms/step - loss: 19.0250 - accuracy: 0.8166 - val_loss: 32.1600 - val_accuracy: 0.7396\n","Epoch 26/50\n","27/27 [==============================] - 3s 111ms/step - loss: 18.9502 - accuracy: 0.8037 - val_loss: 32.1117 - val_accuracy: 0.7604\n","Epoch 27/50\n","27/27 [==============================] - 2s 78ms/step - loss: 19.0124 - accuracy: 0.8061 - val_loss: 32.4676 - val_accuracy: 0.8125\n","Epoch 28/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.0638 - accuracy: 0.8072 - val_loss: 32.6703 - val_accuracy: 0.8125\n","Epoch 29/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.0583 - accuracy: 0.8096 - val_loss: 32.2938 - val_accuracy: 0.8125\n","Epoch 30/50\n","27/27 [==============================] - 2s 76ms/step - loss: 18.9021 - accuracy: 0.8061 - val_loss: 32.0666 - val_accuracy: 0.8125\n","Epoch 31/50\n","27/27 [==============================] - 3s 101ms/step - loss: 18.8611 - accuracy: 0.8107 - val_loss: 33.1360 - val_accuracy: 0.8125\n","Epoch 32/50\n","27/27 [==============================] - 3s 105ms/step - loss: 18.8613 - accuracy: 0.8084 - val_loss: 32.0363 - val_accuracy: 0.8125\n","Epoch 33/50\n","27/27 [==============================] - 2s 77ms/step - loss: 18.9162 - accuracy: 0.8026 - val_loss: 33.2760 - val_accuracy: 0.8125\n","Epoch 34/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.1740 - accuracy: 0.8096 - val_loss: 33.3342 - val_accuracy: 0.8125\n","Epoch 35/50\n","27/27 [==============================] - 2s 73ms/step - loss: 19.0907 - accuracy: 0.8061 - val_loss: 36.0738 - val_accuracy: 0.8125\n","Epoch 36/50\n","27/27 [==============================] - 2s 75ms/step - loss: 19.4909 - accuracy: 0.7932 - val_loss: 32.0255 - val_accuracy: 0.8125\n","Epoch 37/50\n","27/27 [==============================] - 2s 79ms/step - loss: 19.4608 - accuracy: 0.8026 - val_loss: 34.7418 - val_accuracy: 0.8125\n","Epoch 38/50\n","27/27 [==============================] - 3s 107ms/step - loss: 19.6150 - accuracy: 0.8037 - val_loss: 33.1026 - val_accuracy: 0.7917\n","Epoch 39/50\n","27/27 [==============================] - 3s 99ms/step - loss: 19.9877 - accuracy: 0.7991 - val_loss: 33.6344 - val_accuracy: 0.8125\n","Epoch 40/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.9722 - accuracy: 0.7956 - val_loss: 34.7734 - val_accuracy: 0.8125\n","Epoch 41/50\n","27/27 [==============================] - 2s 76ms/step - loss: 20.0250 - accuracy: 0.8037 - val_loss: 32.3081 - val_accuracy: 0.8229\n","Epoch 42/50\n","27/27 [==============================] - 2s 77ms/step - loss: 19.1381 - accuracy: 0.8107 - val_loss: 33.1372 - val_accuracy: 0.8125\n","Epoch 43/50\n","27/27 [==============================] - 2s 78ms/step - loss: 18.8651 - accuracy: 0.8096 - val_loss: 33.3600 - val_accuracy: 0.8125\n","Epoch 44/50\n","27/27 [==============================] - 2s 88ms/step - loss: 18.7326 - accuracy: 0.8096 - val_loss: 32.5495 - val_accuracy: 0.8125\n","Epoch 45/50\n","27/27 [==============================] - 3s 102ms/step - loss: 18.4973 - accuracy: 0.8096 - val_loss: 32.7934 - val_accuracy: 0.8125\n","Epoch 46/50\n","27/27 [==============================] - 3s 99ms/step - loss: 18.3878 - accuracy: 0.8072 - val_loss: 32.0166 - val_accuracy: 0.8125\n","Epoch 47/50\n","27/27 [==============================] - 2s 77ms/step - loss: 18.3029 - accuracy: 0.8084 - val_loss: 32.5014 - val_accuracy: 0.8125\n","Epoch 48/50\n","27/27 [==============================] - 2s 79ms/step - loss: 18.3121 - accuracy: 0.8096 - val_loss: 31.9646 - val_accuracy: 0.8125\n","Epoch 49/50\n","27/27 [==============================] - 2s 78ms/step - loss: 18.1998 - accuracy: 0.8072 - val_loss: 32.4099 - val_accuracy: 0.8125\n","Epoch 50/50\n","27/27 [==============================] - 2s 75ms/step - loss: 18.1910 - accuracy: 0.8061 - val_loss: 32.2018 - val_accuracy: 0.8125\n","8/8 [==============================] - 0s 21ms/step\n","8/8 [==============================] - 0s 27ms/step - loss: 231.7475 - accuracy: 1.0000\n","Test Loss: 231.7475, Test accuracy : 1.0000\n","Epoch 1/50\n","27/27 [==============================] - 4s 119ms/step - loss: 72.7296 - accuracy: 0.1507 - val_loss: 59.7727 - val_accuracy: 0.2188\n","Epoch 2/50\n","27/27 [==============================] - 2s 88ms/step - loss: 64.4764 - accuracy: 0.2371 - val_loss: 60.2383 - val_accuracy: 0.3229\n","Epoch 3/50\n","27/27 [==============================] - 2s 75ms/step - loss: 59.0380 - accuracy: 0.2255 - val_loss: 56.8590 - val_accuracy: 0.3542\n","Epoch 4/50\n","27/27 [==============================] - 2s 78ms/step - loss: 51.8121 - accuracy: 0.2044 - val_loss: 51.5754 - val_accuracy: 0.3646\n","Epoch 5/50\n","27/27 [==============================] - 2s 76ms/step - loss: 46.4582 - accuracy: 0.2231 - val_loss: 52.7642 - val_accuracy: 0.3646\n","Epoch 6/50\n","27/27 [==============================] - 2s 77ms/step - loss: 41.3375 - accuracy: 0.2348 - val_loss: 52.1794 - val_accuracy: 0.3438\n","Epoch 7/50\n","27/27 [==============================] - 3s 103ms/step - loss: 37.7052 - accuracy: 0.2313 - val_loss: 49.0729 - val_accuracy: 0.3333\n","Epoch 8/50\n","27/27 [==============================] - 3s 108ms/step - loss: 35.4993 - accuracy: 0.2535 - val_loss: 48.6264 - val_accuracy: 0.3125\n","Epoch 9/50\n","27/27 [==============================] - 2s 81ms/step - loss: 33.5880 - accuracy: 0.2617 - val_loss: 47.9839 - val_accuracy: 0.3438\n","Epoch 10/50\n","27/27 [==============================] - 2s 77ms/step - loss: 32.2107 - accuracy: 0.2687 - val_loss: 49.1091 - val_accuracy: 0.3542\n","Epoch 11/50\n","27/27 [==============================] - 2s 75ms/step - loss: 31.0283 - accuracy: 0.2734 - val_loss: 46.7291 - val_accuracy: 0.3021\n","Epoch 12/50\n","27/27 [==============================] - 2s 76ms/step - loss: 29.6995 - accuracy: 0.2874 - val_loss: 48.3459 - val_accuracy: 0.3646\n","Epoch 13/50\n","27/27 [==============================] - 2s 75ms/step - loss: 30.1640 - accuracy: 0.2862 - val_loss: 45.2163 - val_accuracy: 0.3438\n","Epoch 14/50\n","27/27 [==============================] - 3s 99ms/step - loss: 29.5839 - accuracy: 0.2886 - val_loss: 51.4242 - val_accuracy: 0.3333\n","Epoch 15/50\n","27/27 [==============================] - 3s 107ms/step - loss: 27.6781 - accuracy: 0.2991 - val_loss: 46.6476 - val_accuracy: 0.3438\n","Epoch 16/50\n","27/27 [==============================] - 2s 79ms/step - loss: 26.5761 - accuracy: 0.1939 - val_loss: 47.8376 - val_accuracy: 0.3542\n","Epoch 17/50\n","27/27 [==============================] - 2s 76ms/step - loss: 25.8859 - accuracy: 0.2360 - val_loss: 49.1820 - val_accuracy: 0.3750\n","Epoch 18/50\n","27/27 [==============================] - 2s 75ms/step - loss: 24.9054 - accuracy: 0.2161 - val_loss: 48.9097 - val_accuracy: 0.3333\n","Epoch 19/50\n","27/27 [==============================] - 2s 77ms/step - loss: 24.3576 - accuracy: 0.2208 - val_loss: 46.8566 - val_accuracy: 0.3229\n","Epoch 20/50\n","27/27 [==============================] - 2s 77ms/step - loss: 23.7122 - accuracy: 0.3049 - val_loss: 48.6441 - val_accuracy: 0.3021\n","Epoch 21/50\n","27/27 [==============================] - 3s 108ms/step - loss: 23.1372 - accuracy: 0.3271 - val_loss: 46.9922 - val_accuracy: 0.2917\n","Epoch 22/50\n","27/27 [==============================] - 3s 102ms/step - loss: 22.7196 - accuracy: 0.3341 - val_loss: 49.3105 - val_accuracy: 0.3438\n","Epoch 23/50\n","27/27 [==============================] - 2s 75ms/step - loss: 22.6362 - accuracy: 0.3306 - val_loss: 48.7805 - val_accuracy: 0.3438\n","Epoch 24/50\n","27/27 [==============================] - 2s 76ms/step - loss: 22.1088 - accuracy: 0.3481 - val_loss: 48.1093 - val_accuracy: 0.3438\n","Epoch 25/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.9004 - accuracy: 0.3563 - val_loss: 47.1051 - val_accuracy: 0.3646\n","Epoch 26/50\n","27/27 [==============================] - 2s 77ms/step - loss: 22.0456 - accuracy: 0.3435 - val_loss: 50.7024 - val_accuracy: 0.3750\n","Epoch 27/50\n","27/27 [==============================] - 2s 80ms/step - loss: 21.4667 - accuracy: 0.3528 - val_loss: 48.1217 - val_accuracy: 0.3333\n","Epoch 28/50\n","27/27 [==============================] - 3s 104ms/step - loss: 21.4391 - accuracy: 0.3353 - val_loss: 48.1115 - val_accuracy: 0.2812\n","Epoch 29/50\n","27/27 [==============================] - 3s 104ms/step - loss: 21.0210 - accuracy: 0.3914 - val_loss: 52.3618 - val_accuracy: 0.3542\n","Epoch 30/50\n","27/27 [==============================] - 2s 75ms/step - loss: 20.4811 - accuracy: 0.3516 - val_loss: 49.7665 - val_accuracy: 0.2917\n","Epoch 31/50\n","27/27 [==============================] - 2s 78ms/step - loss: 20.1988 - accuracy: 0.3551 - val_loss: 48.5722 - val_accuracy: 0.3229\n","Epoch 32/50\n","27/27 [==============================] - 2s 76ms/step - loss: 20.0007 - accuracy: 0.3376 - val_loss: 50.3806 - val_accuracy: 0.3542\n","Epoch 33/50\n","27/27 [==============================] - 2s 76ms/step - loss: 20.0910 - accuracy: 0.3341 - val_loss: 49.4382 - val_accuracy: 0.3333\n","Epoch 34/50\n","27/27 [==============================] - 2s 81ms/step - loss: 19.4292 - accuracy: 0.3692 - val_loss: 50.5858 - val_accuracy: 0.3125\n","Epoch 35/50\n","27/27 [==============================] - 3s 103ms/step - loss: 19.0502 - accuracy: 0.3925 - val_loss: 50.1120 - val_accuracy: 0.3438\n","Epoch 36/50\n","27/27 [==============================] - 3s 105ms/step - loss: 18.6727 - accuracy: 0.3937 - val_loss: 50.5325 - val_accuracy: 0.3229\n","Epoch 37/50\n","27/27 [==============================] - 2s 77ms/step - loss: 18.8597 - accuracy: 0.3984 - val_loss: 54.8785 - val_accuracy: 0.3333\n","Epoch 38/50\n","27/27 [==============================] - 2s 77ms/step - loss: 18.1783 - accuracy: 0.4007 - val_loss: 51.7076 - val_accuracy: 0.3125\n","Epoch 39/50\n","27/27 [==============================] - 2s 75ms/step - loss: 18.2135 - accuracy: 0.3843 - val_loss: 51.7378 - val_accuracy: 0.3333\n","Epoch 40/50\n","27/27 [==============================] - 2s 78ms/step - loss: 18.1219 - accuracy: 0.3843 - val_loss: 51.9294 - val_accuracy: 0.3333\n","Epoch 41/50\n","27/27 [==============================] - 2s 76ms/step - loss: 17.8559 - accuracy: 0.3890 - val_loss: 50.6167 - val_accuracy: 0.3333\n","Epoch 42/50\n","27/27 [==============================] - 3s 105ms/step - loss: 17.7934 - accuracy: 0.3914 - val_loss: 50.9403 - val_accuracy: 0.2708\n","Epoch 43/50\n","27/27 [==============================] - 3s 104ms/step - loss: 17.9339 - accuracy: 0.3820 - val_loss: 53.9507 - val_accuracy: 0.3125\n","Epoch 44/50\n","27/27 [==============================] - 2s 77ms/step - loss: 17.6841 - accuracy: 0.3937 - val_loss: 51.9273 - val_accuracy: 0.3021\n","Epoch 45/50\n","27/27 [==============================] - 2s 76ms/step - loss: 17.4718 - accuracy: 0.3960 - val_loss: 48.7588 - val_accuracy: 0.2812\n","Epoch 46/50\n","27/27 [==============================] - 2s 77ms/step - loss: 17.5958 - accuracy: 0.3902 - val_loss: 56.0506 - val_accuracy: 0.2708\n","Epoch 47/50\n","27/27 [==============================] - 2s 78ms/step - loss: 17.8509 - accuracy: 0.3867 - val_loss: 52.3842 - val_accuracy: 0.3021\n","Epoch 48/50\n","27/27 [==============================] - 2s 87ms/step - loss: 17.6158 - accuracy: 0.3785 - val_loss: 51.7524 - val_accuracy: 0.3229\n","Epoch 49/50\n","27/27 [==============================] - 3s 110ms/step - loss: 17.6197 - accuracy: 0.3715 - val_loss: 55.3460 - val_accuracy: 0.2708\n","Epoch 50/50\n","27/27 [==============================] - 3s 96ms/step - loss: 17.8109 - accuracy: 0.3785 - val_loss: 52.1562 - val_accuracy: 0.2708\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 16ms/step - loss: 414.3999 - accuracy: 0.9417\n","Test Loss: 414.3999, Test accuracy : 0.9417\n","Epoch 1/50\n","27/27 [==============================] - 4s 105ms/step - loss: 95.6121 - accuracy: 0.3213 - val_loss: 46.4078 - val_accuracy: 0.5417\n","Epoch 2/50\n","27/27 [==============================] - 2s 78ms/step - loss: 63.7764 - accuracy: 0.7780 - val_loss: 45.1100 - val_accuracy: 0.7292\n","Epoch 3/50\n","27/27 [==============================] - 2s 78ms/step - loss: 59.1768 - accuracy: 0.7652 - val_loss: 46.8518 - val_accuracy: 0.7292\n","Epoch 4/50\n","27/27 [==============================] - 2s 77ms/step - loss: 55.2891 - accuracy: 0.7558 - val_loss: 58.2778 - val_accuracy: 0.8125\n","Epoch 5/50\n","27/27 [==============================] - 2s 77ms/step - loss: 52.1675 - accuracy: 0.7804 - val_loss: 47.9946 - val_accuracy: 0.8021\n","Epoch 6/50\n","27/27 [==============================] - 2s 89ms/step - loss: 46.1824 - accuracy: 0.7862 - val_loss: 44.7278 - val_accuracy: 0.7708\n","Epoch 7/50\n","27/27 [==============================] - 3s 107ms/step - loss: 40.2955 - accuracy: 0.7815 - val_loss: 49.0660 - val_accuracy: 0.8021\n","Epoch 8/50\n","27/27 [==============================] - 3s 94ms/step - loss: 36.5238 - accuracy: 0.7827 - val_loss: 46.8939 - val_accuracy: 0.8125\n","Epoch 9/50\n","27/27 [==============================] - 2s 79ms/step - loss: 32.2879 - accuracy: 0.7827 - val_loss: 51.0964 - val_accuracy: 0.7917\n","Epoch 10/50\n","27/27 [==============================] - 2s 77ms/step - loss: 29.8446 - accuracy: 0.7827 - val_loss: 47.4463 - val_accuracy: 0.8021\n","Epoch 11/50\n","27/27 [==============================] - 2s 77ms/step - loss: 28.1419 - accuracy: 0.7815 - val_loss: 48.5489 - val_accuracy: 0.7812\n","Epoch 12/50\n","27/27 [==============================] - 2s 75ms/step - loss: 26.1625 - accuracy: 0.7932 - val_loss: 48.5017 - val_accuracy: 0.8021\n","Epoch 13/50\n","27/27 [==============================] - 3s 101ms/step - loss: 25.3476 - accuracy: 0.7886 - val_loss: 47.4208 - val_accuracy: 0.7812\n","Epoch 14/50\n","27/27 [==============================] - 3s 110ms/step - loss: 24.5489 - accuracy: 0.7874 - val_loss: 48.5313 - val_accuracy: 0.8021\n","Epoch 15/50\n","27/27 [==============================] - 2s 84ms/step - loss: 24.2886 - accuracy: 0.7886 - val_loss: 47.8215 - val_accuracy: 0.7708\n","Epoch 16/50\n","27/27 [==============================] - 2s 77ms/step - loss: 22.9378 - accuracy: 0.7862 - val_loss: 47.2274 - val_accuracy: 0.8021\n","Epoch 17/50\n","27/27 [==============================] - 2s 76ms/step - loss: 22.1532 - accuracy: 0.7944 - val_loss: 48.7093 - val_accuracy: 0.7917\n","Epoch 18/50\n","27/27 [==============================] - 2s 79ms/step - loss: 21.5770 - accuracy: 0.7991 - val_loss: 50.1337 - val_accuracy: 0.8125\n","Epoch 19/50\n","27/27 [==============================] - 2s 78ms/step - loss: 21.2228 - accuracy: 0.8014 - val_loss: 46.8525 - val_accuracy: 0.7812\n","Epoch 20/50\n","27/27 [==============================] - 3s 102ms/step - loss: 21.1886 - accuracy: 0.7967 - val_loss: 47.3467 - val_accuracy: 0.7708\n","Epoch 21/50\n","27/27 [==============================] - 3s 111ms/step - loss: 20.7618 - accuracy: 0.8026 - val_loss: 49.0875 - val_accuracy: 0.8021\n","Epoch 22/50\n","27/27 [==============================] - 2s 84ms/step - loss: 20.4441 - accuracy: 0.8014 - val_loss: 50.0098 - val_accuracy: 0.8021\n","Epoch 23/50\n","27/27 [==============================] - 2s 80ms/step - loss: 20.6902 - accuracy: 0.8049 - val_loss: 49.7931 - val_accuracy: 0.8021\n","Epoch 24/50\n","27/27 [==============================] - 2s 78ms/step - loss: 21.5073 - accuracy: 0.8049 - val_loss: 48.0971 - val_accuracy: 0.8021\n","Epoch 25/50\n","27/27 [==============================] - 2s 79ms/step - loss: 21.9118 - accuracy: 0.8014 - val_loss: 50.6432 - val_accuracy: 0.8021\n","Epoch 26/50\n","27/27 [==============================] - 2s 80ms/step - loss: 21.9066 - accuracy: 0.8014 - val_loss: 43.7570 - val_accuracy: 0.7396\n","Epoch 27/50\n","27/27 [==============================] - 3s 104ms/step - loss: 23.2354 - accuracy: 0.8037 - val_loss: 44.7026 - val_accuracy: 0.8021\n","Epoch 28/50\n","27/27 [==============================] - 3s 109ms/step - loss: 21.9230 - accuracy: 0.8026 - val_loss: 45.5867 - val_accuracy: 0.7917\n","Epoch 29/50\n","27/27 [==============================] - 2s 79ms/step - loss: 22.0236 - accuracy: 0.8026 - val_loss: 47.2447 - val_accuracy: 0.8021\n","Epoch 30/50\n","27/27 [==============================] - 2s 77ms/step - loss: 22.5143 - accuracy: 0.8049 - val_loss: 54.1194 - val_accuracy: 0.8021\n","Epoch 31/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.9916 - accuracy: 0.8014 - val_loss: 51.2764 - val_accuracy: 0.8125\n","Epoch 32/50\n","27/27 [==============================] - 2s 74ms/step - loss: 21.7562 - accuracy: 0.8037 - val_loss: 51.2820 - val_accuracy: 0.8125\n","Epoch 33/50\n","27/27 [==============================] - 2s 80ms/step - loss: 21.4516 - accuracy: 0.7956 - val_loss: 51.4568 - val_accuracy: 0.8125\n","Epoch 34/50\n","27/27 [==============================] - 3s 98ms/step - loss: 21.4518 - accuracy: 0.7967 - val_loss: 50.6889 - val_accuracy: 0.8125\n","Epoch 35/50\n","27/27 [==============================] - 3s 109ms/step - loss: 21.3715 - accuracy: 0.7956 - val_loss: 51.5997 - val_accuracy: 0.8021\n","Epoch 36/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.2501 - accuracy: 0.7956 - val_loss: 51.1472 - val_accuracy: 0.8125\n","Epoch 37/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.4578 - accuracy: 0.7932 - val_loss: 52.2886 - val_accuracy: 0.8125\n","Epoch 38/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.8151 - accuracy: 0.7932 - val_loss: 50.3346 - val_accuracy: 0.8125\n","Epoch 39/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.4945 - accuracy: 0.7956 - val_loss: 51.9107 - val_accuracy: 0.8125\n","Epoch 40/50\n","27/27 [==============================] - 2s 79ms/step - loss: 21.4635 - accuracy: 0.7967 - val_loss: 51.5366 - val_accuracy: 0.8125\n","Epoch 41/50\n","27/27 [==============================] - 3s 109ms/step - loss: 21.6080 - accuracy: 0.7967 - val_loss: 51.8745 - val_accuracy: 0.8021\n","Epoch 42/50\n","27/27 [==============================] - 3s 101ms/step - loss: 21.9662 - accuracy: 0.7815 - val_loss: 51.4678 - val_accuracy: 0.8125\n","Epoch 43/50\n","27/27 [==============================] - 2s 77ms/step - loss: 22.1097 - accuracy: 0.7967 - val_loss: 51.9591 - val_accuracy: 0.8125\n","Epoch 44/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.9612 - accuracy: 0.7956 - val_loss: 50.5273 - val_accuracy: 0.8125\n","Epoch 45/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.7460 - accuracy: 0.7956 - val_loss: 52.0029 - val_accuracy: 0.8229\n","Epoch 46/50\n","27/27 [==============================] - 2s 77ms/step - loss: 21.9228 - accuracy: 0.7991 - val_loss: 50.8809 - val_accuracy: 0.8125\n","Epoch 47/50\n","27/27 [==============================] - 2s 88ms/step - loss: 21.7323 - accuracy: 0.7967 - val_loss: 54.7893 - val_accuracy: 0.8125\n","Epoch 48/50\n","27/27 [==============================] - 3s 102ms/step - loss: 21.7398 - accuracy: 0.7991 - val_loss: 50.6061 - val_accuracy: 0.8125\n","Epoch 49/50\n","27/27 [==============================] - 3s 102ms/step - loss: 21.7465 - accuracy: 0.7932 - val_loss: 57.0012 - val_accuracy: 0.8125\n","Epoch 50/50\n","27/27 [==============================] - 2s 76ms/step - loss: 21.8521 - accuracy: 0.7979 - val_loss: 53.7919 - val_accuracy: 0.8125\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 18ms/step - loss: 1053.6315 - accuracy: 0.9708\n","Test Loss: 1053.6315, Test accuracy : 0.9708\n","Epoch 1/50\n","27/27 [==============================] - 3s 85ms/step - loss: 71.9657 - accuracy: 0.3318 - val_loss: 82.4872 - val_accuracy: 0.6875\n","Epoch 2/50\n","27/27 [==============================] - 2s 78ms/step - loss: 51.5078 - accuracy: 0.6495 - val_loss: 82.3918 - val_accuracy: 0.7396\n","Epoch 3/50\n","27/27 [==============================] - 2s 78ms/step - loss: 48.0447 - accuracy: 0.6577 - val_loss: 82.2437 - val_accuracy: 0.7396\n","Epoch 4/50\n","27/27 [==============================] - 2s 79ms/step - loss: 44.3001 - accuracy: 0.6402 - val_loss: 82.1722 - val_accuracy: 0.7396\n","Epoch 5/50\n","27/27 [==============================] - 2s 89ms/step - loss: 40.5268 - accuracy: 0.6717 - val_loss: 82.6886 - val_accuracy: 0.7396\n","Epoch 6/50\n","27/27 [==============================] - 3s 107ms/step - loss: 36.1332 - accuracy: 0.6811 - val_loss: 82.4767 - val_accuracy: 0.7396\n","Epoch 7/50\n","27/27 [==============================] - 3s 95ms/step - loss: 30.2670 - accuracy: 0.7056 - val_loss: 83.1675 - val_accuracy: 0.7396\n","Epoch 8/50\n","27/27 [==============================] - 2s 77ms/step - loss: 26.9793 - accuracy: 0.7208 - val_loss: 82.0419 - val_accuracy: 0.7500\n","Epoch 9/50\n","27/27 [==============================] - 2s 77ms/step - loss: 22.7395 - accuracy: 0.7512 - val_loss: 81.8809 - val_accuracy: 0.7292\n","Epoch 10/50\n","27/27 [==============================] - 2s 76ms/step - loss: 19.2281 - accuracy: 0.7407 - val_loss: 82.1176 - val_accuracy: 0.7292\n","Epoch 11/50\n","27/27 [==============================] - 2s 75ms/step - loss: 16.7560 - accuracy: 0.7780 - val_loss: 83.0041 - val_accuracy: 0.7396\n","Epoch 12/50\n","27/27 [==============================] - 3s 98ms/step - loss: 15.6810 - accuracy: 0.7921 - val_loss: 83.3486 - val_accuracy: 0.7396\n","Epoch 13/50\n","27/27 [==============================] - 3s 108ms/step - loss: 16.1526 - accuracy: 0.7967 - val_loss: 82.2686 - val_accuracy: 0.7292\n","Epoch 14/50\n","27/27 [==============================] - 3s 98ms/step - loss: 15.5850 - accuracy: 0.8166 - val_loss: 82.8789 - val_accuracy: 0.7188\n","Epoch 15/50\n","27/27 [==============================] - 2s 76ms/step - loss: 14.7038 - accuracy: 0.8084 - val_loss: 83.8292 - val_accuracy: 0.7292\n","Epoch 16/50\n","27/27 [==============================] - 2s 80ms/step - loss: 14.3427 - accuracy: 0.8411 - val_loss: 84.3522 - val_accuracy: 0.6562\n","Epoch 17/50\n","27/27 [==============================] - 2s 76ms/step - loss: 13.4985 - accuracy: 0.8867 - val_loss: 83.3225 - val_accuracy: 0.5833\n","Epoch 18/50\n","27/27 [==============================] - 2s 80ms/step - loss: 13.1237 - accuracy: 0.8960 - val_loss: 84.8771 - val_accuracy: 0.5729\n","Epoch 19/50\n","27/27 [==============================] - 3s 107ms/step - loss: 13.6171 - accuracy: 0.8925 - val_loss: 85.2633 - val_accuracy: 0.5729\n","Epoch 20/50\n","27/27 [==============================] - 3s 102ms/step - loss: 13.9529 - accuracy: 0.8703 - val_loss: 84.3249 - val_accuracy: 0.5625\n","Epoch 21/50\n","27/27 [==============================] - 2s 74ms/step - loss: 13.3290 - accuracy: 0.9054 - val_loss: 86.2300 - val_accuracy: 0.5312\n","Epoch 22/50\n","27/27 [==============================] - 2s 76ms/step - loss: 13.2105 - accuracy: 0.9100 - val_loss: 83.3435 - val_accuracy: 0.5938\n","Epoch 23/50\n","27/27 [==============================] - 2s 76ms/step - loss: 12.3274 - accuracy: 0.9159 - val_loss: 84.0724 - val_accuracy: 0.5938\n","Epoch 24/50\n","27/27 [==============================] - 2s 78ms/step - loss: 11.8353 - accuracy: 0.9252 - val_loss: 84.7355 - val_accuracy: 0.5729\n","Epoch 25/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.6829 - accuracy: 0.9241 - val_loss: 83.7110 - val_accuracy: 0.5938\n","Epoch 26/50\n","27/27 [==============================] - 3s 102ms/step - loss: 11.4980 - accuracy: 0.9171 - val_loss: 85.2290 - val_accuracy: 0.5625\n","Epoch 27/50\n","27/27 [==============================] - 3s 103ms/step - loss: 11.3366 - accuracy: 0.9276 - val_loss: 83.7538 - val_accuracy: 0.5938\n","Epoch 28/50\n","27/27 [==============================] - 2s 76ms/step - loss: 11.2235 - accuracy: 0.9287 - val_loss: 84.0135 - val_accuracy: 0.5833\n","Epoch 29/50\n","27/27 [==============================] - 2s 77ms/step - loss: 11.1147 - accuracy: 0.9252 - val_loss: 83.9116 - val_accuracy: 0.5938\n","Epoch 30/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.0060 - accuracy: 0.9311 - val_loss: 83.5058 - val_accuracy: 0.6146\n","Epoch 31/50\n","27/27 [==============================] - 2s 76ms/step - loss: 10.8634 - accuracy: 0.9299 - val_loss: 84.2204 - val_accuracy: 0.5729\n","Epoch 32/50\n","27/27 [==============================] - 2s 84ms/step - loss: 10.7760 - accuracy: 0.9299 - val_loss: 83.3499 - val_accuracy: 0.6146\n","Epoch 33/50\n","27/27 [==============================] - 3s 101ms/step - loss: 10.7244 - accuracy: 0.9311 - val_loss: 83.8035 - val_accuracy: 0.5833\n","Epoch 34/50\n","27/27 [==============================] - 3s 107ms/step - loss: 10.7315 - accuracy: 0.9276 - val_loss: 89.1281 - val_accuracy: 0.4792\n","Epoch 35/50\n","27/27 [==============================] - 2s 75ms/step - loss: 10.6971 - accuracy: 0.9299 - val_loss: 82.5422 - val_accuracy: 0.6562\n","Epoch 36/50\n","27/27 [==============================] - 2s 77ms/step - loss: 10.9788 - accuracy: 0.9252 - val_loss: 85.5782 - val_accuracy: 0.5729\n","Epoch 37/50\n","27/27 [==============================] - 2s 76ms/step - loss: 11.0664 - accuracy: 0.9100 - val_loss: 82.4841 - val_accuracy: 0.6562\n","Epoch 38/50\n","27/27 [==============================] - 2s 77ms/step - loss: 10.7299 - accuracy: 0.9206 - val_loss: 83.4833 - val_accuracy: 0.6042\n","Epoch 39/50\n","27/27 [==============================] - 2s 84ms/step - loss: 10.5498 - accuracy: 0.9287 - val_loss: 83.2871 - val_accuracy: 0.6042\n","Epoch 40/50\n","27/27 [==============================] - 3s 105ms/step - loss: 10.5305 - accuracy: 0.9229 - val_loss: 85.5979 - val_accuracy: 0.5417\n","Epoch 41/50\n","27/27 [==============================] - 3s 103ms/step - loss: 10.4760 - accuracy: 0.9299 - val_loss: 83.8035 - val_accuracy: 0.5938\n","Epoch 42/50\n","27/27 [==============================] - 2s 77ms/step - loss: 10.3538 - accuracy: 0.9287 - val_loss: 84.7054 - val_accuracy: 0.5521\n","Epoch 43/50\n","27/27 [==============================] - 2s 80ms/step - loss: 10.4628 - accuracy: 0.9276 - val_loss: 84.3545 - val_accuracy: 0.5625\n","Epoch 44/50\n","27/27 [==============================] - 2s 78ms/step - loss: 10.5534 - accuracy: 0.9182 - val_loss: 83.7562 - val_accuracy: 0.5938\n","Epoch 45/50\n","27/27 [==============================] - 2s 79ms/step - loss: 11.0699 - accuracy: 0.9077 - val_loss: 84.8455 - val_accuracy: 0.5729\n","Epoch 46/50\n","27/27 [==============================] - 2s 88ms/step - loss: 11.4523 - accuracy: 0.9054 - val_loss: 83.6801 - val_accuracy: 0.6042\n","Epoch 47/50\n","27/27 [==============================] - 3s 105ms/step - loss: 11.5512 - accuracy: 0.9077 - val_loss: 82.9311 - val_accuracy: 0.6562\n","Epoch 48/50\n","27/27 [==============================] - 3s 101ms/step - loss: 12.2195 - accuracy: 0.8960 - val_loss: 85.6250 - val_accuracy: 0.5208\n","Epoch 49/50\n","27/27 [==============================] - 2s 81ms/step - loss: 11.8743 - accuracy: 0.8972 - val_loss: 83.7151 - val_accuracy: 0.5625\n","Epoch 50/50\n","27/27 [==============================] - 2s 78ms/step - loss: 11.8473 - accuracy: 0.9054 - val_loss: 85.7875 - val_accuracy: 0.5625\n","8/8 [==============================] - 0s 14ms/step\n","8/8 [==============================] - 0s 15ms/step - loss: 690.7078 - accuracy: 0.7875\n","Test Loss: 690.7078, Test accuracy : 0.7875\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU","executionInfo":{"status":"ok","timestamp":1715956396544,"user_tz":-60,"elapsed":11,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1715956402871,"user_tz":-60,"elapsed":6335,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd164559-8116-4d24-a2e9-1cbf74dabc62"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten (Flatten)           (None, 81471)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                5214208   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 5214338 (19.89 MB)\n","Trainable params: 5214338 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 5214403 (19.89 MB)\n","Trainable params: 5214403 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_5 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 5214533 (19.89 MB)\n","Trainable params: 5214533 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_9 (Dense)             (None, 9)                 585       \n","                                                                 \n","=================================================================\n","Total params: 5214793 (19.89 MB)\n","Trainable params: 5214793 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_11 (Dense)            (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 5215053 (19.89 MB)\n","Trainable params: 5215053 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_12 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_13 (Dense)            (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 5215768 (19.90 MB)\n","Trainable params: 5215768 (19.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_15 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_17 (Dense)            (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 5214663 (19.89 MB)\n","Trainable params: 5214663 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw","executionInfo":{"status":"ok","timestamp":1715956402871,"user_tz":-60,"elapsed":22,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1715956403276,"user_tz":-60,"elapsed":426,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"543a22ce-baf4-4978-d750-450222c69c6d"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                238                60   \n","1   madd_6_Lazim  Yassin Al Jazaery                238                60   \n","2   madd_6_Lazim   Ibrahim_Aldosary                238                60   \n","3   madd_6_Lazim               safa                238                60   \n","4   madd_6_Lazim       all reciters                952               240   \n","5       madd_246        Abdul Basit                238                60   \n","6       madd_246  Yassin Al Jazaery                238                60   \n","7       madd_246   Ibrahim_Aldosary                238                60   \n","8       madd_246               safa                238                60   \n","9       madd_246       all reciters                952               240   \n","10        madd_6        Abdul Basit                238                60   \n","11        madd_6  Yassin Al Jazaery                238                60   \n","12        madd_6   Ibrahim_Aldosary                238                60   \n","13        madd_6               safa                238                60   \n","14        madd_6       all reciters                952               240   \n","15        madd_2        Abdul Basit                238                60   \n","16        madd_2  Yassin Al Jazaery                238                60   \n","17        madd_2   Ibrahim_Aldosary                238                60   \n","18        madd_2               safa                238                60   \n","19        madd_2       all reciters                952               240   \n","20        Ikhfaa        Abdul Basit                238                60   \n","21        Ikhfaa  Yassin Al Jazaery                238                60   \n","22        Ikhfaa   Ibrahim_Aldosary                238                60   \n","23        Ikhfaa               safa                238                60   \n","24        Ikhfaa       all reciters                952               240   \n","25        Idgham        Abdul Basit                238                60   \n","26        Idgham  Yassin Al Jazaery                238                60   \n","27        Idgham   Ibrahim_Aldosary                238                60   \n","28        Idgham               safa                238                60   \n","29        Idgham       all reciters                952               240   \n","30       tafkhim        Abdul Basit                238                60   \n","31       tafkhim  Yassin Al Jazaery                238                60   \n","32       tafkhim   Ibrahim_Aldosary                238                60   \n","33       tafkhim               safa                238                60   \n","34       tafkhim       all reciters                952               240   \n","35       qalqala        Abdul Basit                238                60   \n","36       qalqala  Yassin Al Jazaery                238                60   \n","37       qalqala   Ibrahim_Aldosary                238                60   \n","38       qalqala               safa                238                60   \n","39       qalqala       all reciters                952               240   \n","40         imala        Abdul Basit                238                60   \n","41         imala  Yassin Al Jazaery                238                60   \n","42         imala   Ibrahim_Aldosary                238                60   \n","43         imala               safa                238                60   \n","44         imala       all reciters                952               240   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                 238                60  \n","1                 238                60  \n","2                 238                60  \n","3                 238                60  \n","4                 952               240  \n","5                 238                60  \n","6                 238                60  \n","7                 238                60  \n","8                 238                60  \n","9                 952               240  \n","10                238                60  \n","11                238                60  \n","12                238                60  \n","13                238                60  \n","14                952               240  \n","15                238                60  \n","16                238                60  \n","17                238                60  \n","18                238                60  \n","19                952               240  \n","20                238                60  \n","21                238                60  \n","22                238                60  \n","23                238                60  \n","24                952               240  \n","25                238                60  \n","26                238                60  \n","27                238                60  \n","28                238                60  \n","29                952               240  \n","30                238                60  \n","31                238                60  \n","32                238                60  \n","33                238                60  \n","34                952               240  \n","35                238                60  \n","36                238                60  \n","37                238                60  \n","38                238                60  \n","39                952               240  \n","40                238                60  \n","41                238                60  \n","42                238                60  \n","43                238                60  \n","44                952               240  "],"text/html":["\n","  <div id=\"df-ef223d15-65dc-46d9-b787-7024b62e4d58\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_246</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_6</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>madd_2</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Ikhfaa</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Idgham</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>tafkhim</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>qalqala</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>imala</td>\n","      <td>safa</td>\n","      <td>238</td>\n","      <td>60</td>\n","      <td>238</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>952</td>\n","      <td>240</td>\n","      <td>952</td>\n","      <td>240</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef223d15-65dc-46d9-b787-7024b62e4d58')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ef223d15-65dc-46d9-b787-7024b62e4d58 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ef223d15-65dc-46d9-b787-7024b62e4d58');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2a849e87-ad62-4e2c-8bdc-412f7383bc71\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a849e87-ad62-4e2c-8bdc-412f7383bc71')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2a849e87-ad62-4e2c-8bdc-412f7383bc71 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 45,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Yassin Al Jazaery\",\n          \"all reciters\",\n          \"Ibrahim_Aldosary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"952\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"240\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"952\",\n          \"238\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"240\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1715956403277,"user_tz":-60,"elapsed":23,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"69c7ecd3-1ff2-4342-ee87-9e0b6df5c9bf"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model       Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model   116.9364   1.0000     100.00   \n","1      madd_246_tajweed_rule_model   654.1515   0.9917      99.17   \n","2        madd_6_tajweed_rule_model   126.5052   0.9625      96.25   \n","3        madd_2_tajweed_rule_model    45.7938   1.0000     100.00   \n","4        Ikhfaa_tajweed_rule_model   507.0646   0.9833      98.33   \n","5        Idgham_tajweed_rule_model   231.7475   1.0000     100.00   \n","6       tafkhim_tajweed_rule_model   414.3999   0.9417      94.17   \n","7       qalqala_tajweed_rule_model  1053.6315   0.9708      97.08   \n","8         imala_tajweed_rule_model   690.7078   0.7875      78.75   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","1  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","2  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","3  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","4  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","5  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","6  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","7  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  \n","8  /content/drive/My Drive/M2 GL/PFE/AI_models_v4...  "],"text/html":["\n","  <div id=\"df-9ae494c5-84cc-4a76-b37d-eedf29dba655\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>116.9364</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>654.1515</td>\n","      <td>0.9917</td>\n","      <td>99.17</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>126.5052</td>\n","      <td>0.9625</td>\n","      <td>96.25</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>45.7938</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>507.0646</td>\n","      <td>0.9833</td>\n","      <td>98.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>231.7475</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>414.3999</td>\n","      <td>0.9417</td>\n","      <td>94.17</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>1053.6315</td>\n","      <td>0.9708</td>\n","      <td>97.08</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>690.7078</td>\n","      <td>0.7875</td>\n","      <td>78.75</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v4...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ae494c5-84cc-4a76-b37d-eedf29dba655')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9ae494c5-84cc-4a76-b37d-eedf29dba655 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9ae494c5-84cc-4a76-b37d-eedf29dba655');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-12e7e755-e7b1-457f-98c0-f72b232c8478\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12e7e755-e7b1-457f-98c0-f72b232c8478')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-12e7e755-e7b1-457f-98c0-f72b232c8478 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1053.6315\",\n          \"654.1515\",\n          \"231.7475\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1.0000\",\n          \"0.9917\",\n          \"0.9708\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"100.00\",\n          \"99.17\",\n          \"97.08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v4/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v4/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v4/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]}]}