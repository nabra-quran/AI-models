{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPVP0afDdvyLi16UfSRX5eA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1715437470768,"user_tz":-60,"elapsed":2906,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"6dd35678-1053-4a99-fd34-ae019ec1353f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing.csv')"],"metadata":{"id":"WtJVQemz7klg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/AI_models'"],"metadata":{"id":"7A9PSizPHQos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']"],"metadata":{"id":"KoKbTBQr7nY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def max_sequence_length_X_Y(data, tajweed_rule):\n","  data_filtered = data[data[tajweed_rule].apply(lambda x: x != '[]')]\n","  X_raw = data_filtered['mfcc'].astype(str).tolist()\n","  Y_raw = data_filtered[tajweed_rule].astype(str).tolist()\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = []\n","  for y_str in Y_raw:\n","      y_list = eval(y_str)\n","      flat_list = [item for sublist in y_list for item in sublist]\n","      Y.append(flat_list)\n","  max_sequence_length_Y = max(len(seq) for seq in Y)\n","  max_sequence_length_X = max(len(seq) for seq in X)\n","  return max_sequence_length_X, max_sequence_length_Y"],"metadata":{"id":"H950tSVTMxlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule, max_X, max_Y):\n","  data_filtered = reciter_data[reciter_data[tajweed_rule].apply(lambda x: x != '[]')]\n","\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = data_filtered['mfcc'].astype(str).tolist()\n","  Y_raw = data_filtered[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data (X)\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","\n","  # Preprocess the target data (Y)\n","  Y = []\n","  for y_str in Y_raw:\n","      y_list = eval(y_str)\n","      # Flatten nested lists and convert to numpy array\n","      flat_list = [item for sublist in y_list for item in sublist]\n","      Y.append(flat_list)\n","\n","  # Pad sequences in Y to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y, padding='post', dtype='int32', value=-1)\n","\n","  # Pad sequences in X to ensure all have the same length\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","\n","  max_X, max_Y = max_sequence_length_X_Y(data, tajweed_rule)\n","\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule, max_X, max_Y)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule, max_X, max_Y)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule, max_X, max_Y)\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3)]:\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tajweed_rules = ['madd_6_Lazim', 'madd_246', 'madd_6', 'madd_2', 'Ikhfaa', 'Idgham', 'tafkhim', 'qalqala', 'imala']"],"metadata":{"id":"qpgV2OY8K09J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1715438122209,"user_tz":-60,"elapsed":648548,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"71e02397-9c53-469c-ebb9-b713a1028974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 1s 763ms/step - loss: 205.9565 - accuracy: 0.0000e+00 - val_loss: 88.1186 - val_accuracy: 0.0000e+00\n","Epoch 2/50\n","1/1 [==============================] - 0s 51ms/step - loss: 210.5045 - accuracy: 0.5000 - val_loss: 68.2077 - val_accuracy: 1.0000\n","Epoch 3/50\n","1/1 [==============================] - 0s 53ms/step - loss: 106.1456 - accuracy: 1.0000 - val_loss: 73.6304 - val_accuracy: 1.0000\n","Epoch 4/50\n","1/1 [==============================] - 0s 52ms/step - loss: 77.2131 - accuracy: 1.0000 - val_loss: 67.7513 - val_accuracy: 1.0000\n","Epoch 5/50\n","1/1 [==============================] - 0s 52ms/step - loss: 66.1441 - accuracy: 0.5000 - val_loss: 68.1021 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","1/1 [==============================] - 0s 52ms/step - loss: 57.6922 - accuracy: 0.5000 - val_loss: 77.4168 - val_accuracy: 0.0000e+00\n","Epoch 7/50\n","1/1 [==============================] - 0s 53ms/step - loss: 52.8873 - accuracy: 0.0000e+00 - val_loss: 92.1687 - val_accuracy: 0.0000e+00\n","Epoch 8/50\n","1/1 [==============================] - 0s 52ms/step - loss: 35.0147 - accuracy: 0.0000e+00 - val_loss: 109.4839 - val_accuracy: 0.0000e+00\n","Epoch 9/50\n","1/1 [==============================] - 0s 53ms/step - loss: 13.9944 - accuracy: 0.5000 - val_loss: 124.8637 - val_accuracy: 0.0000e+00\n","Epoch 10/50\n","1/1 [==============================] - 0s 64ms/step - loss: 15.5325 - accuracy: 0.5000 - val_loss: 131.6295 - val_accuracy: 0.0000e+00\n","Epoch 11/50\n","1/1 [==============================] - 0s 75ms/step - loss: 29.7361 - accuracy: 1.0000 - val_loss: 127.1113 - val_accuracy: 1.0000\n","Epoch 12/50\n","1/1 [==============================] - 0s 68ms/step - loss: 34.8707 - accuracy: 1.0000 - val_loss: 114.5530 - val_accuracy: 0.0000e+00\n","Epoch 13/50\n","1/1 [==============================] - 0s 55ms/step - loss: 26.7777 - accuracy: 1.0000 - val_loss: 100.0064 - val_accuracy: 0.0000e+00\n","Epoch 14/50\n","1/1 [==============================] - 0s 52ms/step - loss: 16.7553 - accuracy: 0.5000 - val_loss: 88.2167 - val_accuracy: 0.0000e+00\n","Epoch 15/50\n","1/1 [==============================] - 0s 67ms/step - loss: 11.5293 - accuracy: 0.5000 - val_loss: 81.2735 - val_accuracy: 0.0000e+00\n","Epoch 16/50\n","1/1 [==============================] - 0s 52ms/step - loss: 8.2209 - accuracy: 0.5000 - val_loss: 79.6080 - val_accuracy: 0.0000e+00\n","Epoch 17/50\n","1/1 [==============================] - 0s 67ms/step - loss: 6.3241 - accuracy: 0.5000 - val_loss: 82.6021 - val_accuracy: 1.0000\n","Epoch 18/50\n","1/1 [==============================] - 0s 53ms/step - loss: 9.4909 - accuracy: 0.5000 - val_loss: 87.9868 - val_accuracy: 1.0000\n","Epoch 19/50\n","1/1 [==============================] - 0s 51ms/step - loss: 15.8245 - accuracy: 0.5000 - val_loss: 92.4345 - val_accuracy: 1.0000\n","Epoch 20/50\n","1/1 [==============================] - 0s 70ms/step - loss: 17.6243 - accuracy: 0.5000 - val_loss: 94.0736 - val_accuracy: 1.0000\n","Epoch 21/50\n","1/1 [==============================] - 0s 52ms/step - loss: 11.8500 - accuracy: 0.5000 - val_loss: 93.7852 - val_accuracy: 1.0000\n","Epoch 22/50\n","1/1 [==============================] - 0s 50ms/step - loss: 3.9833 - accuracy: 1.0000 - val_loss: 93.7664 - val_accuracy: 0.0000e+00\n","Epoch 23/50\n","1/1 [==============================] - 0s 53ms/step - loss: 0.8369 - accuracy: 0.5000 - val_loss: 95.4443 - val_accuracy: 0.0000e+00\n","Epoch 24/50\n","1/1 [==============================] - 0s 59ms/step - loss: 3.0379 - accuracy: 0.5000 - val_loss: 98.8561 - val_accuracy: 0.0000e+00\n","Epoch 25/50\n","1/1 [==============================] - 0s 70ms/step - loss: 6.1003 - accuracy: 0.5000 - val_loss: 103.2749 - val_accuracy: 0.0000e+00\n","Epoch 26/50\n","1/1 [==============================] - 0s 63ms/step - loss: 7.1556 - accuracy: 0.5000 - val_loss: 107.4808 - val_accuracy: 0.0000e+00\n","Epoch 27/50\n","1/1 [==============================] - 0s 69ms/step - loss: 6.9776 - accuracy: 0.5000 - val_loss: 109.6902 - val_accuracy: 0.0000e+00\n","Epoch 28/50\n","1/1 [==============================] - 0s 69ms/step - loss: 6.1313 - accuracy: 1.0000 - val_loss: 108.3893 - val_accuracy: 0.0000e+00\n","Epoch 29/50\n","1/1 [==============================] - 0s 51ms/step - loss: 3.8035 - accuracy: 1.0000 - val_loss: 103.6773 - val_accuracy: 0.0000e+00\n","Epoch 30/50\n","1/1 [==============================] - 0s 49ms/step - loss: 1.0059 - accuracy: 1.0000 - val_loss: 97.3952 - val_accuracy: 0.0000e+00\n","Epoch 31/50\n","1/1 [==============================] - 0s 53ms/step - loss: 0.4386 - accuracy: 1.0000 - val_loss: 91.8698 - val_accuracy: 0.0000e+00\n","Epoch 32/50\n","1/1 [==============================] - 0s 55ms/step - loss: 2.3810 - accuracy: 0.0000e+00 - val_loss: 88.7031 - val_accuracy: 0.0000e+00\n","Epoch 33/50\n","1/1 [==============================] - 0s 69ms/step - loss: 4.1055 - accuracy: 0.0000e+00 - val_loss: 88.4350 - val_accuracy: 0.0000e+00\n","Epoch 34/50\n","1/1 [==============================] - 0s 51ms/step - loss: 3.7602 - accuracy: 1.0000 - val_loss: 90.6174 - val_accuracy: 0.0000e+00\n","Epoch 35/50\n","1/1 [==============================] - 0s 53ms/step - loss: 2.3131 - accuracy: 1.0000 - val_loss: 93.9164 - val_accuracy: 1.0000\n","Epoch 36/50\n","1/1 [==============================] - 0s 54ms/step - loss: 1.3944 - accuracy: 1.0000 - val_loss: 96.6884 - val_accuracy: 1.0000\n","Epoch 37/50\n","1/1 [==============================] - 0s 57ms/step - loss: 1.1353 - accuracy: 1.0000 - val_loss: 98.0278 - val_accuracy: 1.0000\n","Epoch 38/50\n","1/1 [==============================] - 0s 52ms/step - loss: 0.9510 - accuracy: 1.0000 - val_loss: 98.2551 - val_accuracy: 0.0000e+00\n","Epoch 39/50\n","1/1 [==============================] - 0s 56ms/step - loss: 1.0388 - accuracy: 1.0000 - val_loss: 98.3337 - val_accuracy: 0.0000e+00\n","Epoch 40/50\n","1/1 [==============================] - 0s 51ms/step - loss: 1.6003 - accuracy: 0.5000 - val_loss: 98.9843 - val_accuracy: 0.0000e+00\n","Epoch 41/50\n","1/1 [==============================] - 0s 68ms/step - loss: 1.8014 - accuracy: 0.5000 - val_loss: 100.2930 - val_accuracy: 0.0000e+00\n","Epoch 42/50\n","1/1 [==============================] - 0s 54ms/step - loss: 1.1480 - accuracy: 0.5000 - val_loss: 101.7578 - val_accuracy: 0.0000e+00\n","Epoch 43/50\n","1/1 [==============================] - 0s 64ms/step - loss: 0.5034 - accuracy: 0.5000 - val_loss: 102.4853 - val_accuracy: 0.0000e+00\n","Epoch 44/50\n","1/1 [==============================] - 0s 53ms/step - loss: 0.5636 - accuracy: 1.0000 - val_loss: 101.6607 - val_accuracy: 0.0000e+00\n","Epoch 45/50\n","1/1 [==============================] - 0s 52ms/step - loss: 0.8447 - accuracy: 1.0000 - val_loss: 99.2127 - val_accuracy: 0.0000e+00\n","Epoch 46/50\n","1/1 [==============================] - 0s 52ms/step - loss: 0.7848 - accuracy: 1.0000 - val_loss: 96.0329 - val_accuracy: 0.0000e+00\n","Epoch 47/50\n","1/1 [==============================] - 0s 51ms/step - loss: 0.5816 - accuracy: 1.0000 - val_loss: 93.4359 - val_accuracy: 0.0000e+00\n","Epoch 48/50\n","1/1 [==============================] - 0s 69ms/step - loss: 0.5553 - accuracy: 1.0000 - val_loss: 92.3924 - val_accuracy: 0.0000e+00\n","Epoch 49/50\n","1/1 [==============================] - 0s 52ms/step - loss: 0.5403 - accuracy: 1.0000 - val_loss: 93.1251 - val_accuracy: 0.0000e+00\n","Epoch 50/50\n","1/1 [==============================] - 0s 71ms/step - loss: 0.3885 - accuracy: 1.0000 - val_loss: 95.0991 - val_accuracy: 0.0000e+00\n","1/1 [==============================] - 0s 74ms/step\n","1/1 [==============================] - 0s 38ms/step - loss: 149.6475 - accuracy: 0.6667\n","Test Loss: 149.6475, Test accuracy : 0.6667\n","Epoch 1/50\n","6/6 [==============================] - 1s 76ms/step - loss: 340.5280 - accuracy: 0.3174 - val_loss: 241.1237 - val_accuracy: 0.5789\n","Epoch 2/50\n","6/6 [==============================] - 0s 41ms/step - loss: 146.7759 - accuracy: 0.5988 - val_loss: 251.5828 - val_accuracy: 0.4737\n","Epoch 3/50\n","6/6 [==============================] - 0s 42ms/step - loss: 101.0081 - accuracy: 0.4910 - val_loss: 242.7575 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","6/6 [==============================] - 0s 42ms/step - loss: 68.4733 - accuracy: 0.5449 - val_loss: 249.1550 - val_accuracy: 0.8947\n","Epoch 5/50\n","6/6 [==============================] - 0s 43ms/step - loss: 50.2709 - accuracy: 0.5329 - val_loss: 249.2727 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","6/6 [==============================] - 0s 40ms/step - loss: 35.2851 - accuracy: 0.5868 - val_loss: 246.7842 - val_accuracy: 0.8947\n","Epoch 7/50\n","6/6 [==============================] - 0s 45ms/step - loss: 29.6551 - accuracy: 0.6946 - val_loss: 238.4178 - val_accuracy: 0.2632\n","Epoch 8/50\n","6/6 [==============================] - 0s 40ms/step - loss: 20.7435 - accuracy: 0.2934 - val_loss: 238.1293 - val_accuracy: 0.6316\n","Epoch 9/50\n","6/6 [==============================] - 0s 45ms/step - loss: 17.7357 - accuracy: 0.7904 - val_loss: 231.7332 - val_accuracy: 0.5263\n","Epoch 10/50\n","6/6 [==============================] - 0s 44ms/step - loss: 14.9427 - accuracy: 0.4371 - val_loss: 233.7396 - val_accuracy: 0.4211\n","Epoch 11/50\n","6/6 [==============================] - 0s 43ms/step - loss: 14.6716 - accuracy: 0.4671 - val_loss: 241.2543 - val_accuracy: 0.6842\n","Epoch 12/50\n","6/6 [==============================] - 0s 39ms/step - loss: 9.5088 - accuracy: 0.5329 - val_loss: 231.0468 - val_accuracy: 0.5789\n","Epoch 13/50\n","6/6 [==============================] - 0s 43ms/step - loss: 7.8808 - accuracy: 0.5749 - val_loss: 242.7943 - val_accuracy: 0.6316\n","Epoch 14/50\n","6/6 [==============================] - 0s 44ms/step - loss: 6.2219 - accuracy: 0.5689 - val_loss: 229.3670 - val_accuracy: 0.0526\n","Epoch 15/50\n","6/6 [==============================] - 0s 43ms/step - loss: 4.7244 - accuracy: 0.4910 - val_loss: 239.5036 - val_accuracy: 0.3158\n","Epoch 16/50\n","6/6 [==============================] - 0s 44ms/step - loss: 3.4258 - accuracy: 0.4731 - val_loss: 231.6261 - val_accuracy: 0.6316\n","Epoch 17/50\n","6/6 [==============================] - 0s 47ms/step - loss: 3.5639 - accuracy: 0.5329 - val_loss: 231.5607 - val_accuracy: 0.4737\n","Epoch 18/50\n","6/6 [==============================] - 0s 45ms/step - loss: 3.1811 - accuracy: 0.4970 - val_loss: 249.0441 - val_accuracy: 0.8947\n","Epoch 19/50\n","6/6 [==============================] - 0s 43ms/step - loss: 3.5150 - accuracy: 0.5389 - val_loss: 230.3356 - val_accuracy: 0.7895\n","Epoch 20/50\n","6/6 [==============================] - 0s 43ms/step - loss: 3.7873 - accuracy: 0.5988 - val_loss: 237.2134 - val_accuracy: 0.0000e+00\n","Epoch 21/50\n","6/6 [==============================] - 0s 45ms/step - loss: 3.8407 - accuracy: 0.5808 - val_loss: 237.1971 - val_accuracy: 0.5789\n","Epoch 22/50\n","6/6 [==============================] - 0s 44ms/step - loss: 2.4163 - accuracy: 0.4910 - val_loss: 230.6628 - val_accuracy: 0.1053\n","Epoch 23/50\n","6/6 [==============================] - 0s 43ms/step - loss: 2.8941 - accuracy: 0.4850 - val_loss: 237.7625 - val_accuracy: 0.3684\n","Epoch 24/50\n","6/6 [==============================] - 0s 40ms/step - loss: 1.9666 - accuracy: 0.6766 - val_loss: 236.1732 - val_accuracy: 0.5263\n","Epoch 25/50\n","6/6 [==============================] - 0s 45ms/step - loss: 2.1000 - accuracy: 0.4731 - val_loss: 232.7962 - val_accuracy: 0.2632\n","Epoch 26/50\n","6/6 [==============================] - 0s 42ms/step - loss: 1.5262 - accuracy: 0.4910 - val_loss: 240.8359 - val_accuracy: 0.5263\n","Epoch 27/50\n","6/6 [==============================] - 0s 40ms/step - loss: 1.3889 - accuracy: 0.6048 - val_loss: 234.3152 - val_accuracy: 0.4737\n","Epoch 28/50\n","6/6 [==============================] - 0s 40ms/step - loss: 1.1197 - accuracy: 0.5449 - val_loss: 232.7283 - val_accuracy: 0.6316\n","Epoch 29/50\n","6/6 [==============================] - 0s 43ms/step - loss: 0.7386 - accuracy: 0.5629 - val_loss: 238.3519 - val_accuracy: 0.3684\n","Epoch 30/50\n","6/6 [==============================] - 0s 44ms/step - loss: 0.6976 - accuracy: 0.4371 - val_loss: 234.2739 - val_accuracy: 0.4737\n","Epoch 31/50\n","6/6 [==============================] - 0s 52ms/step - loss: 0.8334 - accuracy: 0.6108 - val_loss: 234.5963 - val_accuracy: 0.2105\n","Epoch 32/50\n","6/6 [==============================] - 0s 57ms/step - loss: 2.2289 - accuracy: 0.4192 - val_loss: 234.9000 - val_accuracy: 0.8421\n","Epoch 33/50\n","6/6 [==============================] - 0s 60ms/step - loss: 1.2678 - accuracy: 0.5509 - val_loss: 238.1432 - val_accuracy: 0.7895\n","Epoch 34/50\n","6/6 [==============================] - 0s 53ms/step - loss: 1.4725 - accuracy: 0.5090 - val_loss: 230.7966 - val_accuracy: 0.2105\n","Epoch 35/50\n","6/6 [==============================] - 0s 57ms/step - loss: 1.3761 - accuracy: 0.5210 - val_loss: 238.4525 - val_accuracy: 0.8947\n","Epoch 36/50\n","6/6 [==============================] - 0s 60ms/step - loss: 1.7164 - accuracy: 0.5569 - val_loss: 239.0888 - val_accuracy: 0.7368\n","Epoch 37/50\n","6/6 [==============================] - 0s 55ms/step - loss: 6.7087 - accuracy: 0.6287 - val_loss: 238.5033 - val_accuracy: 0.8947\n","Epoch 38/50\n","6/6 [==============================] - 0s 54ms/step - loss: 8.3136 - accuracy: 0.6168 - val_loss: 233.8544 - val_accuracy: 0.5789\n","Epoch 39/50\n","6/6 [==============================] - 0s 55ms/step - loss: 2.8858 - accuracy: 0.4611 - val_loss: 235.2821 - val_accuracy: 0.3158\n","Epoch 40/50\n","6/6 [==============================] - 0s 59ms/step - loss: 6.2503 - accuracy: 0.5090 - val_loss: 236.3685 - val_accuracy: 0.4211\n","Epoch 41/50\n","6/6 [==============================] - 0s 58ms/step - loss: 3.6828 - accuracy: 0.5689 - val_loss: 234.1465 - val_accuracy: 0.0526\n","Epoch 42/50\n","6/6 [==============================] - 0s 63ms/step - loss: 5.0312 - accuracy: 0.6587 - val_loss: 230.7336 - val_accuracy: 0.0526\n","Epoch 43/50\n","6/6 [==============================] - 0s 53ms/step - loss: 4.4229 - accuracy: 0.5509 - val_loss: 241.3029 - val_accuracy: 0.0000e+00\n","Epoch 44/50\n","6/6 [==============================] - 0s 58ms/step - loss: 3.6584 - accuracy: 0.4132 - val_loss: 238.0975 - val_accuracy: 0.8421\n","Epoch 45/50\n","6/6 [==============================] - 0s 63ms/step - loss: 6.2447 - accuracy: 0.4910 - val_loss: 233.8931 - val_accuracy: 0.6842\n","Epoch 46/50\n","6/6 [==============================] - 0s 56ms/step - loss: 5.5635 - accuracy: 0.4910 - val_loss: 241.7324 - val_accuracy: 0.8947\n","Epoch 47/50\n","6/6 [==============================] - 0s 54ms/step - loss: 6.5178 - accuracy: 0.5090 - val_loss: 240.2853 - val_accuracy: 0.3684\n","Epoch 48/50\n","6/6 [==============================] - 0s 51ms/step - loss: 5.9766 - accuracy: 0.6826 - val_loss: 242.0760 - val_accuracy: 0.4737\n","Epoch 49/50\n","6/6 [==============================] - 0s 43ms/step - loss: 6.6328 - accuracy: 0.4431 - val_loss: 234.8782 - val_accuracy: 0.4211\n","Epoch 50/50\n","6/6 [==============================] - 0s 40ms/step - loss: 4.6734 - accuracy: 0.6287 - val_loss: 245.0037 - val_accuracy: 0.1053\n","2/2 [==============================] - 0s 9ms/step\n","2/2 [==============================] - 0s 14ms/step - loss: 17.1294 - accuracy: 0.9583\n","Test Loss: 17.1294, Test accuracy : 0.9583\n","Epoch 1/50\n","4/4 [==============================] - 1s 154ms/step - loss: 580.9197 - accuracy: 0.3651 - val_loss: 336.1620 - val_accuracy: 0.1333\n","Epoch 2/50\n","4/4 [==============================] - 0s 101ms/step - loss: 310.1158 - accuracy: 0.0873 - val_loss: 259.7466 - val_accuracy: 0.0667\n","Epoch 3/50\n","4/4 [==============================] - 0s 91ms/step - loss: 152.1066 - accuracy: 0.2460 - val_loss: 207.7871 - val_accuracy: 0.1333\n","Epoch 4/50\n","4/4 [==============================] - 0s 86ms/step - loss: 127.0834 - accuracy: 0.0873 - val_loss: 215.3826 - val_accuracy: 0.1333\n","Epoch 5/50\n","4/4 [==============================] - 0s 83ms/step - loss: 116.1485 - accuracy: 0.3175 - val_loss: 211.5848 - val_accuracy: 0.1333\n","Epoch 6/50\n","4/4 [==============================] - 0s 80ms/step - loss: 103.4578 - accuracy: 0.4286 - val_loss: 203.6353 - val_accuracy: 0.1333\n","Epoch 7/50\n","4/4 [==============================] - 0s 85ms/step - loss: 91.2331 - accuracy: 0.4444 - val_loss: 199.2563 - val_accuracy: 0.1333\n","Epoch 8/50\n","4/4 [==============================] - 0s 90ms/step - loss: 84.6471 - accuracy: 0.4524 - val_loss: 195.7950 - val_accuracy: 0.1333\n","Epoch 9/50\n","4/4 [==============================] - 0s 89ms/step - loss: 78.0401 - accuracy: 0.5556 - val_loss: 199.6454 - val_accuracy: 0.1333\n","Epoch 10/50\n","4/4 [==============================] - 0s 93ms/step - loss: 70.8514 - accuracy: 0.4524 - val_loss: 200.3852 - val_accuracy: 0.1333\n","Epoch 11/50\n","4/4 [==============================] - 0s 89ms/step - loss: 67.1067 - accuracy: 0.3651 - val_loss: 200.4164 - val_accuracy: 0.1333\n","Epoch 12/50\n","4/4 [==============================] - 0s 85ms/step - loss: 62.6764 - accuracy: 0.4286 - val_loss: 205.7101 - val_accuracy: 0.1333\n","Epoch 13/50\n","4/4 [==============================] - 0s 89ms/step - loss: 58.4353 - accuracy: 0.5317 - val_loss: 210.1414 - val_accuracy: 0.1333\n","Epoch 14/50\n","4/4 [==============================] - 0s 84ms/step - loss: 54.5275 - accuracy: 0.5000 - val_loss: 211.7721 - val_accuracy: 0.1333\n","Epoch 15/50\n","4/4 [==============================] - 0s 89ms/step - loss: 52.1862 - accuracy: 0.4286 - val_loss: 212.6546 - val_accuracy: 0.1333\n","Epoch 16/50\n","4/4 [==============================] - 0s 88ms/step - loss: 49.5569 - accuracy: 0.4683 - val_loss: 212.5810 - val_accuracy: 0.1333\n","Epoch 17/50\n","4/4 [==============================] - 0s 81ms/step - loss: 47.7254 - accuracy: 0.5000 - val_loss: 211.5618 - val_accuracy: 0.1333\n","Epoch 18/50\n","4/4 [==============================] - 0s 82ms/step - loss: 45.8537 - accuracy: 0.4603 - val_loss: 212.0464 - val_accuracy: 0.1333\n","Epoch 19/50\n","4/4 [==============================] - 0s 90ms/step - loss: 43.8893 - accuracy: 0.4524 - val_loss: 213.3689 - val_accuracy: 0.1333\n","Epoch 20/50\n","4/4 [==============================] - 0s 116ms/step - loss: 42.6880 - accuracy: 0.5079 - val_loss: 212.5796 - val_accuracy: 0.1333\n","Epoch 21/50\n","4/4 [==============================] - 0s 111ms/step - loss: 41.3723 - accuracy: 0.4762 - val_loss: 211.1811 - val_accuracy: 0.1333\n","Epoch 22/50\n","4/4 [==============================] - 0s 113ms/step - loss: 40.3792 - accuracy: 0.4921 - val_loss: 213.3746 - val_accuracy: 0.1333\n","Epoch 23/50\n","4/4 [==============================] - 1s 136ms/step - loss: 39.4478 - accuracy: 0.5000 - val_loss: 213.5571 - val_accuracy: 0.1333\n","Epoch 24/50\n","4/4 [==============================] - 0s 123ms/step - loss: 38.5949 - accuracy: 0.5079 - val_loss: 212.6309 - val_accuracy: 0.1333\n","Epoch 25/50\n","4/4 [==============================] - 0s 126ms/step - loss: 37.8175 - accuracy: 0.4841 - val_loss: 213.2039 - val_accuracy: 0.1333\n","Epoch 26/50\n","4/4 [==============================] - 0s 132ms/step - loss: 37.2548 - accuracy: 0.5238 - val_loss: 212.9136 - val_accuracy: 0.1333\n","Epoch 27/50\n","4/4 [==============================] - 0s 127ms/step - loss: 36.5701 - accuracy: 0.4603 - val_loss: 212.2961 - val_accuracy: 0.1333\n","Epoch 28/50\n","4/4 [==============================] - 0s 122ms/step - loss: 36.1101 - accuracy: 0.5159 - val_loss: 210.8423 - val_accuracy: 0.1333\n","Epoch 29/50\n","4/4 [==============================] - 1s 139ms/step - loss: 35.4841 - accuracy: 0.5476 - val_loss: 210.6370 - val_accuracy: 0.1333\n","Epoch 30/50\n","4/4 [==============================] - 0s 126ms/step - loss: 35.0260 - accuracy: 0.5238 - val_loss: 209.9719 - val_accuracy: 0.2000\n","Epoch 31/50\n","4/4 [==============================] - 0s 120ms/step - loss: 34.7389 - accuracy: 0.5238 - val_loss: 209.5337 - val_accuracy: 0.1333\n","Epoch 32/50\n","4/4 [==============================] - 0s 90ms/step - loss: 34.2866 - accuracy: 0.5635 - val_loss: 209.6440 - val_accuracy: 0.2000\n","Epoch 33/50\n","4/4 [==============================] - 0s 89ms/step - loss: 33.8950 - accuracy: 0.5556 - val_loss: 209.3795 - val_accuracy: 0.2000\n","Epoch 34/50\n","4/4 [==============================] - 0s 81ms/step - loss: 33.5311 - accuracy: 0.5952 - val_loss: 208.8701 - val_accuracy: 0.2000\n","Epoch 35/50\n","4/4 [==============================] - 0s 93ms/step - loss: 33.2513 - accuracy: 0.6032 - val_loss: 208.7153 - val_accuracy: 0.2667\n","Epoch 36/50\n","4/4 [==============================] - 0s 99ms/step - loss: 32.9812 - accuracy: 0.5952 - val_loss: 206.2112 - val_accuracy: 0.2000\n","Epoch 37/50\n","4/4 [==============================] - 0s 84ms/step - loss: 32.7726 - accuracy: 0.6349 - val_loss: 206.8752 - val_accuracy: 0.4000\n","Epoch 38/50\n","4/4 [==============================] - 0s 87ms/step - loss: 32.5505 - accuracy: 0.6111 - val_loss: 206.6365 - val_accuracy: 0.2000\n","Epoch 39/50\n","4/4 [==============================] - 0s 89ms/step - loss: 32.3010 - accuracy: 0.6032 - val_loss: 206.1641 - val_accuracy: 0.3333\n","Epoch 40/50\n","4/4 [==============================] - 0s 91ms/step - loss: 32.0473 - accuracy: 0.6270 - val_loss: 205.9610 - val_accuracy: 0.2667\n","Epoch 41/50\n","4/4 [==============================] - 0s 83ms/step - loss: 31.8181 - accuracy: 0.6270 - val_loss: 206.2814 - val_accuracy: 0.4000\n","Epoch 42/50\n","4/4 [==============================] - 0s 92ms/step - loss: 31.6653 - accuracy: 0.6587 - val_loss: 205.6379 - val_accuracy: 0.3333\n","Epoch 43/50\n","4/4 [==============================] - 0s 80ms/step - loss: 31.4970 - accuracy: 0.6587 - val_loss: 205.5129 - val_accuracy: 0.4000\n","Epoch 44/50\n","4/4 [==============================] - 0s 99ms/step - loss: 31.3094 - accuracy: 0.6667 - val_loss: 204.9766 - val_accuracy: 0.3333\n","Epoch 45/50\n","4/4 [==============================] - 0s 86ms/step - loss: 31.1348 - accuracy: 0.6508 - val_loss: 205.1157 - val_accuracy: 0.4000\n","Epoch 46/50\n","4/4 [==============================] - 0s 81ms/step - loss: 31.0476 - accuracy: 0.6746 - val_loss: 204.5323 - val_accuracy: 0.4000\n","Epoch 47/50\n","4/4 [==============================] - 0s 80ms/step - loss: 30.8843 - accuracy: 0.6825 - val_loss: 204.7729 - val_accuracy: 0.4000\n","Epoch 48/50\n","4/4 [==============================] - 0s 85ms/step - loss: 30.7573 - accuracy: 0.6667 - val_loss: 204.6670 - val_accuracy: 0.4000\n","Epoch 49/50\n","4/4 [==============================] - 0s 81ms/step - loss: 30.6463 - accuracy: 0.6825 - val_loss: 204.2371 - val_accuracy: 0.4000\n","Epoch 50/50\n","4/4 [==============================] - 0s 85ms/step - loss: 30.5457 - accuracy: 0.6746 - val_loss: 204.5370 - val_accuracy: 0.4000\n","2/2 [==============================] - 0s 12ms/step\n","2/2 [==============================] - 0s 13ms/step - loss: 252.0194 - accuracy: 0.6944\n","Test Loss: 252.0194, Test accuracy : 0.6944\n","Epoch 1/50\n","7/7 [==============================] - 2s 159ms/step - loss: 376.9304 - accuracy: 0.4601 - val_loss: 461.8164 - val_accuracy: 0.0000e+00\n","Epoch 2/50\n","7/7 [==============================] - 1s 109ms/step - loss: 179.9955 - accuracy: 0.4413 - val_loss: 463.6180 - val_accuracy: 0.7083\n","Epoch 3/50\n","7/7 [==============================] - 1s 103ms/step - loss: 113.7696 - accuracy: 0.3380 - val_loss: 439.0924 - val_accuracy: 0.0417\n","Epoch 4/50\n","7/7 [==============================] - 1s 77ms/step - loss: 99.2014 - accuracy: 0.5822 - val_loss: 417.8634 - val_accuracy: 0.1250\n","Epoch 5/50\n","7/7 [==============================] - 1s 82ms/step - loss: 78.6803 - accuracy: 0.3521 - val_loss: 389.3558 - val_accuracy: 0.0000e+00\n","Epoch 6/50\n","7/7 [==============================] - 1s 82ms/step - loss: 60.2427 - accuracy: 0.4460 - val_loss: 398.5623 - val_accuracy: 0.2083\n","Epoch 7/50\n","7/7 [==============================] - 1s 80ms/step - loss: 48.6805 - accuracy: 0.4272 - val_loss: 391.7248 - val_accuracy: 0.0417\n","Epoch 8/50\n","7/7 [==============================] - 1s 113ms/step - loss: 38.3626 - accuracy: 0.3662 - val_loss: 396.2126 - val_accuracy: 0.0833\n","Epoch 9/50\n","7/7 [==============================] - 1s 126ms/step - loss: 34.4784 - accuracy: 0.4225 - val_loss: 386.9735 - val_accuracy: 0.1250\n","Epoch 10/50\n","7/7 [==============================] - 1s 115ms/step - loss: 28.4151 - accuracy: 0.4413 - val_loss: 383.8665 - val_accuracy: 0.1250\n","Epoch 11/50\n","7/7 [==============================] - 1s 108ms/step - loss: 26.4863 - accuracy: 0.4507 - val_loss: 396.0583 - val_accuracy: 0.0000e+00\n","Epoch 12/50\n","7/7 [==============================] - 1s 115ms/step - loss: 22.5188 - accuracy: 0.3568 - val_loss: 395.8385 - val_accuracy: 0.0417\n","Epoch 13/50\n","7/7 [==============================] - 1s 118ms/step - loss: 19.5075 - accuracy: 0.3897 - val_loss: 374.8047 - val_accuracy: 0.0417\n","Epoch 14/50\n","7/7 [==============================] - 1s 91ms/step - loss: 18.1765 - accuracy: 0.3709 - val_loss: 399.2648 - val_accuracy: 0.0833\n","Epoch 15/50\n","7/7 [==============================] - 1s 82ms/step - loss: 18.2618 - accuracy: 0.5023 - val_loss: 395.7949 - val_accuracy: 0.2083\n","Epoch 16/50\n","7/7 [==============================] - 1s 81ms/step - loss: 17.1880 - accuracy: 0.3709 - val_loss: 372.6233 - val_accuracy: 0.1250\n","Epoch 17/50\n","7/7 [==============================] - 1s 79ms/step - loss: 14.7854 - accuracy: 0.4413 - val_loss: 382.6320 - val_accuracy: 0.0833\n","Epoch 18/50\n","7/7 [==============================] - 1s 85ms/step - loss: 12.2002 - accuracy: 0.3850 - val_loss: 390.8402 - val_accuracy: 0.1250\n","Epoch 19/50\n","7/7 [==============================] - 1s 77ms/step - loss: 12.5909 - accuracy: 0.4225 - val_loss: 385.1205 - val_accuracy: 0.0833\n","Epoch 20/50\n","7/7 [==============================] - 1s 79ms/step - loss: 10.2375 - accuracy: 0.4225 - val_loss: 394.8802 - val_accuracy: 0.1667\n","Epoch 21/50\n","7/7 [==============================] - 1s 76ms/step - loss: 12.0713 - accuracy: 0.5164 - val_loss: 382.8604 - val_accuracy: 0.1250\n","Epoch 22/50\n","7/7 [==============================] - 1s 79ms/step - loss: 11.5261 - accuracy: 0.4085 - val_loss: 401.6208 - val_accuracy: 0.3750\n","Epoch 23/50\n","7/7 [==============================] - 1s 78ms/step - loss: 11.7292 - accuracy: 0.4883 - val_loss: 391.3127 - val_accuracy: 0.1250\n","Epoch 24/50\n","7/7 [==============================] - 1s 80ms/step - loss: 14.0466 - accuracy: 0.5446 - val_loss: 391.7175 - val_accuracy: 0.1250\n","Epoch 25/50\n","7/7 [==============================] - 1s 84ms/step - loss: 10.5308 - accuracy: 0.4272 - val_loss: 400.4302 - val_accuracy: 0.1250\n","Epoch 26/50\n","7/7 [==============================] - 1s 80ms/step - loss: 10.0032 - accuracy: 0.4225 - val_loss: 391.0039 - val_accuracy: 0.1250\n","Epoch 27/50\n","7/7 [==============================] - 1s 88ms/step - loss: 15.9405 - accuracy: 0.4977 - val_loss: 387.7740 - val_accuracy: 0.3333\n","Epoch 28/50\n","7/7 [==============================] - 1s 79ms/step - loss: 12.0486 - accuracy: 0.3474 - val_loss: 387.6108 - val_accuracy: 0.1667\n","Epoch 29/50\n","7/7 [==============================] - 1s 78ms/step - loss: 6.2350 - accuracy: 0.4695 - val_loss: 396.3308 - val_accuracy: 0.1250\n","Epoch 30/50\n","7/7 [==============================] - 1s 82ms/step - loss: 8.6029 - accuracy: 0.4038 - val_loss: 391.6941 - val_accuracy: 0.2083\n","Epoch 31/50\n","7/7 [==============================] - 1s 80ms/step - loss: 8.1962 - accuracy: 0.5117 - val_loss: 397.0633 - val_accuracy: 0.1250\n","Epoch 32/50\n","7/7 [==============================] - 1s 112ms/step - loss: 10.4614 - accuracy: 0.3239 - val_loss: 392.6842 - val_accuracy: 0.1667\n","Epoch 33/50\n","7/7 [==============================] - 1s 105ms/step - loss: 16.8548 - accuracy: 0.4695 - val_loss: 392.7878 - val_accuracy: 0.2500\n","Epoch 34/50\n","7/7 [==============================] - 1s 111ms/step - loss: 18.6353 - accuracy: 0.2723 - val_loss: 403.1449 - val_accuracy: 0.1667\n","Epoch 35/50\n","7/7 [==============================] - 1s 112ms/step - loss: 31.6154 - accuracy: 0.6526 - val_loss: 391.4187 - val_accuracy: 0.2500\n","Epoch 36/50\n","7/7 [==============================] - 1s 118ms/step - loss: 36.4306 - accuracy: 0.2864 - val_loss: 402.3494 - val_accuracy: 0.1667\n","Epoch 37/50\n","7/7 [==============================] - 1s 115ms/step - loss: 25.1773 - accuracy: 0.6479 - val_loss: 400.3647 - val_accuracy: 0.3333\n","Epoch 38/50\n","7/7 [==============================] - 1s 116ms/step - loss: 26.3666 - accuracy: 0.5070 - val_loss: 400.8263 - val_accuracy: 0.2500\n","Epoch 39/50\n","7/7 [==============================] - 1s 97ms/step - loss: 15.0223 - accuracy: 0.2770 - val_loss: 395.5969 - val_accuracy: 0.4583\n","Epoch 40/50\n","7/7 [==============================] - 1s 78ms/step - loss: 13.7530 - accuracy: 0.4085 - val_loss: 399.7475 - val_accuracy: 0.2917\n","Epoch 41/50\n","7/7 [==============================] - 1s 79ms/step - loss: 13.8048 - accuracy: 0.4695 - val_loss: 437.4784 - val_accuracy: 0.2917\n","Epoch 42/50\n","7/7 [==============================] - 1s 79ms/step - loss: 20.6849 - accuracy: 0.5352 - val_loss: 390.7246 - val_accuracy: 0.1250\n","Epoch 43/50\n","7/7 [==============================] - 1s 80ms/step - loss: 12.9687 - accuracy: 0.2911 - val_loss: 424.9191 - val_accuracy: 0.2083\n","Epoch 44/50\n","7/7 [==============================] - 1s 91ms/step - loss: 8.6220 - accuracy: 0.4225 - val_loss: 409.4165 - val_accuracy: 0.3750\n","Epoch 45/50\n","7/7 [==============================] - 1s 87ms/step - loss: 7.5299 - accuracy: 0.3991 - val_loss: 405.7966 - val_accuracy: 0.3333\n","Epoch 46/50\n","7/7 [==============================] - 1s 81ms/step - loss: 5.5549 - accuracy: 0.6197 - val_loss: 402.4835 - val_accuracy: 0.2917\n","Epoch 47/50\n","7/7 [==============================] - 1s 82ms/step - loss: 4.9634 - accuracy: 0.3803 - val_loss: 410.7549 - val_accuracy: 0.2500\n","Epoch 48/50\n","7/7 [==============================] - 1s 78ms/step - loss: 4.7123 - accuracy: 0.4085 - val_loss: 407.2914 - val_accuracy: 0.2083\n","Epoch 49/50\n","7/7 [==============================] - 1s 86ms/step - loss: 4.5987 - accuracy: 0.4131 - val_loss: 409.3659 - val_accuracy: 0.2500\n","Epoch 50/50\n","7/7 [==============================] - 1s 76ms/step - loss: 3.9907 - accuracy: 0.3756 - val_loss: 411.0899 - val_accuracy: 0.2083\n","2/2 [==============================] - 0s 17ms/step\n","2/2 [==============================] - 0s 18ms/step - loss: 5.5740 - accuracy: 0.9667\n","Test Loss: 5.5740, Test accuracy : 0.9667\n","Epoch 1/50\n","11/11 [==============================] - 2s 97ms/step - loss: 255.5047 - accuracy: 0.3178 - val_loss: 92.8717 - val_accuracy: 0.1944\n","Epoch 2/50\n","11/11 [==============================] - 1s 81ms/step - loss: 160.7363 - accuracy: 0.2056 - val_loss: 96.6557 - val_accuracy: 0.5278\n","Epoch 3/50\n","11/11 [==============================] - 1s 77ms/step - loss: 135.4190 - accuracy: 0.3832 - val_loss: 94.5936 - val_accuracy: 0.2500\n","Epoch 4/50\n","11/11 [==============================] - 1s 76ms/step - loss: 127.4089 - accuracy: 0.2960 - val_loss: 76.8859 - val_accuracy: 0.1944\n","Epoch 5/50\n","11/11 [==============================] - 1s 75ms/step - loss: 110.6573 - accuracy: 0.3178 - val_loss: 74.0371 - val_accuracy: 0.5278\n","Epoch 6/50\n","11/11 [==============================] - 1s 78ms/step - loss: 102.0115 - accuracy: 0.4455 - val_loss: 71.4891 - val_accuracy: 0.5556\n","Epoch 7/50\n","11/11 [==============================] - 1s 74ms/step - loss: 99.3908 - accuracy: 0.3988 - val_loss: 77.9134 - val_accuracy: 0.3056\n","Epoch 8/50\n","11/11 [==============================] - 1s 74ms/step - loss: 85.3758 - accuracy: 0.5140 - val_loss: 62.1016 - val_accuracy: 0.5278\n","Epoch 9/50\n","11/11 [==============================] - 1s 73ms/step - loss: 75.6570 - accuracy: 0.4766 - val_loss: 64.6627 - val_accuracy: 0.5000\n","Epoch 10/50\n","11/11 [==============================] - 1s 76ms/step - loss: 75.0734 - accuracy: 0.4642 - val_loss: 64.3980 - val_accuracy: 0.4722\n","Epoch 11/50\n","11/11 [==============================] - 1s 86ms/step - loss: 66.0946 - accuracy: 0.4984 - val_loss: 61.6509 - val_accuracy: 0.5556\n","Epoch 12/50\n","11/11 [==============================] - 1s 112ms/step - loss: 61.3870 - accuracy: 0.4984 - val_loss: 63.6591 - val_accuracy: 0.5556\n","Epoch 13/50\n","11/11 [==============================] - 1s 103ms/step - loss: 54.9503 - accuracy: 0.5078 - val_loss: 64.4399 - val_accuracy: 0.4722\n","Epoch 14/50\n","11/11 [==============================] - 1s 109ms/step - loss: 53.9219 - accuracy: 0.4611 - val_loss: 69.6556 - val_accuracy: 0.2222\n","Epoch 15/50\n","11/11 [==============================] - 1s 105ms/step - loss: 50.3096 - accuracy: 0.4735 - val_loss: 63.4642 - val_accuracy: 0.5833\n","Epoch 16/50\n","11/11 [==============================] - 1s 101ms/step - loss: 44.2135 - accuracy: 0.5016 - val_loss: 64.4296 - val_accuracy: 0.4722\n","Epoch 17/50\n","11/11 [==============================] - 1s 78ms/step - loss: 41.5654 - accuracy: 0.4953 - val_loss: 64.2571 - val_accuracy: 0.5278\n","Epoch 18/50\n","11/11 [==============================] - 1s 83ms/step - loss: 38.7929 - accuracy: 0.5016 - val_loss: 59.3354 - val_accuracy: 0.5556\n","Epoch 19/50\n","11/11 [==============================] - 1s 81ms/step - loss: 37.1203 - accuracy: 0.5234 - val_loss: 57.7117 - val_accuracy: 0.5556\n","Epoch 20/50\n","11/11 [==============================] - 1s 81ms/step - loss: 35.7947 - accuracy: 0.5016 - val_loss: 57.9142 - val_accuracy: 0.5556\n","Epoch 21/50\n","11/11 [==============================] - 1s 78ms/step - loss: 36.1441 - accuracy: 0.4798 - val_loss: 62.0954 - val_accuracy: 0.5278\n","Epoch 22/50\n","11/11 [==============================] - 1s 81ms/step - loss: 34.9356 - accuracy: 0.4922 - val_loss: 58.9537 - val_accuracy: 0.5278\n","Epoch 23/50\n","11/11 [==============================] - 1s 77ms/step - loss: 32.3706 - accuracy: 0.4766 - val_loss: 61.9366 - val_accuracy: 0.5556\n","Epoch 24/50\n","11/11 [==============================] - 1s 76ms/step - loss: 31.2200 - accuracy: 0.5265 - val_loss: 55.7841 - val_accuracy: 0.5833\n","Epoch 25/50\n","11/11 [==============================] - 1s 76ms/step - loss: 30.7700 - accuracy: 0.4798 - val_loss: 67.4669 - val_accuracy: 0.5000\n","Epoch 26/50\n","11/11 [==============================] - 1s 75ms/step - loss: 32.3739 - accuracy: 0.4829 - val_loss: 61.1459 - val_accuracy: 0.4444\n","Epoch 27/50\n","11/11 [==============================] - 1s 76ms/step - loss: 37.2234 - accuracy: 0.4798 - val_loss: 63.2809 - val_accuracy: 0.5000\n","Epoch 28/50\n","11/11 [==============================] - 1s 102ms/step - loss: 35.3972 - accuracy: 0.4735 - val_loss: 63.7284 - val_accuracy: 0.5278\n","Epoch 29/50\n","11/11 [==============================] - 1s 110ms/step - loss: 32.6549 - accuracy: 0.5140 - val_loss: 63.9403 - val_accuracy: 0.6111\n","Epoch 30/50\n","11/11 [==============================] - 1s 108ms/step - loss: 30.7400 - accuracy: 0.4860 - val_loss: 67.1440 - val_accuracy: 0.3611\n","Epoch 31/50\n","11/11 [==============================] - 1s 113ms/step - loss: 34.1173 - accuracy: 0.4891 - val_loss: 66.2671 - val_accuracy: 0.5556\n","Epoch 32/50\n","11/11 [==============================] - 1s 115ms/step - loss: 32.2621 - accuracy: 0.4953 - val_loss: 65.0511 - val_accuracy: 0.4444\n","Epoch 33/50\n","11/11 [==============================] - 1s 83ms/step - loss: 28.5799 - accuracy: 0.4829 - val_loss: 61.6909 - val_accuracy: 0.6111\n","Epoch 34/50\n","11/11 [==============================] - 1s 74ms/step - loss: 25.5833 - accuracy: 0.5140 - val_loss: 94.3511 - val_accuracy: 0.3889\n","Epoch 35/50\n","11/11 [==============================] - 1s 73ms/step - loss: 117.9539 - accuracy: 0.4517 - val_loss: 98.8531 - val_accuracy: 0.2778\n","Epoch 36/50\n","11/11 [==============================] - 1s 75ms/step - loss: 62.6967 - accuracy: 0.4112 - val_loss: 83.6102 - val_accuracy: 0.2778\n","Epoch 37/50\n","11/11 [==============================] - 1s 83ms/step - loss: 39.1440 - accuracy: 0.4050 - val_loss: 73.0939 - val_accuracy: 0.2222\n","Epoch 38/50\n","11/11 [==============================] - 1s 78ms/step - loss: 31.7687 - accuracy: 0.4206 - val_loss: 71.3974 - val_accuracy: 0.4167\n","Epoch 39/50\n","11/11 [==============================] - 1s 80ms/step - loss: 26.5748 - accuracy: 0.5234 - val_loss: 65.7908 - val_accuracy: 0.3611\n","Epoch 40/50\n","11/11 [==============================] - 1s 80ms/step - loss: 23.7362 - accuracy: 0.4798 - val_loss: 71.1858 - val_accuracy: 0.4167\n","Epoch 41/50\n","11/11 [==============================] - 1s 81ms/step - loss: 21.2011 - accuracy: 0.5109 - val_loss: 70.2341 - val_accuracy: 0.4444\n","Epoch 42/50\n","11/11 [==============================] - 1s 80ms/step - loss: 19.4804 - accuracy: 0.5234 - val_loss: 66.9827 - val_accuracy: 0.3333\n","Epoch 43/50\n","11/11 [==============================] - 1s 80ms/step - loss: 18.2905 - accuracy: 0.5452 - val_loss: 65.8734 - val_accuracy: 0.5278\n","Epoch 44/50\n","11/11 [==============================] - 1s 96ms/step - loss: 17.6946 - accuracy: 0.5327 - val_loss: 68.4859 - val_accuracy: 0.3333\n","Epoch 45/50\n","11/11 [==============================] - 1s 98ms/step - loss: 17.0314 - accuracy: 0.5421 - val_loss: 66.2211 - val_accuracy: 0.5000\n","Epoch 46/50\n","11/11 [==============================] - 1s 103ms/step - loss: 16.7149 - accuracy: 0.5296 - val_loss: 73.1144 - val_accuracy: 0.3333\n","Epoch 47/50\n","11/11 [==============================] - 1s 103ms/step - loss: 16.5858 - accuracy: 0.5763 - val_loss: 63.1392 - val_accuracy: 0.5556\n","Epoch 48/50\n","11/11 [==============================] - 1s 106ms/step - loss: 18.6783 - accuracy: 0.5421 - val_loss: 66.3437 - val_accuracy: 0.5556\n","Epoch 49/50\n","11/11 [==============================] - 1s 98ms/step - loss: 19.1306 - accuracy: 0.5701 - val_loss: 69.0533 - val_accuracy: 0.4444\n","Epoch 50/50\n","11/11 [==============================] - 1s 80ms/step - loss: 21.4586 - accuracy: 0.5265 - val_loss: 62.7034 - val_accuracy: 0.5833\n","3/3 [==============================] - 0s 14ms/step\n","3/3 [==============================] - 0s 16ms/step - loss: 1.1614 - accuracy: 0.9333\n","Test Loss: 1.1614, Test accuracy : 0.9333\n","Epoch 1/50\n","10/10 [==============================] - 2s 103ms/step - loss: 255.5944 - accuracy: 0.2345 - val_loss: 352.0907 - val_accuracy: 0.3429\n","Epoch 2/50\n","10/10 [==============================] - 1s 86ms/step - loss: 167.1749 - accuracy: 0.1954 - val_loss: 349.7706 - val_accuracy: 0.0571\n","Epoch 3/50\n","10/10 [==============================] - 1s 79ms/step - loss: 132.0913 - accuracy: 0.1433 - val_loss: 361.4792 - val_accuracy: 0.0857\n","Epoch 4/50\n","10/10 [==============================] - 1s 102ms/step - loss: 111.0158 - accuracy: 0.2150 - val_loss: 346.6440 - val_accuracy: 0.0857\n","Epoch 5/50\n","10/10 [==============================] - 1s 104ms/step - loss: 104.1223 - accuracy: 0.1889 - val_loss: 360.3156 - val_accuracy: 0.0571\n","Epoch 6/50\n","10/10 [==============================] - 1s 108ms/step - loss: 81.1846 - accuracy: 0.2150 - val_loss: 348.1081 - val_accuracy: 0.1143\n","Epoch 7/50\n","10/10 [==============================] - 1s 103ms/step - loss: 72.5132 - accuracy: 0.1889 - val_loss: 354.4239 - val_accuracy: 0.1143\n","Epoch 8/50\n","10/10 [==============================] - 1s 106ms/step - loss: 66.5327 - accuracy: 0.2020 - val_loss: 355.6609 - val_accuracy: 0.0857\n","Epoch 9/50\n","10/10 [==============================] - 1s 103ms/step - loss: 60.1337 - accuracy: 0.1857 - val_loss: 348.0589 - val_accuracy: 0.0857\n","Epoch 10/50\n","10/10 [==============================] - 1s 77ms/step - loss: 59.9222 - accuracy: 0.2020 - val_loss: 356.1122 - val_accuracy: 0.0857\n","Epoch 11/50\n","10/10 [==============================] - 1s 79ms/step - loss: 54.8723 - accuracy: 0.2085 - val_loss: 356.3125 - val_accuracy: 0.0857\n","Epoch 12/50\n","10/10 [==============================] - 1s 84ms/step - loss: 45.3733 - accuracy: 0.2052 - val_loss: 369.7001 - val_accuracy: 0.0571\n","Epoch 13/50\n","10/10 [==============================] - 1s 79ms/step - loss: 41.6879 - accuracy: 0.1987 - val_loss: 356.4056 - val_accuracy: 0.0857\n","Epoch 14/50\n","10/10 [==============================] - 1s 78ms/step - loss: 38.2710 - accuracy: 0.1922 - val_loss: 358.4743 - val_accuracy: 0.0571\n","Epoch 15/50\n","10/10 [==============================] - 1s 81ms/step - loss: 37.2486 - accuracy: 0.1954 - val_loss: 350.6061 - val_accuracy: 0.1143\n","Epoch 16/50\n","10/10 [==============================] - 1s 78ms/step - loss: 32.8816 - accuracy: 0.2280 - val_loss: 359.4030 - val_accuracy: 0.0857\n","Epoch 17/50\n","10/10 [==============================] - 1s 77ms/step - loss: 32.0355 - accuracy: 0.1922 - val_loss: 343.0184 - val_accuracy: 0.0857\n","Epoch 18/50\n","10/10 [==============================] - 1s 83ms/step - loss: 30.7477 - accuracy: 0.1922 - val_loss: 338.9796 - val_accuracy: 0.0571\n","Epoch 19/50\n","10/10 [==============================] - 1s 76ms/step - loss: 32.5726 - accuracy: 0.2117 - val_loss: 354.8990 - val_accuracy: 0.1429\n","Epoch 20/50\n","10/10 [==============================] - 1s 83ms/step - loss: 34.2182 - accuracy: 0.2117 - val_loss: 332.1205 - val_accuracy: 0.0571\n","Epoch 21/50\n","10/10 [==============================] - 1s 79ms/step - loss: 28.9968 - accuracy: 0.1987 - val_loss: 344.0560 - val_accuracy: 0.0571\n","Epoch 22/50\n","10/10 [==============================] - 1s 95ms/step - loss: 43.3201 - accuracy: 0.1889 - val_loss: 335.6837 - val_accuracy: 0.0571\n","Epoch 23/50\n","10/10 [==============================] - 1s 104ms/step - loss: 43.8902 - accuracy: 0.2052 - val_loss: 332.2130 - val_accuracy: 0.0857\n","Epoch 24/50\n","10/10 [==============================] - 1s 106ms/step - loss: 37.4561 - accuracy: 0.1954 - val_loss: 344.8163 - val_accuracy: 0.0571\n","Epoch 25/50\n","10/10 [==============================] - 1s 110ms/step - loss: 108.4183 - accuracy: 0.2117 - val_loss: 329.8041 - val_accuracy: 0.0857\n","Epoch 26/50\n","10/10 [==============================] - 1s 113ms/step - loss: 75.6241 - accuracy: 0.2248 - val_loss: 336.6093 - val_accuracy: 0.1143\n","Epoch 27/50\n","10/10 [==============================] - 1s 106ms/step - loss: 56.6551 - accuracy: 0.2085 - val_loss: 346.1082 - val_accuracy: 0.0857\n","Epoch 28/50\n","10/10 [==============================] - 1s 84ms/step - loss: 47.1213 - accuracy: 0.2117 - val_loss: 362.6677 - val_accuracy: 0.0857\n","Epoch 29/50\n","10/10 [==============================] - 1s 84ms/step - loss: 40.5239 - accuracy: 0.1694 - val_loss: 357.9827 - val_accuracy: 0.0857\n","Epoch 30/50\n","10/10 [==============================] - 1s 82ms/step - loss: 40.5453 - accuracy: 0.1857 - val_loss: 354.9134 - val_accuracy: 0.1143\n","Epoch 31/50\n","10/10 [==============================] - 1s 77ms/step - loss: 32.3928 - accuracy: 0.2476 - val_loss: 356.8670 - val_accuracy: 0.0857\n","Epoch 32/50\n","10/10 [==============================] - 1s 79ms/step - loss: 27.1563 - accuracy: 0.1726 - val_loss: 348.1722 - val_accuracy: 0.0571\n","Epoch 33/50\n","10/10 [==============================] - 1s 78ms/step - loss: 26.4095 - accuracy: 0.2150 - val_loss: 353.7065 - val_accuracy: 0.0571\n","Epoch 34/50\n","10/10 [==============================] - 1s 77ms/step - loss: 25.2144 - accuracy: 0.1726 - val_loss: 358.3272 - val_accuracy: 0.1143\n","Epoch 35/50\n","10/10 [==============================] - 1s 81ms/step - loss: 25.9471 - accuracy: 0.2834 - val_loss: 350.2162 - val_accuracy: 0.0857\n","Epoch 36/50\n","10/10 [==============================] - 1s 82ms/step - loss: 25.1688 - accuracy: 0.3160 - val_loss: 348.7534 - val_accuracy: 0.0857\n","Epoch 37/50\n","10/10 [==============================] - 1s 79ms/step - loss: 26.1746 - accuracy: 0.2899 - val_loss: 365.8095 - val_accuracy: 0.1143\n","Epoch 38/50\n","10/10 [==============================] - 1s 76ms/step - loss: 25.4513 - accuracy: 0.2866 - val_loss: 361.3232 - val_accuracy: 0.1143\n","Epoch 39/50\n","10/10 [==============================] - 1s 79ms/step - loss: 20.0545 - accuracy: 0.3420 - val_loss: 352.1439 - val_accuracy: 0.0857\n","Epoch 40/50\n","10/10 [==============================] - 1s 95ms/step - loss: 20.0815 - accuracy: 0.3355 - val_loss: 352.1033 - val_accuracy: 0.1143\n","Epoch 41/50\n","10/10 [==============================] - 1s 125ms/step - loss: 16.5260 - accuracy: 0.3192 - val_loss: 359.2013 - val_accuracy: 0.0857\n","Epoch 42/50\n","10/10 [==============================] - 1s 124ms/step - loss: 15.5217 - accuracy: 0.3127 - val_loss: 351.5337 - val_accuracy: 0.1143\n","Epoch 43/50\n","10/10 [==============================] - 1s 110ms/step - loss: 14.6228 - accuracy: 0.3257 - val_loss: 355.5242 - val_accuracy: 0.0857\n","Epoch 44/50\n","10/10 [==============================] - 1s 122ms/step - loss: 14.2890 - accuracy: 0.3257 - val_loss: 344.1359 - val_accuracy: 0.0857\n","Epoch 45/50\n","10/10 [==============================] - 1s 126ms/step - loss: 13.2437 - accuracy: 0.3485 - val_loss: 358.0287 - val_accuracy: 0.0857\n","Epoch 46/50\n","10/10 [==============================] - 1s 127ms/step - loss: 12.3548 - accuracy: 0.3257 - val_loss: 343.8726 - val_accuracy: 0.1143\n","Epoch 47/50\n","10/10 [==============================] - 1s 111ms/step - loss: 11.1422 - accuracy: 0.3388 - val_loss: 353.6137 - val_accuracy: 0.0857\n","Epoch 48/50\n","10/10 [==============================] - 1s 135ms/step - loss: 10.4042 - accuracy: 0.3420 - val_loss: 347.6175 - val_accuracy: 0.0857\n","Epoch 49/50\n","10/10 [==============================] - 1s 90ms/step - loss: 9.5224 - accuracy: 0.3355 - val_loss: 355.3987 - val_accuracy: 0.1143\n","Epoch 50/50\n","10/10 [==============================] - 1s 77ms/step - loss: 9.0838 - accuracy: 0.3290 - val_loss: 341.2521 - val_accuracy: 0.1143\n","3/3 [==============================] - 0s 14ms/step\n","3/3 [==============================] - 0s 15ms/step - loss: 1.4251 - accuracy: 0.7126\n","Test Loss: 1.4251, Test accuracy : 0.7126\n","Epoch 1/50\n","16/16 [==============================] - 2s 92ms/step - loss: 210.9317 - accuracy: 0.2712 - val_loss: 352.8672 - val_accuracy: 0.2963\n","Epoch 2/50\n","16/16 [==============================] - 1s 78ms/step - loss: 127.0047 - accuracy: 0.3975 - val_loss: 301.7643 - val_accuracy: 0.3889\n","Epoch 3/50\n","16/16 [==============================] - 1s 77ms/step - loss: 97.0243 - accuracy: 0.4327 - val_loss: 295.9331 - val_accuracy: 0.3704\n","Epoch 4/50\n","16/16 [==============================] - 1s 78ms/step - loss: 81.0029 - accuracy: 0.4203 - val_loss: 291.7646 - val_accuracy: 0.3704\n","Epoch 5/50\n","16/16 [==============================] - 1s 79ms/step - loss: 70.2702 - accuracy: 0.4348 - val_loss: 289.4591 - val_accuracy: 0.3333\n","Epoch 6/50\n","16/16 [==============================] - 2s 104ms/step - loss: 66.1481 - accuracy: 0.3747 - val_loss: 287.4038 - val_accuracy: 0.3704\n","Epoch 7/50\n","16/16 [==============================] - 2s 100ms/step - loss: 62.5986 - accuracy: 0.4037 - val_loss: 275.2834 - val_accuracy: 0.3333\n","Epoch 8/50\n","16/16 [==============================] - 2s 104ms/step - loss: 48.4432 - accuracy: 0.3934 - val_loss: 275.9757 - val_accuracy: 0.3333\n","Epoch 9/50\n","16/16 [==============================] - 1s 90ms/step - loss: 47.2980 - accuracy: 0.3685 - val_loss: 274.2180 - val_accuracy: 0.3519\n","Epoch 10/50\n","16/16 [==============================] - 1s 75ms/step - loss: 42.3781 - accuracy: 0.3685 - val_loss: 277.8320 - val_accuracy: 0.3333\n","Epoch 11/50\n","16/16 [==============================] - 1s 77ms/step - loss: 39.5852 - accuracy: 0.3437 - val_loss: 270.5603 - val_accuracy: 0.2963\n","Epoch 12/50\n","16/16 [==============================] - 1s 76ms/step - loss: 35.9745 - accuracy: 0.3292 - val_loss: 271.5283 - val_accuracy: 0.3519\n","Epoch 13/50\n","16/16 [==============================] - 1s 75ms/step - loss: 34.8215 - accuracy: 0.3437 - val_loss: 272.5418 - val_accuracy: 0.2778\n","Epoch 14/50\n","16/16 [==============================] - 1s 77ms/step - loss: 32.7628 - accuracy: 0.3085 - val_loss: 275.9789 - val_accuracy: 0.3333\n","Epoch 15/50\n","16/16 [==============================] - 1s 75ms/step - loss: 30.3427 - accuracy: 0.3934 - val_loss: 262.0561 - val_accuracy: 0.2778\n","Epoch 16/50\n","16/16 [==============================] - 1s 76ms/step - loss: 31.7153 - accuracy: 0.3644 - val_loss: 281.9988 - val_accuracy: 0.2963\n","Epoch 17/50\n","16/16 [==============================] - 1s 90ms/step - loss: 101.2911 - accuracy: 0.3975 - val_loss: 273.0658 - val_accuracy: 0.3148\n","Epoch 18/50\n","16/16 [==============================] - 2s 101ms/step - loss: 86.4625 - accuracy: 0.3499 - val_loss: 274.4974 - val_accuracy: 0.3148\n","Epoch 19/50\n","16/16 [==============================] - 2s 102ms/step - loss: 44.0728 - accuracy: 0.3747 - val_loss: 271.6065 - val_accuracy: 0.2593\n","Epoch 20/50\n","16/16 [==============================] - 2s 101ms/step - loss: 36.3319 - accuracy: 0.3789 - val_loss: 276.1502 - val_accuracy: 0.3148\n","Epoch 21/50\n","16/16 [==============================] - 1s 85ms/step - loss: 41.3542 - accuracy: 0.4120 - val_loss: 264.8255 - val_accuracy: 0.3148\n","Epoch 22/50\n","16/16 [==============================] - 1s 76ms/step - loss: 40.9762 - accuracy: 0.4513 - val_loss: 281.4727 - val_accuracy: 0.2963\n","Epoch 23/50\n","16/16 [==============================] - 1s 77ms/step - loss: 34.4775 - accuracy: 0.4327 - val_loss: 285.4225 - val_accuracy: 0.2963\n","Epoch 24/50\n","16/16 [==============================] - 1s 78ms/step - loss: 31.5556 - accuracy: 0.4969 - val_loss: 276.2477 - val_accuracy: 0.2963\n","Epoch 25/50\n","16/16 [==============================] - 1s 75ms/step - loss: 29.3331 - accuracy: 0.4741 - val_loss: 277.6244 - val_accuracy: 0.3148\n","Epoch 26/50\n","16/16 [==============================] - 1s 79ms/step - loss: 26.1141 - accuracy: 0.5549 - val_loss: 276.0492 - val_accuracy: 0.2037\n","Epoch 27/50\n","16/16 [==============================] - 1s 78ms/step - loss: 24.0316 - accuracy: 0.5487 - val_loss: 274.3593 - val_accuracy: 0.2963\n","Epoch 28/50\n","16/16 [==============================] - 1s 78ms/step - loss: 22.9545 - accuracy: 0.5859 - val_loss: 273.3257 - val_accuracy: 0.3519\n","Epoch 29/50\n","16/16 [==============================] - 1s 90ms/step - loss: 22.1774 - accuracy: 0.6046 - val_loss: 258.6884 - val_accuracy: 0.3148\n","Epoch 30/50\n","16/16 [==============================] - 2s 104ms/step - loss: 33.3912 - accuracy: 0.5197 - val_loss: 288.0599 - val_accuracy: 0.3519\n","Epoch 31/50\n","16/16 [==============================] - 2s 102ms/step - loss: 30.0103 - accuracy: 0.5114 - val_loss: 290.1320 - val_accuracy: 0.3519\n","Epoch 32/50\n","16/16 [==============================] - 2s 104ms/step - loss: 25.2866 - accuracy: 0.4969 - val_loss: 274.1091 - val_accuracy: 0.3148\n","Epoch 33/50\n","16/16 [==============================] - 1s 86ms/step - loss: 26.2430 - accuracy: 0.5549 - val_loss: 282.5801 - val_accuracy: 0.3519\n","Epoch 34/50\n","16/16 [==============================] - 1s 75ms/step - loss: 21.0860 - accuracy: 0.5549 - val_loss: 267.1646 - val_accuracy: 0.3333\n","Epoch 35/50\n","16/16 [==============================] - 1s 79ms/step - loss: 17.6517 - accuracy: 0.5714 - val_loss: 270.5623 - val_accuracy: 0.3148\n","Epoch 36/50\n","16/16 [==============================] - 1s 78ms/step - loss: 17.8266 - accuracy: 0.5818 - val_loss: 267.1783 - val_accuracy: 0.2963\n","Epoch 37/50\n","16/16 [==============================] - 1s 78ms/step - loss: 16.3701 - accuracy: 0.6025 - val_loss: 266.1478 - val_accuracy: 0.3519\n","Epoch 38/50\n","16/16 [==============================] - 1s 78ms/step - loss: 14.7181 - accuracy: 0.6108 - val_loss: 265.9931 - val_accuracy: 0.3519\n","Epoch 39/50\n","16/16 [==============================] - 1s 78ms/step - loss: 14.2164 - accuracy: 0.6563 - val_loss: 270.9071 - val_accuracy: 0.3333\n","Epoch 40/50\n","16/16 [==============================] - 1s 76ms/step - loss: 18.8993 - accuracy: 0.6439 - val_loss: 268.1241 - val_accuracy: 0.3148\n","Epoch 41/50\n","16/16 [==============================] - 1s 91ms/step - loss: 15.9294 - accuracy: 0.6749 - val_loss: 266.8959 - val_accuracy: 0.3148\n","Epoch 42/50\n","16/16 [==============================] - 2s 103ms/step - loss: 13.7961 - accuracy: 0.6812 - val_loss: 264.2435 - val_accuracy: 0.3519\n","Epoch 43/50\n","16/16 [==============================] - 2s 101ms/step - loss: 13.1762 - accuracy: 0.6832 - val_loss: 273.2750 - val_accuracy: 0.3148\n","Epoch 44/50\n","16/16 [==============================] - 2s 102ms/step - loss: 12.9083 - accuracy: 0.6729 - val_loss: 262.0447 - val_accuracy: 0.3333\n","Epoch 45/50\n","16/16 [==============================] - 1s 77ms/step - loss: 13.3141 - accuracy: 0.6729 - val_loss: 265.9823 - val_accuracy: 0.3148\n","Epoch 46/50\n","16/16 [==============================] - 1s 77ms/step - loss: 12.2933 - accuracy: 0.6957 - val_loss: 268.0696 - val_accuracy: 0.3333\n","Epoch 47/50\n","16/16 [==============================] - 1s 77ms/step - loss: 11.4000 - accuracy: 0.6915 - val_loss: 268.6451 - val_accuracy: 0.3148\n","Epoch 48/50\n","16/16 [==============================] - 1s 76ms/step - loss: 10.8037 - accuracy: 0.7122 - val_loss: 264.3649 - val_accuracy: 0.3333\n","Epoch 49/50\n","16/16 [==============================] - 1s 76ms/step - loss: 10.5800 - accuracy: 0.7184 - val_loss: 267.9963 - val_accuracy: 0.2778\n","Epoch 50/50\n","16/16 [==============================] - 1s 78ms/step - loss: 10.3150 - accuracy: 0.7039 - val_loss: 282.9755 - val_accuracy: 0.3333\n","5/5 [==============================] - 0s 16ms/step\n","5/5 [==============================] - 0s 14ms/step - loss: 131.5932 - accuracy: 0.9407\n","Test Loss: 131.5932, Test accuracy : 0.9407\n","Epoch 1/50\n","7/7 [==============================] - 2s 136ms/step - loss: 326.5246 - accuracy: 0.2976 - val_loss: 170.4915 - val_accuracy: 0.3043\n","Epoch 2/50\n","7/7 [==============================] - 1s 103ms/step - loss: 147.8120 - accuracy: 0.4634 - val_loss: 149.8688 - val_accuracy: 0.2174\n","Epoch 3/50\n","7/7 [==============================] - 1s 120ms/step - loss: 115.4224 - accuracy: 0.4634 - val_loss: 138.6913 - val_accuracy: 0.2174\n","Epoch 4/50\n","7/7 [==============================] - 1s 107ms/step - loss: 98.1700 - accuracy: 0.4878 - val_loss: 136.6906 - val_accuracy: 0.2174\n","Epoch 5/50\n","7/7 [==============================] - 1s 83ms/step - loss: 86.0110 - accuracy: 0.4439 - val_loss: 136.3660 - val_accuracy: 0.2174\n","Epoch 6/50\n","7/7 [==============================] - 1s 79ms/step - loss: 72.5339 - accuracy: 0.4000 - val_loss: 131.9095 - val_accuracy: 0.2174\n","Epoch 7/50\n","7/7 [==============================] - 1s 78ms/step - loss: 64.7096 - accuracy: 0.4439 - val_loss: 123.8440 - val_accuracy: 0.1739\n","Epoch 8/50\n","7/7 [==============================] - 1s 81ms/step - loss: 57.3877 - accuracy: 0.4732 - val_loss: 120.9849 - val_accuracy: 0.3478\n","Epoch 9/50\n","7/7 [==============================] - 1s 77ms/step - loss: 51.0650 - accuracy: 0.4439 - val_loss: 118.9470 - val_accuracy: 0.4348\n","Epoch 10/50\n","7/7 [==============================] - 1s 82ms/step - loss: 45.3422 - accuracy: 0.4829 - val_loss: 119.0831 - val_accuracy: 0.4348\n","Epoch 11/50\n","7/7 [==============================] - 1s 79ms/step - loss: 41.8626 - accuracy: 0.4683 - val_loss: 119.3361 - val_accuracy: 0.5652\n","Epoch 12/50\n","7/7 [==============================] - 1s 82ms/step - loss: 38.0023 - accuracy: 0.4878 - val_loss: 117.8829 - val_accuracy: 0.3913\n","Epoch 13/50\n","7/7 [==============================] - 1s 79ms/step - loss: 34.7751 - accuracy: 0.4976 - val_loss: 118.0555 - val_accuracy: 0.5217\n","Epoch 14/50\n","7/7 [==============================] - 1s 81ms/step - loss: 32.0987 - accuracy: 0.4829 - val_loss: 118.1487 - val_accuracy: 0.5652\n","Epoch 15/50\n","7/7 [==============================] - 1s 81ms/step - loss: 29.8172 - accuracy: 0.4683 - val_loss: 116.3084 - val_accuracy: 0.3478\n","Epoch 16/50\n","7/7 [==============================] - 1s 81ms/step - loss: 27.1660 - accuracy: 0.5122 - val_loss: 117.2537 - val_accuracy: 0.5652\n","Epoch 17/50\n","7/7 [==============================] - 1s 79ms/step - loss: 25.1368 - accuracy: 0.5610 - val_loss: 117.6249 - val_accuracy: 0.3478\n","Epoch 18/50\n","7/7 [==============================] - 1s 80ms/step - loss: 23.2968 - accuracy: 0.4634 - val_loss: 120.0522 - val_accuracy: 0.4348\n","Epoch 19/50\n","7/7 [==============================] - 1s 82ms/step - loss: 21.6918 - accuracy: 0.4732 - val_loss: 118.6214 - val_accuracy: 0.4783\n","Epoch 20/50\n","7/7 [==============================] - 1s 79ms/step - loss: 19.8315 - accuracy: 0.5610 - val_loss: 120.4276 - val_accuracy: 0.4783\n","Epoch 21/50\n","7/7 [==============================] - 1s 79ms/step - loss: 18.6196 - accuracy: 0.5512 - val_loss: 119.4603 - val_accuracy: 0.5652\n","Epoch 22/50\n","7/7 [==============================] - 1s 82ms/step - loss: 17.2612 - accuracy: 0.5415 - val_loss: 121.1148 - val_accuracy: 0.4348\n","Epoch 23/50\n","7/7 [==============================] - 1s 104ms/step - loss: 15.8728 - accuracy: 0.6049 - val_loss: 122.6681 - val_accuracy: 0.5217\n","Epoch 24/50\n","7/7 [==============================] - 1s 104ms/step - loss: 14.7699 - accuracy: 0.6000 - val_loss: 120.5252 - val_accuracy: 0.4783\n","Epoch 25/50\n","7/7 [==============================] - 1s 102ms/step - loss: 14.3336 - accuracy: 0.5756 - val_loss: 124.3891 - val_accuracy: 0.5217\n","Epoch 26/50\n","7/7 [==============================] - 1s 103ms/step - loss: 13.4047 - accuracy: 0.5561 - val_loss: 122.9926 - val_accuracy: 0.4783\n","Epoch 27/50\n","7/7 [==============================] - 1s 106ms/step - loss: 12.8067 - accuracy: 0.5659 - val_loss: 125.0089 - val_accuracy: 0.4783\n","Epoch 28/50\n","7/7 [==============================] - 1s 111ms/step - loss: 12.2945 - accuracy: 0.5805 - val_loss: 123.1724 - val_accuracy: 0.4348\n","Epoch 29/50\n","7/7 [==============================] - 1s 110ms/step - loss: 12.4432 - accuracy: 0.5415 - val_loss: 127.6163 - val_accuracy: 0.5217\n","Epoch 30/50\n","7/7 [==============================] - 1s 109ms/step - loss: 11.8366 - accuracy: 0.5854 - val_loss: 122.2739 - val_accuracy: 0.4783\n","Epoch 31/50\n","7/7 [==============================] - 1s 93ms/step - loss: 11.9212 - accuracy: 0.5756 - val_loss: 130.6936 - val_accuracy: 0.4783\n","Epoch 32/50\n","7/7 [==============================] - 1s 82ms/step - loss: 10.6913 - accuracy: 0.6341 - val_loss: 126.5915 - val_accuracy: 0.5652\n","Epoch 33/50\n","7/7 [==============================] - 1s 77ms/step - loss: 10.6151 - accuracy: 0.5951 - val_loss: 127.4929 - val_accuracy: 0.4783\n","Epoch 34/50\n","7/7 [==============================] - 1s 80ms/step - loss: 10.3100 - accuracy: 0.5951 - val_loss: 125.9677 - val_accuracy: 0.5217\n","Epoch 35/50\n","7/7 [==============================] - 1s 79ms/step - loss: 10.3276 - accuracy: 0.5610 - val_loss: 127.7742 - val_accuracy: 0.4348\n","Epoch 36/50\n","7/7 [==============================] - 1s 84ms/step - loss: 9.2170 - accuracy: 0.5756 - val_loss: 126.7626 - val_accuracy: 0.4783\n","Epoch 37/50\n","7/7 [==============================] - 1s 81ms/step - loss: 8.7051 - accuracy: 0.5561 - val_loss: 126.1647 - val_accuracy: 0.4348\n","Epoch 38/50\n","7/7 [==============================] - 1s 79ms/step - loss: 8.3204 - accuracy: 0.5854 - val_loss: 127.0819 - val_accuracy: 0.5217\n","Epoch 39/50\n","7/7 [==============================] - 1s 85ms/step - loss: 7.9335 - accuracy: 0.5512 - val_loss: 126.4811 - val_accuracy: 0.5652\n","Epoch 40/50\n","7/7 [==============================] - 1s 81ms/step - loss: 8.1241 - accuracy: 0.6000 - val_loss: 126.4188 - val_accuracy: 0.5652\n","Epoch 41/50\n","7/7 [==============================] - 1s 81ms/step - loss: 8.4468 - accuracy: 0.6049 - val_loss: 125.0886 - val_accuracy: 0.5652\n","Epoch 42/50\n","7/7 [==============================] - 1s 80ms/step - loss: 8.3108 - accuracy: 0.5415 - val_loss: 126.7394 - val_accuracy: 0.4783\n","Epoch 43/50\n","7/7 [==============================] - 1s 82ms/step - loss: 8.9867 - accuracy: 0.5366 - val_loss: 125.5749 - val_accuracy: 0.5217\n","Epoch 44/50\n","7/7 [==============================] - 1s 82ms/step - loss: 9.3102 - accuracy: 0.6098 - val_loss: 126.3999 - val_accuracy: 0.5652\n","Epoch 45/50\n","7/7 [==============================] - 1s 81ms/step - loss: 10.4390 - accuracy: 0.5756 - val_loss: 126.5985 - val_accuracy: 0.5217\n","Epoch 46/50\n","7/7 [==============================] - 1s 79ms/step - loss: 12.7885 - accuracy: 0.5902 - val_loss: 125.9828 - val_accuracy: 0.5217\n","Epoch 47/50\n","7/7 [==============================] - 1s 77ms/step - loss: 11.4684 - accuracy: 0.6000 - val_loss: 125.4752 - val_accuracy: 0.4783\n","Epoch 48/50\n","7/7 [==============================] - 1s 83ms/step - loss: 10.2283 - accuracy: 0.6146 - val_loss: 125.0305 - val_accuracy: 0.5217\n","Epoch 49/50\n","7/7 [==============================] - 1s 102ms/step - loss: 8.9338 - accuracy: 0.6488 - val_loss: 125.3787 - val_accuracy: 0.5652\n","Epoch 50/50\n","7/7 [==============================] - 1s 105ms/step - loss: 7.4372 - accuracy: 0.6195 - val_loss: 124.7344 - val_accuracy: 0.5652\n","2/2 [==============================] - 0s 23ms/step\n","2/2 [==============================] - 0s 22ms/step - loss: 632.3442 - accuracy: 0.8833\n","Test Loss: 632.3442, Test accuracy : 0.8833\n","Epoch 1/50\n","5/5 [==============================] - 1s 100ms/step - loss: 197.6985 - accuracy: 0.4929 - val_loss: 141.7046 - val_accuracy: 0.0000e+00\n","Epoch 2/50\n","5/5 [==============================] - 0s 62ms/step - loss: 72.9992 - accuracy: 0.3357 - val_loss: 50.1117 - val_accuracy: 1.0000\n","Epoch 3/50\n","5/5 [==============================] - 0s 63ms/step - loss: 57.0823 - accuracy: 0.6571 - val_loss: 40.8420 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","5/5 [==============================] - 0s 70ms/step - loss: 30.5867 - accuracy: 0.6071 - val_loss: 35.2282 - val_accuracy: 1.0000\n","Epoch 5/50\n","5/5 [==============================] - 0s 73ms/step - loss: 66.9245 - accuracy: 0.5500 - val_loss: 42.8049 - val_accuracy: 0.0625\n","Epoch 6/50\n","5/5 [==============================] - 0s 65ms/step - loss: 49.3845 - accuracy: 0.3429 - val_loss: 45.1297 - val_accuracy: 1.0000\n","Epoch 7/50\n","5/5 [==============================] - 0s 59ms/step - loss: 16.8620 - accuracy: 0.8286 - val_loss: 48.9538 - val_accuracy: 0.0000e+00\n","Epoch 8/50\n","5/5 [==============================] - 0s 63ms/step - loss: 13.1778 - accuracy: 0.5929 - val_loss: 45.5429 - val_accuracy: 1.0000\n","Epoch 9/50\n","5/5 [==============================] - 0s 63ms/step - loss: 10.7762 - accuracy: 0.7714 - val_loss: 45.1022 - val_accuracy: 0.0000e+00\n","Epoch 10/50\n","5/5 [==============================] - 0s 78ms/step - loss: 7.8969 - accuracy: 0.5929 - val_loss: 40.7743 - val_accuracy: 1.0000\n","Epoch 11/50\n","5/5 [==============================] - 0s 98ms/step - loss: 7.1733 - accuracy: 0.6714 - val_loss: 40.8216 - val_accuracy: 0.1250\n","Epoch 12/50\n","5/5 [==============================] - 0s 79ms/step - loss: 6.4063 - accuracy: 0.7929 - val_loss: 37.3515 - val_accuracy: 0.8750\n","Epoch 13/50\n","5/5 [==============================] - 0s 82ms/step - loss: 3.6343 - accuracy: 0.6643 - val_loss: 38.7302 - val_accuracy: 0.8125\n","Epoch 14/50\n","5/5 [==============================] - 0s 87ms/step - loss: 2.4201 - accuracy: 0.8929 - val_loss: 40.0603 - val_accuracy: 0.1875\n","Epoch 15/50\n","5/5 [==============================] - 0s 91ms/step - loss: 1.8855 - accuracy: 0.6214 - val_loss: 40.8816 - val_accuracy: 0.9375\n","Epoch 16/50\n","5/5 [==============================] - 0s 79ms/step - loss: 2.3231 - accuracy: 0.7786 - val_loss: 39.7410 - val_accuracy: 0.5000\n","Epoch 17/50\n","5/5 [==============================] - 0s 87ms/step - loss: 1.8181 - accuracy: 0.8929 - val_loss: 39.3500 - val_accuracy: 0.8125\n","Epoch 18/50\n","5/5 [==============================] - 0s 81ms/step - loss: 1.1681 - accuracy: 0.7857 - val_loss: 38.8583 - val_accuracy: 0.8750\n","Epoch 19/50\n","5/5 [==============================] - 0s 82ms/step - loss: 1.6291 - accuracy: 0.8714 - val_loss: 39.5767 - val_accuracy: 0.4375\n","Epoch 20/50\n","5/5 [==============================] - 0s 93ms/step - loss: 1.7910 - accuracy: 0.8500 - val_loss: 38.5695 - val_accuracy: 0.8125\n","Epoch 21/50\n","5/5 [==============================] - 0s 89ms/step - loss: 1.0828 - accuracy: 0.7071 - val_loss: 39.8566 - val_accuracy: 0.8750\n","Epoch 22/50\n","5/5 [==============================] - 0s 79ms/step - loss: 0.8575 - accuracy: 0.9643 - val_loss: 39.7112 - val_accuracy: 0.3750\n","Epoch 23/50\n","5/5 [==============================] - 0s 99ms/step - loss: 0.7409 - accuracy: 0.8143 - val_loss: 39.7648 - val_accuracy: 0.8750\n","Epoch 24/50\n","5/5 [==============================] - 0s 91ms/step - loss: 0.6460 - accuracy: 0.8857 - val_loss: 39.1187 - val_accuracy: 0.8125\n","Epoch 25/50\n","5/5 [==============================] - 0s 70ms/step - loss: 0.5387 - accuracy: 0.9214 - val_loss: 39.5929 - val_accuracy: 0.6250\n","Epoch 26/50\n","5/5 [==============================] - 0s 69ms/step - loss: 0.4300 - accuracy: 0.9143 - val_loss: 39.1368 - val_accuracy: 0.6250\n","Epoch 27/50\n","5/5 [==============================] - 0s 65ms/step - loss: 0.3862 - accuracy: 0.8786 - val_loss: 39.6228 - val_accuracy: 0.8750\n","Epoch 28/50\n","5/5 [==============================] - 0s 65ms/step - loss: 0.3818 - accuracy: 0.9714 - val_loss: 39.8709 - val_accuracy: 0.6250\n","Epoch 29/50\n","5/5 [==============================] - 0s 68ms/step - loss: 0.3729 - accuracy: 0.8786 - val_loss: 39.7971 - val_accuracy: 0.8125\n","Epoch 30/50\n","5/5 [==============================] - 0s 60ms/step - loss: 0.3834 - accuracy: 0.9000 - val_loss: 39.0960 - val_accuracy: 0.8750\n","Epoch 31/50\n","5/5 [==============================] - 0s 66ms/step - loss: 0.4595 - accuracy: 0.8786 - val_loss: 38.9897 - val_accuracy: 0.7500\n","Epoch 32/50\n","5/5 [==============================] - 0s 65ms/step - loss: 0.3929 - accuracy: 0.9214 - val_loss: 40.2483 - val_accuracy: 0.5000\n","Epoch 33/50\n","5/5 [==============================] - 0s 63ms/step - loss: 0.5550 - accuracy: 0.8500 - val_loss: 40.4584 - val_accuracy: 0.2500\n","Epoch 34/50\n","5/5 [==============================] - 0s 60ms/step - loss: 0.5025 - accuracy: 0.7643 - val_loss: 40.0248 - val_accuracy: 0.8750\n","Epoch 35/50\n","5/5 [==============================] - 0s 68ms/step - loss: 0.6378 - accuracy: 0.8643 - val_loss: 39.9956 - val_accuracy: 0.5625\n","Epoch 36/50\n","5/5 [==============================] - 0s 62ms/step - loss: 0.3511 - accuracy: 0.9357 - val_loss: 39.6353 - val_accuracy: 0.8750\n","Epoch 37/50\n","5/5 [==============================] - 0s 60ms/step - loss: 0.4002 - accuracy: 0.8857 - val_loss: 39.9982 - val_accuracy: 0.5000\n","Epoch 38/50\n","5/5 [==============================] - 0s 64ms/step - loss: 0.3352 - accuracy: 0.9000 - val_loss: 39.6306 - val_accuracy: 0.8125\n","Epoch 39/50\n","5/5 [==============================] - 0s 63ms/step - loss: 0.3229 - accuracy: 0.9500 - val_loss: 39.8025 - val_accuracy: 0.8125\n","Epoch 40/50\n","5/5 [==============================] - 0s 64ms/step - loss: 0.2919 - accuracy: 0.9571 - val_loss: 39.7521 - val_accuracy: 0.6250\n","Epoch 41/50\n","5/5 [==============================] - 0s 64ms/step - loss: 0.3169 - accuracy: 0.9500 - val_loss: 39.7747 - val_accuracy: 0.8125\n","Epoch 42/50\n","5/5 [==============================] - 0s 62ms/step - loss: 0.3247 - accuracy: 0.9500 - val_loss: 39.9371 - val_accuracy: 0.8125\n","Epoch 43/50\n","5/5 [==============================] - 0s 63ms/step - loss: 0.3675 - accuracy: 0.9429 - val_loss: 39.9786 - val_accuracy: 0.8125\n","Epoch 44/50\n","5/5 [==============================] - 0s 63ms/step - loss: 0.4633 - accuracy: 0.9714 - val_loss: 40.2439 - val_accuracy: 0.8125\n","Epoch 45/50\n","5/5 [==============================] - 0s 60ms/step - loss: 0.4365 - accuracy: 0.9714 - val_loss: 40.2157 - val_accuracy: 0.5625\n","Epoch 46/50\n","5/5 [==============================] - 0s 66ms/step - loss: 0.5894 - accuracy: 0.9000 - val_loss: 39.9324 - val_accuracy: 0.7500\n","Epoch 47/50\n","5/5 [==============================] - 0s 64ms/step - loss: 0.6275 - accuracy: 0.9000 - val_loss: 39.4925 - val_accuracy: 0.8125\n","Epoch 48/50\n","5/5 [==============================] - 0s 58ms/step - loss: 0.4665 - accuracy: 0.9071 - val_loss: 40.0495 - val_accuracy: 0.9375\n","Epoch 49/50\n","5/5 [==============================] - 0s 65ms/step - loss: 0.9267 - accuracy: 0.8429 - val_loss: 39.6121 - val_accuracy: 0.8125\n","Epoch 50/50\n","5/5 [==============================] - 0s 64ms/step - loss: 0.7250 - accuracy: 0.9143 - val_loss: 40.6368 - val_accuracy: 0.3125\n","2/2 [==============================] - 0s 11ms/step\n","2/2 [==============================] - 0s 15ms/step - loss: 6.4415 - accuracy: 0.9286\n","Test Loss: 6.4415, Test accuracy : 0.9286\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1715438127933,"user_tz":-60,"elapsed":5732,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ab70551-6bbc-42d8-de0d-0e90625e443e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_29 (InputLayer)       [(None, 2004, 13)]        0         \n","                                                                 \n"," flatten_28 (Flatten)        (None, 26052)             0         \n","                                                                 \n"," dense_56 (Dense)            (None, 64)                1667392   \n","                                                                 \n"," dense_57 (Dense)            (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 1667522 (6.36 MB)\n","Trainable params: 1667522 (6.36 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_30 (InputLayer)       [(None, 3216, 13)]        0         \n","                                                                 \n"," flatten_29 (Flatten)        (None, 41808)             0         \n","                                                                 \n"," dense_58 (Dense)            (None, 64)                2675776   \n","                                                                 \n"," dense_59 (Dense)            (None, 4)                 260       \n","                                                                 \n","=================================================================\n","Total params: 2676036 (10.21 MB)\n","Trainable params: 2676036 (10.21 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_30\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_31 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_30 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_60 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_61 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_31\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_32 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_31 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_62 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_63 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 5214858 (19.89 MB)\n","Trainable params: 5214858 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_32\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_33 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_32 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_64 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_65 (Dense)            (None, 8)                 520       \n","                                                                 \n","=================================================================\n","Total params: 5214728 (19.89 MB)\n","Trainable params: 5214728 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_33\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_34 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_33 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_66 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_67 (Dense)            (None, 18)                1170      \n","                                                                 \n","=================================================================\n","Total params: 5215378 (19.90 MB)\n","Trainable params: 5215378 (19.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_34\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_35 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_34 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_68 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_69 (Dense)            (None, 18)                1170      \n","                                                                 \n","=================================================================\n","Total params: 5215378 (19.90 MB)\n","Trainable params: 5215378 (19.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_35\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_36 (InputLayer)       [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_35 (Flatten)        (None, 81471)             0         \n","                                                                 \n"," dense_70 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_71 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_36\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_37 (InputLayer)       [(None, 4502, 13)]        0         \n","                                                                 \n"," flatten_36 (Flatten)        (None, 58526)             0         \n","                                                                 \n"," dense_72 (Dense)            (None, 64)                3745728   \n","                                                                 \n"," dense_73 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 3746118 (14.29 MB)\n","Trainable params: 3746118 (14.29 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1715438127934,"user_tz":-60,"elapsed":52,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b56b3791-eb99-4fc0-a757-c2f5923eb066"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                  1                 1   \n","1   madd_6_Lazim  Yassin Al Jazaery                  1                 1   \n","2   madd_6_Lazim   Ibrahim_Aldosary                  1                 1   \n","3   madd_6_Lazim       all reciters                  3                 3   \n","4       madd_246        Abdul Basit                 62                16   \n","5       madd_246  Yassin Al Jazaery                 62                16   \n","6       madd_246   Ibrahim_Aldosary                 62                16   \n","7       madd_246       all reciters                186                48   \n","8         madd_6        Abdul Basit                 47                12   \n","9         madd_6  Yassin Al Jazaery                 47                12   \n","10        madd_6   Ibrahim_Aldosary                 47                12   \n","11        madd_6       all reciters                141                36   \n","12        madd_2        Abdul Basit                 79                20   \n","13        madd_2  Yassin Al Jazaery                 79                20   \n","14        madd_2   Ibrahim_Aldosary                 79                20   \n","15        madd_2       all reciters                237                60   \n","16        Ikhfaa        Abdul Basit                119                30   \n","17        Ikhfaa  Yassin Al Jazaery                119                30   \n","18        Ikhfaa   Ibrahim_Aldosary                119                30   \n","19        Ikhfaa       all reciters                357                90   \n","20        Idgham        Abdul Basit                114                29   \n","21        Idgham  Yassin Al Jazaery                114                29   \n","22        Idgham   Ibrahim_Aldosary                114                29   \n","23        Idgham       all reciters                342                87   \n","24       tafkhim        Abdul Basit                179                45   \n","25       tafkhim  Yassin Al Jazaery                179                45   \n","26       tafkhim   Ibrahim_Aldosary                179                45   \n","27       tafkhim       all reciters                537               135   \n","28       qalqala        Abdul Basit                 76                20   \n","29       qalqala  Yassin Al Jazaery                 76                20   \n","30       qalqala   Ibrahim_Aldosary                 76                20   \n","31       qalqala       all reciters                228                60   \n","32         imala        Abdul Basit                 52                14   \n","33         imala  Yassin Al Jazaery                 52                14   \n","34         imala   Ibrahim_Aldosary                 52                14   \n","35         imala       all reciters                156                42   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                   1                 1  \n","1                   1                 1  \n","2                   1                 1  \n","3                   3                 3  \n","4                  62                16  \n","5                  62                16  \n","6                  62                16  \n","7                 186                48  \n","8                  47                12  \n","9                  47                12  \n","10                 47                12  \n","11                141                36  \n","12                 79                20  \n","13                 79                20  \n","14                 79                20  \n","15                237                60  \n","16                119                30  \n","17                119                30  \n","18                119                30  \n","19                357                90  \n","20                114                29  \n","21                114                29  \n","22                114                29  \n","23                342                87  \n","24                179                45  \n","25                179                45  \n","26                179                45  \n","27                537               135  \n","28                 76                20  \n","29                 76                20  \n","30                 76                20  \n","31                228                60  \n","32                 52                14  \n","33                 52                14  \n","34                 52                14  \n","35                156                42  "],"text/html":["\n","  <div id=\"df-1e2b45f4-e0d7-4cb9-8c64-4904aa7c3775\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>186</td>\n","      <td>48</td>\n","      <td>186</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>141</td>\n","      <td>36</td>\n","      <td>141</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>237</td>\n","      <td>60</td>\n","      <td>237</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>357</td>\n","      <td>90</td>\n","      <td>357</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>342</td>\n","      <td>87</td>\n","      <td>342</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>537</td>\n","      <td>135</td>\n","      <td>537</td>\n","      <td>135</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>228</td>\n","      <td>60</td>\n","      <td>228</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>156</td>\n","      <td>42</td>\n","      <td>156</td>\n","      <td>42</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e2b45f4-e0d7-4cb9-8c64-4904aa7c3775')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1e2b45f4-e0d7-4cb9-8c64-4904aa7c3775 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1e2b45f4-e0d7-4cb9-8c64-4904aa7c3775');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2b879775-0cbe-451d-9075-f188eeb3e302\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b879775-0cbe-451d-9075-f188eeb3e302')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2b879775-0cbe-451d-9075-f188eeb3e302 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 36,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Yassin Al Jazaery\",\n          \"all reciters\",\n          \"Abdul Basit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"3\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"3\",\n          \"36\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"3\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"3\",\n          \"36\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1715438127935,"user_tz":-60,"elapsed":23,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"a1056028-d510-47ef-b099-fe0d34e547ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model      Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model  149.6475   0.6667      66.67   \n","1      madd_246_tajweed_rule_model   17.1294   0.9583      95.83   \n","2        madd_6_tajweed_rule_model  252.0194   0.6944      69.44   \n","3        madd_2_tajweed_rule_model    5.5740   0.9667      96.67   \n","4        Ikhfaa_tajweed_rule_model    1.1614   0.9333      93.33   \n","5        Idgham_tajweed_rule_model    1.4251   0.7126      71.26   \n","6       tafkhim_tajweed_rule_model  131.5932   0.9407      94.07   \n","7       qalqala_tajweed_rule_model  632.3442   0.8833      88.33   \n","8         imala_tajweed_rule_model    6.4415   0.9286      92.86   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/AI_models/ma...  \n","1  /content/drive/My Drive/M2 GL/PFE/AI_models/ma...  \n","2  /content/drive/My Drive/M2 GL/PFE/AI_models/ma...  \n","3  /content/drive/My Drive/M2 GL/PFE/AI_models/ma...  \n","4  /content/drive/My Drive/M2 GL/PFE/AI_models/Ik...  \n","5  /content/drive/My Drive/M2 GL/PFE/AI_models/Id...  \n","6  /content/drive/My Drive/M2 GL/PFE/AI_models/ta...  \n","7  /content/drive/My Drive/M2 GL/PFE/AI_models/qa...  \n","8  /content/drive/My Drive/M2 GL/PFE/AI_models/im...  "],"text/html":["\n","  <div id=\"df-5b713a5a-0722-4cc5-9bac-12939533460d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>149.6475</td>\n","      <td>0.6667</td>\n","      <td>66.67</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/ma...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>17.1294</td>\n","      <td>0.9583</td>\n","      <td>95.83</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/ma...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>252.0194</td>\n","      <td>0.6944</td>\n","      <td>69.44</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/ma...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>5.5740</td>\n","      <td>0.9667</td>\n","      <td>96.67</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/ma...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>1.1614</td>\n","      <td>0.9333</td>\n","      <td>93.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/Ik...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>1.4251</td>\n","      <td>0.7126</td>\n","      <td>71.26</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/Id...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>131.5932</td>\n","      <td>0.9407</td>\n","      <td>94.07</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/ta...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>632.3442</td>\n","      <td>0.8833</td>\n","      <td>88.33</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/qa...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>6.4415</td>\n","      <td>0.9286</td>\n","      <td>92.86</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models/im...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b713a5a-0722-4cc5-9bac-12939533460d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5b713a5a-0722-4cc5-9bac-12939533460d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5b713a5a-0722-4cc5-9bac-12939533460d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2ee5429c-2c17-4456-b383-924f6e2d9f23\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ee5429c-2c17-4456-b383-924f6e2d9f23')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2ee5429c-2c17-4456-b383-924f6e2d9f23 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"632.3442\",\n          \"17.1294\",\n          \"1.4251\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"0.8833\",\n          \"0.9583\",\n          \"0.7126\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"88.33\",\n          \"95.83\",\n          \"71.26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":128}]}]}