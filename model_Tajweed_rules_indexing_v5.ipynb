{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNm8bs+ZFMFvUj2FrQDnShE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWO1vAVp7HkG","executionInfo":{"status":"ok","timestamp":1715954444008,"user_tz":-60,"elapsed":26598,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"f0ad0e17-774c-4c0a-d804-184503b6f385"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model"],"metadata":{"id":"6I2s5Q0iDpDE","executionInfo":{"status":"ok","timestamp":1715954452965,"user_tz":-60,"elapsed":8964,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing_v2.csv')\n","safa_data = pd.read_csv('/content/drive/My Drive/M2 GL/PFE/Data/safa_hisb_60_and_Al_fatihah_audio_with_transcript_and_MFCC_and_ahkam_indexing.csv')"],"metadata":{"id":"WtJVQemz7klg","executionInfo":{"status":"ok","timestamp":1715954470192,"user_tz":-60,"elapsed":17242,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["export_dir = '/content/drive/My Drive/M2 GL/PFE/AI_models_v5'"],"metadata":{"id":"7A9PSizPHQos","executionInfo":{"status":"ok","timestamp":1715954470193,"user_tz":-60,"elapsed":46,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["abdul_basit = data[data['recitor_en'] == 'Abdul Basit']\n","yassin_aljazaery = data[data['recitor_en'] == 'Yassin Al Jazaery']\n","ibrahim_aldosary = data[data['recitor_en'] == 'Ibrahim_Aldosary']"],"metadata":{"id":"KoKbTBQr7nY8","executionInfo":{"status":"ok","timestamp":1715954470194,"user_tz":-60,"elapsed":44,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["splitted_data_info_np = np.empty((0, 6))\n","models_information_np = np.empty((0, 5))"],"metadata":{"id":"_CenkKQf-AXc","executionInfo":{"status":"ok","timestamp":1715954470194,"user_tz":-60,"elapsed":39,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def max_sequence_length_X_Y(data, tajweed_rule):\n","  data_filtered = data[data[tajweed_rule].apply(lambda x: x != '[-1]')]\n","  X_raw = data_filtered['mfcc'].astype(str).tolist()\n","  Y_raw = data_filtered[tajweed_rule].astype(str).tolist()\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","  max_sequence_length_Y = max(len(seq) for seq in Y)\n","  max_sequence_length_X = max(len(seq) for seq in X)\n","  return max_sequence_length_X, max_sequence_length_Y"],"metadata":{"id":"H950tSVTMxlL","executionInfo":{"status":"ok","timestamp":1715954470195,"user_tz":-60,"elapsed":38,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def data_preparation(reciter_data, tajweed_rule, max_X, max_Y):\n","  data_filtered = reciter_data[reciter_data[tajweed_rule].apply(lambda x: x != '[-1]')]\n","\n","  # Extract 'mfcc' and tajweed_rule columns as lists of strings\n","  X_raw = data_filtered['mfcc'].astype(str).tolist()\n","  Y_raw = data_filtered[tajweed_rule].astype(str).tolist()\n","\n","  # Preprocess the input data\n","  X = [tf.constant(eval(x)) for x in X_raw]\n","  Y = [tf.constant(eval(x)) for x in Y_raw]\n","\n","  # Pad sequences in Y and in X to ensure all have the same length\n","  Y_padded = tf.keras.preprocessing.sequence.pad_sequences(Y, maxlen=max_Y, padding='post', dtype='int32', value=-1)\n","  X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_X, padding='post', dtype='float32')\n","\n","  # Split the data into training and testing sets\n","  X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_padded, test_size=0.2, random_state=10)\n","  return X_train, X_test, Y_train, Y_test"],"metadata":{"id":"pVbn5z76-K4O","executionInfo":{"status":"ok","timestamp":1715954470195,"user_tz":-60,"elapsed":37,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tajweed_rule_model(reciter1, reciter2, reciter3, not_exp, tajweed_rule):\n","  global splitted_data_info_np, models_information_np, data\n","\n","  max_X, max_Y = max_sequence_length_X_Y(data, tajweed_rule)\n","\n","  # data preparation\n","  reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test = data_preparation(reciter1, tajweed_rule, max_X, max_Y)\n","  reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test = data_preparation(reciter2, tajweed_rule, max_X, max_Y)\n","  reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test = data_preparation(reciter3, tajweed_rule, max_X, max_Y)\n","  not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test = data_preparation(not_exp, tajweed_rule, max_X, max_Y)\n","\n","  # Update splitted_data_info with information about each reciter\n","  for reciter_X_train, reciter_X_test, reciter_Y_train, reciter_Y_test, reciter_data in [\n","      (reciter1_X_train, reciter1_X_test, reciter1_Y_train, reciter1_Y_test, reciter1),\n","      (reciter2_X_train, reciter2_X_test, reciter2_Y_train, reciter2_Y_test, reciter2),\n","      (reciter3_X_train, reciter3_X_test, reciter3_Y_train, reciter3_Y_test, reciter3),\n","      (not_exp_X_train, not_exp_X_test, not_exp_Y_train, not_exp_Y_test, not_exp)]:\n","\n","      splitted_data_info_np = np.append(splitted_data_info_np, [[\n","              tajweed_rule,\n","              reciter_data.iloc[0]['recitor_en'],\n","              len(reciter_X_train),\n","              len(reciter_X_test),\n","              len(reciter_Y_train),\n","              len(reciter_Y_test)\n","              ]], axis=0)\n","\n","  # concatenate data\n","  # training data\n","  X_train = np.concatenate([reciter1_X_train, reciter2_X_train, reciter3_X_train, not_exp_X_train], axis=0)\n","  Y_train = np.concatenate([reciter1_Y_train, reciter2_Y_train, reciter3_Y_train, not_exp_Y_train], axis=0)\n","\n","  # testing data\n","  X_test = np.concatenate([reciter1_X_test, reciter2_X_test, reciter3_X_test, not_exp_X_test], axis=0)\n","  Y_test = np.concatenate([reciter1_Y_test, reciter2_Y_test, reciter3_Y_test, not_exp_Y_test], axis=0)\n","\n","  splitted_data_info_np = np.append(splitted_data_info_np, [[\n","          tajweed_rule,\n","          'all reciters',\n","          len(X_train),\n","          len(X_test),\n","          len(Y_train),\n","          len(Y_test)\n","          ]], axis=0)\n","\n","  # Normalize input data by scaling each sequence individually\n","  scaler = StandardScaler()\n","  X_train_scaled = np.array([scaler.fit_transform(seq) for seq in X_train])\n","  X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])\n","\n","  # Define a simple neural network model\n","  input_shape = X_train_scaled[0].shape  # Shape of each mfcc sequence\n","  output_shape = Y_train.shape[1]  # Dimension of output (number of units in output layer)\n","\n","  input_layer = Input(shape=input_shape)\n","  flatten_layer = Flatten()(input_layer)  # Flatten the sequence to a 1D vector\n","  hidden_layer = Dense(64, activation='relu')(flatten_layer)\n","  output_layer = Dense(output_shape, activation='linear')(hidden_layer)  # Define the output layer with the correct units\n","\n","  model = Model(inputs=input_layer, outputs=output_layer)\n","\n","  # Compile the model\n","  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","\n","  # Train the model\n","  model.fit(X_train_scaled, Y_train, epochs=50, batch_size=32, validation_split=0.1)\n","\n","  #export the model\n","  model_filename = f'{tajweed_rule}_tajweed_rule_model'\n","  model_path = os.path.join(export_dir, model_filename)\n","  keras.models.save_model(model, model_path)\n","\n","  # Make predictions on test data\n","  predictions = model.predict(X_test_scaled)\n","\n","  # Evaluate the model with adjusted predictions\n","  predictions[predictions < 0] = -1\n","  predictions = np.round(predictions).astype('int32')\n","  loss, accuracy = model.evaluate(X_test_scaled, predictions)\n","\n","  print(f\"Test Loss: {loss:.4f}, Test accuracy : {accuracy:.4f}\")\n","  models_information_np = np.append(models_information_np, [[\n","          model_filename,\n","          \"{:.4f}\".format(loss),\n","          \"{:.4f}\".format(accuracy),\n","          \"{:.2f}\".format(accuracy*100),\n","          model_path]], axis=0)"],"metadata":{"id":"n3ycP8uz8zp8","executionInfo":{"status":"ok","timestamp":1715954470195,"user_tz":-60,"elapsed":36,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["tajweed_rules = ['madd_6_Lazim', 'madd_246', 'madd_6', 'madd_2', 'Ikhfaa', 'Idgham', 'tafkhim', 'qalqala', 'imala']"],"metadata":{"id":"qpgV2OY8K09J","executionInfo":{"status":"ok","timestamp":1715954470196,"user_tz":-60,"elapsed":35,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","  tajweed_rule_model(abdul_basit, yassin_aljazaery, ibrahim_aldosary, safa_data, rule)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6qxa6hWLAeZ","executionInfo":{"status":"ok","timestamp":1715955263958,"user_tz":-60,"elapsed":793796,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"outputId":"469959ad-211b-442c-c8c3-ea3c4b68ebb9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 1s 949ms/step - loss: 197.0288 - accuracy: 0.3333 - val_loss: 1.1713 - val_accuracy: 1.0000\n","Epoch 2/50\n","1/1 [==============================] - 0s 57ms/step - loss: 170.8870 - accuracy: 1.0000 - val_loss: 6.7806 - val_accuracy: 0.0000e+00\n","Epoch 3/50\n","1/1 [==============================] - 0s 61ms/step - loss: 131.3937 - accuracy: 0.0000e+00 - val_loss: 35.8145 - val_accuracy: 0.0000e+00\n","Epoch 4/50\n","1/1 [==============================] - 0s 54ms/step - loss: 35.5719 - accuracy: 0.6667 - val_loss: 86.6724 - val_accuracy: 0.0000e+00\n","Epoch 5/50\n","1/1 [==============================] - 0s 57ms/step - loss: 17.0300 - accuracy: 0.6667 - val_loss: 134.4271 - val_accuracy: 1.0000\n","Epoch 6/50\n","1/1 [==============================] - 0s 62ms/step - loss: 48.5465 - accuracy: 1.0000 - val_loss: 154.9555 - val_accuracy: 1.0000\n","Epoch 7/50\n","1/1 [==============================] - 0s 61ms/step - loss: 62.8890 - accuracy: 0.6667 - val_loss: 152.0862 - val_accuracy: 1.0000\n","Epoch 8/50\n","1/1 [==============================] - 0s 55ms/step - loss: 41.0188 - accuracy: 0.3333 - val_loss: 139.3742 - val_accuracy: 1.0000\n","Epoch 9/50\n","1/1 [==============================] - 0s 52ms/step - loss: 16.6345 - accuracy: 0.6667 - val_loss: 118.2538 - val_accuracy: 1.0000\n","Epoch 10/50\n","1/1 [==============================] - 0s 55ms/step - loss: 11.5007 - accuracy: 0.6667 - val_loss: 94.4627 - val_accuracy: 1.0000\n","Epoch 11/50\n","1/1 [==============================] - 0s 51ms/step - loss: 16.7663 - accuracy: 0.6667 - val_loss: 74.7568 - val_accuracy: 1.0000\n","Epoch 12/50\n","1/1 [==============================] - 0s 56ms/step - loss: 22.0896 - accuracy: 0.3333 - val_loss: 63.3060 - val_accuracy: 1.0000\n","Epoch 13/50\n","1/1 [==============================] - 0s 55ms/step - loss: 20.8599 - accuracy: 0.3333 - val_loss: 61.3498 - val_accuracy: 1.0000\n","Epoch 14/50\n","1/1 [==============================] - 0s 53ms/step - loss: 16.4123 - accuracy: 0.6667 - val_loss: 68.6613 - val_accuracy: 0.0000e+00\n","Epoch 15/50\n","1/1 [==============================] - 0s 51ms/step - loss: 14.4477 - accuracy: 0.6667 - val_loss: 83.8636 - val_accuracy: 0.0000e+00\n","Epoch 16/50\n","1/1 [==============================] - 0s 55ms/step - loss: 12.7082 - accuracy: 0.3333 - val_loss: 103.7476 - val_accuracy: 0.0000e+00\n","Epoch 17/50\n","1/1 [==============================] - 0s 73ms/step - loss: 10.2037 - accuracy: 0.3333 - val_loss: 123.1645 - val_accuracy: 0.0000e+00\n","Epoch 18/50\n","1/1 [==============================] - 0s 54ms/step - loss: 8.2371 - accuracy: 0.0000e+00 - val_loss: 136.6703 - val_accuracy: 1.0000\n","Epoch 19/50\n","1/1 [==============================] - 0s 55ms/step - loss: 6.4126 - accuracy: 0.0000e+00 - val_loss: 139.9947 - val_accuracy: 1.0000\n","Epoch 20/50\n","1/1 [==============================] - 0s 81ms/step - loss: 6.0465 - accuracy: 1.0000 - val_loss: 136.3875 - val_accuracy: 1.0000\n","Epoch 21/50\n","1/1 [==============================] - 0s 56ms/step - loss: 6.8207 - accuracy: 1.0000 - val_loss: 126.7626 - val_accuracy: 1.0000\n","Epoch 22/50\n","1/1 [==============================] - 0s 69ms/step - loss: 6.7907 - accuracy: 1.0000 - val_loss: 116.1034 - val_accuracy: 1.0000\n","Epoch 23/50\n","1/1 [==============================] - 0s 52ms/step - loss: 6.9082 - accuracy: 0.6667 - val_loss: 107.8060 - val_accuracy: 1.0000\n","Epoch 24/50\n","1/1 [==============================] - 0s 51ms/step - loss: 6.7464 - accuracy: 0.6667 - val_loss: 103.9373 - val_accuracy: 1.0000\n","Epoch 25/50\n","1/1 [==============================] - 0s 57ms/step - loss: 5.5629 - accuracy: 1.0000 - val_loss: 105.2229 - val_accuracy: 1.0000\n","Epoch 26/50\n","1/1 [==============================] - 0s 50ms/step - loss: 4.0834 - accuracy: 0.6667 - val_loss: 110.9856 - val_accuracy: 1.0000\n","Epoch 27/50\n","1/1 [==============================] - 0s 56ms/step - loss: 2.5235 - accuracy: 0.6667 - val_loss: 119.0237 - val_accuracy: 1.0000\n","Epoch 28/50\n","1/1 [==============================] - 0s 58ms/step - loss: 2.0024 - accuracy: 1.0000 - val_loss: 125.9839 - val_accuracy: 1.0000\n","Epoch 29/50\n","1/1 [==============================] - 0s 57ms/step - loss: 2.6406 - accuracy: 0.3333 - val_loss: 128.6570 - val_accuracy: 0.0000e+00\n","Epoch 30/50\n","1/1 [==============================] - 0s 52ms/step - loss: 2.8794 - accuracy: 0.6667 - val_loss: 125.6506 - val_accuracy: 0.0000e+00\n","Epoch 31/50\n","1/1 [==============================] - 0s 51ms/step - loss: 2.6508 - accuracy: 0.6667 - val_loss: 118.1417 - val_accuracy: 0.0000e+00\n","Epoch 32/50\n","1/1 [==============================] - 0s 53ms/step - loss: 2.2735 - accuracy: 0.6667 - val_loss: 109.1302 - val_accuracy: 0.0000e+00\n","Epoch 33/50\n","1/1 [==============================] - 0s 75ms/step - loss: 2.1777 - accuracy: 0.6667 - val_loss: 101.9190 - val_accuracy: 1.0000\n","Epoch 34/50\n","1/1 [==============================] - 0s 50ms/step - loss: 2.4600 - accuracy: 0.3333 - val_loss: 98.8674 - val_accuracy: 1.0000\n","Epoch 35/50\n","1/1 [==============================] - 0s 57ms/step - loss: 2.1757 - accuracy: 0.6667 - val_loss: 100.8711 - val_accuracy: 1.0000\n","Epoch 36/50\n","1/1 [==============================] - 0s 54ms/step - loss: 1.4613 - accuracy: 1.0000 - val_loss: 107.3684 - val_accuracy: 1.0000\n","Epoch 37/50\n","1/1 [==============================] - 0s 71ms/step - loss: 0.8493 - accuracy: 1.0000 - val_loss: 116.4887 - val_accuracy: 1.0000\n","Epoch 38/50\n","1/1 [==============================] - 0s 75ms/step - loss: 0.6617 - accuracy: 1.0000 - val_loss: 125.3978 - val_accuracy: 1.0000\n","Epoch 39/50\n","1/1 [==============================] - 0s 51ms/step - loss: 0.9860 - accuracy: 1.0000 - val_loss: 131.1828 - val_accuracy: 1.0000\n","Epoch 40/50\n","1/1 [==============================] - 0s 54ms/step - loss: 1.1378 - accuracy: 1.0000 - val_loss: 132.1199 - val_accuracy: 1.0000\n","Epoch 41/50\n","1/1 [==============================] - 0s 54ms/step - loss: 1.0507 - accuracy: 1.0000 - val_loss: 128.4791 - val_accuracy: 1.0000\n","Epoch 42/50\n","1/1 [==============================] - 0s 49ms/step - loss: 0.9066 - accuracy: 1.0000 - val_loss: 122.2419 - val_accuracy: 1.0000\n","Epoch 43/50\n","1/1 [==============================] - 0s 52ms/step - loss: 0.8272 - accuracy: 1.0000 - val_loss: 116.0228 - val_accuracy: 1.0000\n","Epoch 44/50\n","1/1 [==============================] - 0s 55ms/step - loss: 0.8488 - accuracy: 1.0000 - val_loss: 111.9739 - val_accuracy: 1.0000\n","Epoch 45/50\n","1/1 [==============================] - 0s 55ms/step - loss: 0.6766 - accuracy: 1.0000 - val_loss: 111.1629 - val_accuracy: 1.0000\n","Epoch 46/50\n","1/1 [==============================] - 0s 72ms/step - loss: 0.4755 - accuracy: 1.0000 - val_loss: 113.4109 - val_accuracy: 1.0000\n","Epoch 47/50\n","1/1 [==============================] - 0s 73ms/step - loss: 0.3351 - accuracy: 1.0000 - val_loss: 117.4185 - val_accuracy: 1.0000\n","Epoch 48/50\n","1/1 [==============================] - 0s 54ms/step - loss: 0.3052 - accuracy: 1.0000 - val_loss: 121.2145 - val_accuracy: 1.0000\n","Epoch 49/50\n","1/1 [==============================] - 0s 58ms/step - loss: 0.3691 - accuracy: 0.6667 - val_loss: 122.9829 - val_accuracy: 1.0000\n","Epoch 50/50\n","1/1 [==============================] - 0s 56ms/step - loss: 0.4122 - accuracy: 0.6667 - val_loss: 121.9422 - val_accuracy: 1.0000\n","1/1 [==============================] - 0s 107ms/step\n","1/1 [==============================] - 0s 28ms/step - loss: 1.2232 - accuracy: 1.0000\n","Test Loss: 1.2232, Test accuracy : 1.0000\n","Epoch 1/50\n","7/7 [==============================] - 1s 71ms/step - loss: 276.5647 - accuracy: 0.7534 - val_loss: 197.7066 - val_accuracy: 0.9200\n","Epoch 2/50\n","7/7 [==============================] - 0s 45ms/step - loss: 140.2020 - accuracy: 0.8834 - val_loss: 121.0700 - val_accuracy: 0.8800\n","Epoch 3/50\n","7/7 [==============================] - 0s 45ms/step - loss: 77.7165 - accuracy: 0.8924 - val_loss: 134.4046 - val_accuracy: 0.8800\n","Epoch 4/50\n","7/7 [==============================] - 0s 41ms/step - loss: 47.8837 - accuracy: 0.8969 - val_loss: 152.8251 - val_accuracy: 0.8400\n","Epoch 5/50\n","7/7 [==============================] - 0s 47ms/step - loss: 36.5391 - accuracy: 0.9193 - val_loss: 141.4037 - val_accuracy: 0.8800\n","Epoch 6/50\n","7/7 [==============================] - 0s 44ms/step - loss: 24.0407 - accuracy: 0.9372 - val_loss: 150.0550 - val_accuracy: 0.8800\n","Epoch 7/50\n","7/7 [==============================] - 0s 44ms/step - loss: 17.3940 - accuracy: 0.9327 - val_loss: 145.2218 - val_accuracy: 0.8800\n","Epoch 8/50\n","7/7 [==============================] - 0s 43ms/step - loss: 12.8545 - accuracy: 0.9327 - val_loss: 149.3428 - val_accuracy: 0.8800\n","Epoch 9/50\n","7/7 [==============================] - 0s 43ms/step - loss: 10.3412 - accuracy: 0.9507 - val_loss: 147.9441 - val_accuracy: 0.8800\n","Epoch 10/50\n","7/7 [==============================] - 0s 47ms/step - loss: 7.4516 - accuracy: 0.9462 - val_loss: 148.4993 - val_accuracy: 0.8800\n","Epoch 11/50\n","7/7 [==============================] - 0s 42ms/step - loss: 5.2199 - accuracy: 0.9596 - val_loss: 148.6964 - val_accuracy: 0.8800\n","Epoch 12/50\n","7/7 [==============================] - 0s 43ms/step - loss: 3.6510 - accuracy: 0.9596 - val_loss: 147.3234 - val_accuracy: 0.8800\n","Epoch 13/50\n","7/7 [==============================] - 0s 47ms/step - loss: 2.7465 - accuracy: 0.9686 - val_loss: 147.8967 - val_accuracy: 0.8800\n","Epoch 14/50\n","7/7 [==============================] - 0s 42ms/step - loss: 2.1784 - accuracy: 0.9821 - val_loss: 149.0717 - val_accuracy: 0.8800\n","Epoch 15/50\n","7/7 [==============================] - 0s 42ms/step - loss: 1.7673 - accuracy: 0.9776 - val_loss: 147.7433 - val_accuracy: 0.8800\n","Epoch 16/50\n","7/7 [==============================] - 0s 41ms/step - loss: 1.6729 - accuracy: 0.9821 - val_loss: 148.1814 - val_accuracy: 0.8800\n","Epoch 17/50\n","7/7 [==============================] - 0s 43ms/step - loss: 1.0718 - accuracy: 0.9910 - val_loss: 149.1573 - val_accuracy: 0.8800\n","Epoch 18/50\n","7/7 [==============================] - 0s 44ms/step - loss: 1.5602 - accuracy: 0.9910 - val_loss: 146.7803 - val_accuracy: 0.8800\n","Epoch 19/50\n","7/7 [==============================] - 0s 41ms/step - loss: 2.4528 - accuracy: 0.9776 - val_loss: 147.4200 - val_accuracy: 0.8800\n","Epoch 20/50\n","7/7 [==============================] - 0s 48ms/step - loss: 0.8019 - accuracy: 0.9865 - val_loss: 149.4949 - val_accuracy: 0.8800\n","Epoch 21/50\n","7/7 [==============================] - 0s 42ms/step - loss: 0.8476 - accuracy: 0.9865 - val_loss: 150.2985 - val_accuracy: 0.8800\n","Epoch 22/50\n","7/7 [==============================] - 0s 41ms/step - loss: 0.6329 - accuracy: 0.9910 - val_loss: 149.8466 - val_accuracy: 0.8800\n","Epoch 23/50\n","7/7 [==============================] - 0s 43ms/step - loss: 0.4962 - accuracy: 0.9910 - val_loss: 150.4836 - val_accuracy: 0.8800\n","Epoch 24/50\n","7/7 [==============================] - 0s 45ms/step - loss: 0.4783 - accuracy: 0.9955 - val_loss: 150.2335 - val_accuracy: 0.8800\n","Epoch 25/50\n","7/7 [==============================] - 0s 42ms/step - loss: 0.4028 - accuracy: 0.9955 - val_loss: 150.2169 - val_accuracy: 0.8800\n","Epoch 26/50\n","7/7 [==============================] - 0s 41ms/step - loss: 0.3871 - accuracy: 1.0000 - val_loss: 150.6779 - val_accuracy: 0.8800\n","Epoch 27/50\n","7/7 [==============================] - 0s 44ms/step - loss: 0.4033 - accuracy: 0.9955 - val_loss: 149.5161 - val_accuracy: 0.8800\n","Epoch 28/50\n","7/7 [==============================] - 0s 43ms/step - loss: 0.3435 - accuracy: 0.9955 - val_loss: 155.7011 - val_accuracy: 0.8800\n","Epoch 29/50\n","7/7 [==============================] - 0s 42ms/step - loss: 1.5718 - accuracy: 1.0000 - val_loss: 154.0972 - val_accuracy: 0.8800\n","Epoch 30/50\n","7/7 [==============================] - 0s 42ms/step - loss: 0.8293 - accuracy: 1.0000 - val_loss: 143.1587 - val_accuracy: 0.8800\n","Epoch 31/50\n","7/7 [==============================] - 0s 43ms/step - loss: 2.0150 - accuracy: 0.9955 - val_loss: 153.8731 - val_accuracy: 0.8800\n","Epoch 32/50\n","7/7 [==============================] - 0s 45ms/step - loss: 7.3653 - accuracy: 0.9865 - val_loss: 154.0453 - val_accuracy: 0.8800\n","Epoch 33/50\n","7/7 [==============================] - 0s 69ms/step - loss: 3.1243 - accuracy: 0.9955 - val_loss: 142.6670 - val_accuracy: 0.8800\n","Epoch 34/50\n","7/7 [==============================] - 0s 56ms/step - loss: 2.5924 - accuracy: 0.9865 - val_loss: 154.4864 - val_accuracy: 0.8800\n","Epoch 35/50\n","7/7 [==============================] - 0s 64ms/step - loss: 2.9754 - accuracy: 0.9731 - val_loss: 145.6235 - val_accuracy: 0.8800\n","Epoch 36/50\n","7/7 [==============================] - 0s 59ms/step - loss: 1.3751 - accuracy: 0.9955 - val_loss: 145.3152 - val_accuracy: 0.8800\n","Epoch 37/50\n","7/7 [==============================] - 0s 65ms/step - loss: 1.4318 - accuracy: 0.9776 - val_loss: 146.1340 - val_accuracy: 0.8800\n","Epoch 38/50\n","7/7 [==============================] - 0s 59ms/step - loss: 1.7654 - accuracy: 0.9865 - val_loss: 148.8404 - val_accuracy: 0.8800\n","Epoch 39/50\n","7/7 [==============================] - 0s 60ms/step - loss: 2.8362 - accuracy: 0.9865 - val_loss: 145.9086 - val_accuracy: 0.8800\n","Epoch 40/50\n","7/7 [==============================] - 0s 58ms/step - loss: 3.8717 - accuracy: 0.9865 - val_loss: 151.9371 - val_accuracy: 0.8800\n","Epoch 41/50\n","7/7 [==============================] - 0s 61ms/step - loss: 2.3645 - accuracy: 0.9865 - val_loss: 146.8163 - val_accuracy: 0.8800\n","Epoch 42/50\n","7/7 [==============================] - 0s 62ms/step - loss: 5.2819 - accuracy: 0.9641 - val_loss: 144.4655 - val_accuracy: 0.8800\n","Epoch 43/50\n","7/7 [==============================] - 0s 56ms/step - loss: 4.4473 - accuracy: 0.9776 - val_loss: 149.5898 - val_accuracy: 0.8800\n","Epoch 44/50\n","7/7 [==============================] - 0s 61ms/step - loss: 2.3268 - accuracy: 0.9641 - val_loss: 149.8157 - val_accuracy: 0.8800\n","Epoch 45/50\n","7/7 [==============================] - 0s 43ms/step - loss: 2.7304 - accuracy: 0.9686 - val_loss: 150.9510 - val_accuracy: 0.8800\n","Epoch 46/50\n","7/7 [==============================] - 0s 43ms/step - loss: 1.7086 - accuracy: 0.9776 - val_loss: 150.4190 - val_accuracy: 0.8800\n","Epoch 47/50\n","7/7 [==============================] - 0s 44ms/step - loss: 1.4903 - accuracy: 0.9641 - val_loss: 150.1818 - val_accuracy: 0.8800\n","Epoch 48/50\n","7/7 [==============================] - 0s 42ms/step - loss: 2.0498 - accuracy: 0.9641 - val_loss: 149.1181 - val_accuracy: 0.8800\n","Epoch 49/50\n","7/7 [==============================] - 0s 42ms/step - loss: 1.9434 - accuracy: 0.9910 - val_loss: 150.2658 - val_accuracy: 0.8800\n","Epoch 50/50\n","7/7 [==============================] - 0s 44ms/step - loss: 1.9004 - accuracy: 0.9641 - val_loss: 150.0518 - val_accuracy: 0.8800\n","2/2 [==============================] - 0s 12ms/step\n","2/2 [==============================] - 0s 21ms/step - loss: 10.8406 - accuracy: 1.0000\n","Test Loss: 10.8406, Test accuracy : 1.0000\n","Epoch 1/50\n","6/6 [==============================] - 1s 119ms/step - loss: 562.1303 - accuracy: 0.2722 - val_loss: 280.8483 - val_accuracy: 0.5263\n","Epoch 2/50\n","6/6 [==============================] - 1s 87ms/step - loss: 217.9252 - accuracy: 0.4142 - val_loss: 211.0293 - val_accuracy: 0.6842\n","Epoch 3/50\n","6/6 [==============================] - 0s 79ms/step - loss: 156.7921 - accuracy: 0.3728 - val_loss: 235.3774 - val_accuracy: 0.5789\n","Epoch 4/50\n","6/6 [==============================] - 1s 86ms/step - loss: 119.0263 - accuracy: 0.4379 - val_loss: 251.5994 - val_accuracy: 0.7895\n","Epoch 5/50\n","6/6 [==============================] - 0s 82ms/step - loss: 105.8576 - accuracy: 0.4201 - val_loss: 241.6627 - val_accuracy: 0.7368\n","Epoch 6/50\n","6/6 [==============================] - 1s 102ms/step - loss: 87.6757 - accuracy: 0.4734 - val_loss: 226.8184 - val_accuracy: 0.5789\n","Epoch 7/50\n","6/6 [==============================] - 1s 108ms/step - loss: 73.3510 - accuracy: 0.3964 - val_loss: 215.5845 - val_accuracy: 0.7368\n","Epoch 8/50\n","6/6 [==============================] - 1s 106ms/step - loss: 69.0322 - accuracy: 0.4260 - val_loss: 218.9717 - val_accuracy: 0.7368\n","Epoch 9/50\n","6/6 [==============================] - 1s 123ms/step - loss: 64.6671 - accuracy: 0.4556 - val_loss: 205.9440 - val_accuracy: 0.6316\n","Epoch 10/50\n","6/6 [==============================] - 1s 136ms/step - loss: 62.2131 - accuracy: 0.5089 - val_loss: 201.7350 - val_accuracy: 0.7895\n","Epoch 11/50\n","6/6 [==============================] - 1s 120ms/step - loss: 56.2700 - accuracy: 0.5266 - val_loss: 207.0127 - val_accuracy: 0.7368\n","Epoch 12/50\n","6/6 [==============================] - 1s 117ms/step - loss: 49.9170 - accuracy: 0.4970 - val_loss: 212.3524 - val_accuracy: 0.7368\n","Epoch 13/50\n","6/6 [==============================] - 1s 137ms/step - loss: 46.1765 - accuracy: 0.4911 - val_loss: 214.9001 - val_accuracy: 0.7368\n","Epoch 14/50\n","6/6 [==============================] - 1s 83ms/step - loss: 42.9421 - accuracy: 0.5089 - val_loss: 212.1830 - val_accuracy: 0.7895\n","Epoch 15/50\n","6/6 [==============================] - 1s 87ms/step - loss: 39.8712 - accuracy: 0.5858 - val_loss: 210.3649 - val_accuracy: 0.7368\n","Epoch 16/50\n","6/6 [==============================] - 0s 83ms/step - loss: 37.4490 - accuracy: 0.5858 - val_loss: 211.3930 - val_accuracy: 0.7368\n","Epoch 17/50\n","6/6 [==============================] - 1s 93ms/step - loss: 34.7869 - accuracy: 0.5680 - val_loss: 209.9570 - val_accuracy: 0.5789\n","Epoch 18/50\n","6/6 [==============================] - 0s 85ms/step - loss: 33.4138 - accuracy: 0.6036 - val_loss: 208.2968 - val_accuracy: 0.6842\n","Epoch 19/50\n","6/6 [==============================] - 1s 84ms/step - loss: 30.2291 - accuracy: 0.5917 - val_loss: 206.5289 - val_accuracy: 0.6842\n","Epoch 20/50\n","6/6 [==============================] - 0s 77ms/step - loss: 28.4489 - accuracy: 0.6095 - val_loss: 205.9063 - val_accuracy: 0.6842\n","Epoch 21/50\n","6/6 [==============================] - 1s 86ms/step - loss: 25.7248 - accuracy: 0.6627 - val_loss: 206.5700 - val_accuracy: 0.6316\n","Epoch 22/50\n","6/6 [==============================] - 0s 77ms/step - loss: 24.6621 - accuracy: 0.6154 - val_loss: 204.6254 - val_accuracy: 0.6316\n","Epoch 23/50\n","6/6 [==============================] - 0s 81ms/step - loss: 22.5210 - accuracy: 0.6391 - val_loss: 202.3446 - val_accuracy: 0.6842\n","Epoch 24/50\n","6/6 [==============================] - 1s 81ms/step - loss: 21.8778 - accuracy: 0.6450 - val_loss: 202.9348 - val_accuracy: 0.6316\n","Epoch 25/50\n","6/6 [==============================] - 0s 78ms/step - loss: 20.5549 - accuracy: 0.5976 - val_loss: 207.5588 - val_accuracy: 0.5789\n","Epoch 26/50\n","6/6 [==============================] - 1s 83ms/step - loss: 19.9501 - accuracy: 0.6686 - val_loss: 205.6416 - val_accuracy: 0.6316\n","Epoch 27/50\n","6/6 [==============================] - 0s 78ms/step - loss: 17.8155 - accuracy: 0.6509 - val_loss: 203.1899 - val_accuracy: 0.6316\n","Epoch 28/50\n","6/6 [==============================] - 0s 82ms/step - loss: 17.9445 - accuracy: 0.6627 - val_loss: 205.4309 - val_accuracy: 0.6316\n","Epoch 29/50\n","6/6 [==============================] - 1s 89ms/step - loss: 15.3951 - accuracy: 0.6272 - val_loss: 201.8825 - val_accuracy: 0.5789\n","Epoch 30/50\n","6/6 [==============================] - 1s 85ms/step - loss: 18.9811 - accuracy: 0.5562 - val_loss: 206.2886 - val_accuracy: 0.5789\n","Epoch 31/50\n","6/6 [==============================] - 1s 85ms/step - loss: 14.1620 - accuracy: 0.6746 - val_loss: 202.0754 - val_accuracy: 0.5789\n","Epoch 32/50\n","6/6 [==============================] - 1s 83ms/step - loss: 14.0011 - accuracy: 0.6627 - val_loss: 199.7285 - val_accuracy: 0.5789\n","Epoch 33/50\n","6/6 [==============================] - 1s 92ms/step - loss: 13.7485 - accuracy: 0.6391 - val_loss: 203.1999 - val_accuracy: 0.5263\n","Epoch 34/50\n","6/6 [==============================] - 1s 120ms/step - loss: 14.3428 - accuracy: 0.7041 - val_loss: 197.2679 - val_accuracy: 0.5789\n","Epoch 35/50\n","6/6 [==============================] - 1s 121ms/step - loss: 29.5269 - accuracy: 0.5680 - val_loss: 194.5428 - val_accuracy: 0.5263\n","Epoch 36/50\n","6/6 [==============================] - 1s 123ms/step - loss: 19.5844 - accuracy: 0.7160 - val_loss: 202.9461 - val_accuracy: 0.5263\n","Epoch 37/50\n","6/6 [==============================] - 1s 130ms/step - loss: 22.3367 - accuracy: 0.6864 - val_loss: 200.8260 - val_accuracy: 0.5789\n","Epoch 38/50\n","6/6 [==============================] - 1s 126ms/step - loss: 14.0694 - accuracy: 0.5858 - val_loss: 198.1293 - val_accuracy: 0.5263\n","Epoch 39/50\n","6/6 [==============================] - 1s 131ms/step - loss: 15.1276 - accuracy: 0.6686 - val_loss: 191.7069 - val_accuracy: 0.5789\n","Epoch 40/50\n","6/6 [==============================] - 1s 111ms/step - loss: 19.7563 - accuracy: 0.5740 - val_loss: 198.3423 - val_accuracy: 0.5263\n","Epoch 41/50\n","6/6 [==============================] - 1s 89ms/step - loss: 12.8462 - accuracy: 0.6627 - val_loss: 197.1079 - val_accuracy: 0.5789\n","Epoch 42/50\n","6/6 [==============================] - 0s 84ms/step - loss: 23.8737 - accuracy: 0.6982 - val_loss: 195.4952 - val_accuracy: 0.5263\n","Epoch 43/50\n","6/6 [==============================] - 1s 94ms/step - loss: 13.6043 - accuracy: 0.6982 - val_loss: 207.5700 - val_accuracy: 0.4737\n","Epoch 44/50\n","6/6 [==============================] - 1s 86ms/step - loss: 24.4059 - accuracy: 0.6213 - val_loss: 208.2881 - val_accuracy: 0.5789\n","Epoch 45/50\n","6/6 [==============================] - 1s 90ms/step - loss: 19.3221 - accuracy: 0.7811 - val_loss: 208.3781 - val_accuracy: 0.5789\n","Epoch 46/50\n","6/6 [==============================] - 0s 80ms/step - loss: 28.8888 - accuracy: 0.6154 - val_loss: 207.2419 - val_accuracy: 0.5789\n","Epoch 47/50\n","6/6 [==============================] - 0s 77ms/step - loss: 16.0521 - accuracy: 0.7101 - val_loss: 201.0992 - val_accuracy: 0.5789\n","Epoch 48/50\n","6/6 [==============================] - 1s 83ms/step - loss: 18.1114 - accuracy: 0.7041 - val_loss: 207.0154 - val_accuracy: 0.5789\n","Epoch 49/50\n","6/6 [==============================] - 0s 81ms/step - loss: 14.2886 - accuracy: 0.6923 - val_loss: 209.0863 - val_accuracy: 0.5789\n","Epoch 50/50\n","6/6 [==============================] - 0s 81ms/step - loss: 14.1471 - accuracy: 0.7219 - val_loss: 208.6393 - val_accuracy: 0.5789\n","2/2 [==============================] - 0s 19ms/step\n","2/2 [==============================] - 0s 18ms/step - loss: 75.4315 - accuracy: 0.9167\n","Test Loss: 75.4315, Test accuracy : 0.9167\n","Epoch 1/50\n","9/9 [==============================] - 1s 99ms/step - loss: 527.9508 - accuracy: 0.2852 - val_loss: 479.1486 - val_accuracy: 0.0938\n","Epoch 2/50\n","9/9 [==============================] - 1s 79ms/step - loss: 218.9719 - accuracy: 0.4754 - val_loss: 437.0344 - val_accuracy: 0.0938\n","Epoch 3/50\n","9/9 [==============================] - 1s 75ms/step - loss: 136.9576 - accuracy: 0.6197 - val_loss: 430.0373 - val_accuracy: 0.1562\n","Epoch 4/50\n","9/9 [==============================] - 1s 85ms/step - loss: 104.8325 - accuracy: 0.6373 - val_loss: 431.6490 - val_accuracy: 0.1875\n","Epoch 5/50\n","9/9 [==============================] - 1s 106ms/step - loss: 86.9898 - accuracy: 0.7289 - val_loss: 414.2249 - val_accuracy: 0.3438\n","Epoch 6/50\n","9/9 [==============================] - 1s 113ms/step - loss: 72.6292 - accuracy: 0.8768 - val_loss: 408.6941 - val_accuracy: 0.5312\n","Epoch 7/50\n","9/9 [==============================] - 1s 105ms/step - loss: 62.0434 - accuracy: 0.9049 - val_loss: 404.5201 - val_accuracy: 0.7188\n","Epoch 8/50\n","9/9 [==============================] - 1s 101ms/step - loss: 53.5602 - accuracy: 0.9190 - val_loss: 405.2173 - val_accuracy: 0.6562\n","Epoch 9/50\n","9/9 [==============================] - 1s 117ms/step - loss: 46.8998 - accuracy: 0.9366 - val_loss: 405.2713 - val_accuracy: 0.6562\n","Epoch 10/50\n","9/9 [==============================] - 1s 92ms/step - loss: 52.4179 - accuracy: 0.9437 - val_loss: 400.5496 - val_accuracy: 0.7500\n","Epoch 11/50\n","9/9 [==============================] - 1s 78ms/step - loss: 48.6922 - accuracy: 0.9437 - val_loss: 392.4124 - val_accuracy: 0.7500\n","Epoch 12/50\n","9/9 [==============================] - 1s 75ms/step - loss: 32.8831 - accuracy: 0.9366 - val_loss: 392.8251 - val_accuracy: 0.7812\n","Epoch 13/50\n","9/9 [==============================] - 1s 77ms/step - loss: 30.5887 - accuracy: 0.9401 - val_loss: 388.5063 - val_accuracy: 0.7500\n","Epoch 14/50\n","9/9 [==============================] - 1s 77ms/step - loss: 26.6545 - accuracy: 0.9261 - val_loss: 386.8984 - val_accuracy: 0.8125\n","Epoch 15/50\n","9/9 [==============================] - 1s 85ms/step - loss: 23.6572 - accuracy: 0.9401 - val_loss: 386.0146 - val_accuracy: 0.8125\n","Epoch 16/50\n","9/9 [==============================] - 1s 78ms/step - loss: 20.8323 - accuracy: 0.9366 - val_loss: 384.4287 - val_accuracy: 0.8125\n","Epoch 17/50\n","9/9 [==============================] - 1s 74ms/step - loss: 19.1278 - accuracy: 0.9472 - val_loss: 383.5919 - val_accuracy: 0.7812\n","Epoch 18/50\n","9/9 [==============================] - 1s 78ms/step - loss: 18.1661 - accuracy: 0.9401 - val_loss: 382.6154 - val_accuracy: 0.8125\n","Epoch 19/50\n","9/9 [==============================] - 1s 78ms/step - loss: 17.4236 - accuracy: 0.9472 - val_loss: 381.5244 - val_accuracy: 0.8125\n","Epoch 20/50\n","9/9 [==============================] - 1s 83ms/step - loss: 16.9160 - accuracy: 0.9401 - val_loss: 380.8979 - val_accuracy: 0.8125\n","Epoch 21/50\n","9/9 [==============================] - 1s 78ms/step - loss: 16.7668 - accuracy: 0.9366 - val_loss: 385.8182 - val_accuracy: 0.7812\n","Epoch 22/50\n","9/9 [==============================] - 1s 77ms/step - loss: 16.3780 - accuracy: 0.9437 - val_loss: 380.0246 - val_accuracy: 0.8125\n","Epoch 23/50\n","9/9 [==============================] - 1s 77ms/step - loss: 15.8844 - accuracy: 0.9472 - val_loss: 384.3269 - val_accuracy: 0.8125\n","Epoch 24/50\n","9/9 [==============================] - 1s 97ms/step - loss: 16.2231 - accuracy: 0.9225 - val_loss: 385.9535 - val_accuracy: 0.8125\n","Epoch 25/50\n","9/9 [==============================] - 1s 101ms/step - loss: 14.8321 - accuracy: 0.9472 - val_loss: 376.0492 - val_accuracy: 0.8125\n","Epoch 26/50\n","9/9 [==============================] - 1s 106ms/step - loss: 18.7180 - accuracy: 0.9401 - val_loss: 377.3136 - val_accuracy: 0.8125\n","Epoch 27/50\n","9/9 [==============================] - 1s 97ms/step - loss: 15.6519 - accuracy: 0.9437 - val_loss: 402.4020 - val_accuracy: 0.7812\n","Epoch 28/50\n","9/9 [==============================] - 1s 116ms/step - loss: 39.3652 - accuracy: 0.9472 - val_loss: 392.0882 - val_accuracy: 0.8125\n","Epoch 29/50\n","9/9 [==============================] - 1s 115ms/step - loss: 55.2066 - accuracy: 0.9437 - val_loss: 386.6887 - val_accuracy: 0.8125\n","Epoch 30/50\n","9/9 [==============================] - 1s 88ms/step - loss: 32.5448 - accuracy: 0.9331 - val_loss: 405.0620 - val_accuracy: 0.7812\n","Epoch 31/50\n","9/9 [==============================] - 1s 75ms/step - loss: 31.6585 - accuracy: 0.9437 - val_loss: 398.6822 - val_accuracy: 0.7500\n","Epoch 32/50\n","9/9 [==============================] - 1s 74ms/step - loss: 25.1774 - accuracy: 0.9437 - val_loss: 363.9183 - val_accuracy: 0.8125\n","Epoch 33/50\n","9/9 [==============================] - 1s 77ms/step - loss: 88.9580 - accuracy: 0.9190 - val_loss: 401.7160 - val_accuracy: 0.7812\n","Epoch 34/50\n","9/9 [==============================] - 1s 75ms/step - loss: 37.4583 - accuracy: 0.9331 - val_loss: 416.6689 - val_accuracy: 0.7500\n","Epoch 35/50\n","9/9 [==============================] - 1s 71ms/step - loss: 19.8685 - accuracy: 0.9472 - val_loss: 405.4933 - val_accuracy: 0.8125\n","Epoch 36/50\n","9/9 [==============================] - 1s 74ms/step - loss: 20.6115 - accuracy: 0.9437 - val_loss: 405.2480 - val_accuracy: 0.8125\n","Epoch 37/50\n","9/9 [==============================] - 1s 73ms/step - loss: 13.1039 - accuracy: 0.9507 - val_loss: 401.8583 - val_accuracy: 0.8125\n","Epoch 38/50\n","9/9 [==============================] - 1s 72ms/step - loss: 10.2758 - accuracy: 0.9577 - val_loss: 401.4233 - val_accuracy: 0.7812\n","Epoch 39/50\n","9/9 [==============================] - 1s 73ms/step - loss: 9.8251 - accuracy: 0.9401 - val_loss: 403.5228 - val_accuracy: 0.8125\n","Epoch 40/50\n","9/9 [==============================] - 1s 73ms/step - loss: 11.1962 - accuracy: 0.9648 - val_loss: 402.8336 - val_accuracy: 0.8125\n","Epoch 41/50\n","9/9 [==============================] - 1s 76ms/step - loss: 9.8230 - accuracy: 0.9613 - val_loss: 398.6509 - val_accuracy: 0.8125\n","Epoch 42/50\n","9/9 [==============================] - 1s 76ms/step - loss: 13.8012 - accuracy: 0.9542 - val_loss: 405.8497 - val_accuracy: 0.8125\n","Epoch 43/50\n","9/9 [==============================] - 1s 73ms/step - loss: 11.1614 - accuracy: 0.9613 - val_loss: 405.8683 - val_accuracy: 0.8125\n","Epoch 44/50\n","9/9 [==============================] - 1s 73ms/step - loss: 9.4046 - accuracy: 0.9507 - val_loss: 403.6886 - val_accuracy: 0.8125\n","Epoch 45/50\n","9/9 [==============================] - 1s 98ms/step - loss: 7.7178 - accuracy: 0.9542 - val_loss: 404.7208 - val_accuracy: 0.8125\n","Epoch 46/50\n","9/9 [==============================] - 1s 106ms/step - loss: 5.8627 - accuracy: 0.9648 - val_loss: 405.1459 - val_accuracy: 0.8125\n","Epoch 47/50\n","9/9 [==============================] - 1s 94ms/step - loss: 4.7513 - accuracy: 0.9683 - val_loss: 405.5466 - val_accuracy: 0.8125\n","Epoch 48/50\n","9/9 [==============================] - 1s 96ms/step - loss: 4.6414 - accuracy: 0.9648 - val_loss: 402.9301 - val_accuracy: 0.8125\n","Epoch 49/50\n","9/9 [==============================] - 1s 96ms/step - loss: 3.9791 - accuracy: 0.9648 - val_loss: 404.8307 - val_accuracy: 0.8125\n","Epoch 50/50\n","9/9 [==============================] - 1s 107ms/step - loss: 3.6237 - accuracy: 0.9683 - val_loss: 404.2802 - val_accuracy: 0.8125\n","3/3 [==============================] - 0s 12ms/step\n","3/3 [==============================] - 0s 13ms/step - loss: 5.4629 - accuracy: 1.0000\n","Test Loss: 5.4629, Test accuracy : 1.0000\n","Epoch 1/50\n","14/14 [==============================] - 2s 82ms/step - loss: 192.7365 - accuracy: 0.1519 - val_loss: 85.2739 - val_accuracy: 0.2708\n","Epoch 2/50\n","14/14 [==============================] - 1s 72ms/step - loss: 129.0394 - accuracy: 0.2710 - val_loss: 94.9602 - val_accuracy: 0.2708\n","Epoch 3/50\n","14/14 [==============================] - 1s 94ms/step - loss: 97.5900 - accuracy: 0.3481 - val_loss: 81.8681 - val_accuracy: 0.2708\n","Epoch 4/50\n","14/14 [==============================] - 1s 94ms/step - loss: 78.8555 - accuracy: 0.4019 - val_loss: 81.0888 - val_accuracy: 0.3125\n","Epoch 5/50\n","14/14 [==============================] - 1s 97ms/step - loss: 69.0883 - accuracy: 0.3341 - val_loss: 83.9431 - val_accuracy: 0.2917\n","Epoch 6/50\n","14/14 [==============================] - 1s 102ms/step - loss: 63.8910 - accuracy: 0.3645 - val_loss: 81.9777 - val_accuracy: 0.2292\n","Epoch 7/50\n","14/14 [==============================] - 1s 75ms/step - loss: 54.7485 - accuracy: 0.3762 - val_loss: 82.2533 - val_accuracy: 0.3125\n","Epoch 8/50\n","14/14 [==============================] - 1s 74ms/step - loss: 48.8313 - accuracy: 0.3364 - val_loss: 81.4616 - val_accuracy: 0.2708\n","Epoch 9/50\n","14/14 [==============================] - 1s 71ms/step - loss: 51.2596 - accuracy: 0.3364 - val_loss: 81.9399 - val_accuracy: 0.2500\n","Epoch 10/50\n","14/14 [==============================] - 1s 72ms/step - loss: 39.8615 - accuracy: 0.3411 - val_loss: 82.2243 - val_accuracy: 0.2292\n","Epoch 11/50\n","14/14 [==============================] - 1s 74ms/step - loss: 41.3784 - accuracy: 0.3294 - val_loss: 84.3165 - val_accuracy: 0.2083\n","Epoch 12/50\n","14/14 [==============================] - 1s 71ms/step - loss: 33.4861 - accuracy: 0.3271 - val_loss: 85.0483 - val_accuracy: 0.2292\n","Epoch 13/50\n","14/14 [==============================] - 1s 71ms/step - loss: 34.5759 - accuracy: 0.3551 - val_loss: 82.3611 - val_accuracy: 0.2083\n","Epoch 14/50\n","14/14 [==============================] - 1s 71ms/step - loss: 33.5093 - accuracy: 0.3318 - val_loss: 85.9020 - val_accuracy: 0.2500\n","Epoch 15/50\n","14/14 [==============================] - 1s 71ms/step - loss: 31.2560 - accuracy: 0.3248 - val_loss: 86.4622 - val_accuracy: 0.2083\n","Epoch 16/50\n","14/14 [==============================] - 1s 70ms/step - loss: 33.1919 - accuracy: 0.3271 - val_loss: 87.4856 - val_accuracy: 0.2500\n","Epoch 17/50\n","14/14 [==============================] - 1s 91ms/step - loss: 27.5187 - accuracy: 0.3458 - val_loss: 87.0165 - val_accuracy: 0.2292\n","Epoch 18/50\n","14/14 [==============================] - 1s 96ms/step - loss: 27.4114 - accuracy: 0.3364 - val_loss: 89.7577 - val_accuracy: 0.2083\n","Epoch 19/50\n","14/14 [==============================] - 1s 96ms/step - loss: 25.1552 - accuracy: 0.3458 - val_loss: 89.2112 - val_accuracy: 0.1875\n","Epoch 20/50\n","14/14 [==============================] - 1s 100ms/step - loss: 26.3165 - accuracy: 0.3318 - val_loss: 86.6104 - val_accuracy: 0.2500\n","Epoch 21/50\n","14/14 [==============================] - 1s 75ms/step - loss: 26.9369 - accuracy: 0.3551 - val_loss: 83.1213 - val_accuracy: 0.2292\n","Epoch 22/50\n","14/14 [==============================] - 1s 70ms/step - loss: 20.0297 - accuracy: 0.3458 - val_loss: 86.1928 - val_accuracy: 0.2500\n","Epoch 23/50\n","14/14 [==============================] - 1s 70ms/step - loss: 18.8654 - accuracy: 0.3621 - val_loss: 86.7422 - val_accuracy: 0.2917\n","Epoch 24/50\n","14/14 [==============================] - 1s 75ms/step - loss: 18.5087 - accuracy: 0.3575 - val_loss: 86.8424 - val_accuracy: 0.2500\n","Epoch 25/50\n","14/14 [==============================] - 1s 72ms/step - loss: 18.5234 - accuracy: 0.3481 - val_loss: 86.6131 - val_accuracy: 0.2500\n","Epoch 26/50\n","14/14 [==============================] - 1s 70ms/step - loss: 18.4808 - accuracy: 0.3692 - val_loss: 86.8052 - val_accuracy: 0.2500\n","Epoch 27/50\n","14/14 [==============================] - 1s 72ms/step - loss: 19.5820 - accuracy: 0.3505 - val_loss: 89.4561 - val_accuracy: 0.2708\n","Epoch 28/50\n","14/14 [==============================] - 1s 92ms/step - loss: 20.2995 - accuracy: 0.3598 - val_loss: 86.5708 - val_accuracy: 0.2500\n","Epoch 29/50\n","14/14 [==============================] - 1s 74ms/step - loss: 17.5697 - accuracy: 0.3528 - val_loss: 87.8299 - val_accuracy: 0.2708\n","Epoch 30/50\n","14/14 [==============================] - 1s 78ms/step - loss: 16.9871 - accuracy: 0.3645 - val_loss: 87.7767 - val_accuracy: 0.2708\n","Epoch 31/50\n","14/14 [==============================] - 1s 97ms/step - loss: 21.6177 - accuracy: 0.3435 - val_loss: 87.3130 - val_accuracy: 0.2500\n","Epoch 32/50\n","14/14 [==============================] - 1s 95ms/step - loss: 26.0737 - accuracy: 0.3785 - val_loss: 91.8538 - val_accuracy: 0.2708\n","Epoch 33/50\n","14/14 [==============================] - 1s 96ms/step - loss: 22.6455 - accuracy: 0.3855 - val_loss: 84.9093 - val_accuracy: 0.2500\n","Epoch 34/50\n","14/14 [==============================] - 1s 91ms/step - loss: 26.3155 - accuracy: 0.3808 - val_loss: 94.3249 - val_accuracy: 0.2708\n","Epoch 35/50\n","14/14 [==============================] - 1s 71ms/step - loss: 23.6507 - accuracy: 0.3995 - val_loss: 88.0877 - val_accuracy: 0.3125\n","Epoch 36/50\n","14/14 [==============================] - 1s 73ms/step - loss: 19.2032 - accuracy: 0.3738 - val_loss: 90.6298 - val_accuracy: 0.2917\n","Epoch 37/50\n","14/14 [==============================] - 1s 74ms/step - loss: 16.9281 - accuracy: 0.4206 - val_loss: 87.9465 - val_accuracy: 0.2708\n","Epoch 38/50\n","14/14 [==============================] - 1s 70ms/step - loss: 22.7386 - accuracy: 0.3855 - val_loss: 88.6094 - val_accuracy: 0.2708\n","Epoch 39/50\n","14/14 [==============================] - 1s 71ms/step - loss: 17.6354 - accuracy: 0.3995 - val_loss: 93.7739 - val_accuracy: 0.2500\n","Epoch 40/50\n","14/14 [==============================] - 1s 73ms/step - loss: 14.5951 - accuracy: 0.4019 - val_loss: 85.5880 - val_accuracy: 0.3125\n","Epoch 41/50\n","14/14 [==============================] - 1s 70ms/step - loss: 14.5375 - accuracy: 0.4065 - val_loss: 92.5689 - val_accuracy: 0.2917\n","Epoch 42/50\n","14/14 [==============================] - 1s 71ms/step - loss: 14.4462 - accuracy: 0.3692 - val_loss: 83.0358 - val_accuracy: 0.2708\n","Epoch 43/50\n","14/14 [==============================] - 1s 73ms/step - loss: 13.4097 - accuracy: 0.3575 - val_loss: 89.5316 - val_accuracy: 0.3125\n","Epoch 44/50\n","14/14 [==============================] - 1s 74ms/step - loss: 12.5682 - accuracy: 0.3598 - val_loss: 87.0279 - val_accuracy: 0.2917\n","Epoch 45/50\n","14/14 [==============================] - 1s 94ms/step - loss: 12.9790 - accuracy: 0.3855 - val_loss: 86.7230 - val_accuracy: 0.3125\n","Epoch 46/50\n","14/14 [==============================] - 1s 97ms/step - loss: 11.9842 - accuracy: 0.3668 - val_loss: 87.0480 - val_accuracy: 0.2917\n","Epoch 47/50\n","14/14 [==============================] - 1s 97ms/step - loss: 11.9656 - accuracy: 0.3621 - val_loss: 87.2445 - val_accuracy: 0.2917\n","Epoch 48/50\n","14/14 [==============================] - 1s 100ms/step - loss: 12.2733 - accuracy: 0.3481 - val_loss: 85.0239 - val_accuracy: 0.2917\n","Epoch 49/50\n","14/14 [==============================] - 1s 71ms/step - loss: 13.2752 - accuracy: 0.3645 - val_loss: 91.0599 - val_accuracy: 0.2708\n","Epoch 50/50\n","14/14 [==============================] - 1s 69ms/step - loss: 12.8438 - accuracy: 0.3621 - val_loss: 86.7707 - val_accuracy: 0.3125\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c16576ae8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 12ms/step\n","4/4 [==============================] - 0s 14ms/step - loss: 1.7323 - accuracy: 0.9417\n","Test Loss: 1.7323, Test accuracy : 0.9417\n","Epoch 1/50\n","13/13 [==============================] - 2s 86ms/step - loss: 223.0459 - accuracy: 0.4171 - val_loss: 313.2804 - val_accuracy: 0.3261\n","Epoch 2/50\n","13/13 [==============================] - 1s 73ms/step - loss: 224.1605 - accuracy: 0.4805 - val_loss: 309.5967 - val_accuracy: 0.5217\n","Epoch 3/50\n","13/13 [==============================] - 1s 73ms/step - loss: 127.2689 - accuracy: 0.4878 - val_loss: 294.1713 - val_accuracy: 0.4783\n","Epoch 4/50\n","13/13 [==============================] - 1s 70ms/step - loss: 104.7029 - accuracy: 0.5317 - val_loss: 285.5589 - val_accuracy: 0.5217\n","Epoch 5/50\n","13/13 [==============================] - 1s 80ms/step - loss: 90.0312 - accuracy: 0.5707 - val_loss: 283.5726 - val_accuracy: 0.4565\n","Epoch 6/50\n","13/13 [==============================] - 1s 95ms/step - loss: 83.9182 - accuracy: 0.5585 - val_loss: 284.4626 - val_accuracy: 0.4783\n","Epoch 7/50\n","13/13 [==============================] - 1s 99ms/step - loss: 74.0657 - accuracy: 0.5829 - val_loss: 287.3393 - val_accuracy: 0.4130\n","Epoch 8/50\n","13/13 [==============================] - 1s 98ms/step - loss: 65.7183 - accuracy: 0.6000 - val_loss: 284.2527 - val_accuracy: 0.3696\n","Epoch 9/50\n","13/13 [==============================] - 1s 92ms/step - loss: 60.7965 - accuracy: 0.5951 - val_loss: 287.0161 - val_accuracy: 0.4565\n","Epoch 10/50\n","13/13 [==============================] - 1s 74ms/step - loss: 55.9368 - accuracy: 0.6244 - val_loss: 285.1226 - val_accuracy: 0.4783\n","Epoch 11/50\n","13/13 [==============================] - 1s 71ms/step - loss: 52.3992 - accuracy: 0.6463 - val_loss: 283.4591 - val_accuracy: 0.4783\n","Epoch 12/50\n","13/13 [==============================] - 1s 71ms/step - loss: 50.5880 - accuracy: 0.6049 - val_loss: 287.1636 - val_accuracy: 0.5217\n","Epoch 13/50\n","13/13 [==============================] - 1s 71ms/step - loss: 46.8327 - accuracy: 0.6268 - val_loss: 281.7538 - val_accuracy: 0.5000\n","Epoch 14/50\n","13/13 [==============================] - 1s 75ms/step - loss: 45.0103 - accuracy: 0.6585 - val_loss: 282.4701 - val_accuracy: 0.5000\n","Epoch 15/50\n","13/13 [==============================] - 1s 74ms/step - loss: 42.4569 - accuracy: 0.6537 - val_loss: 282.9396 - val_accuracy: 0.5217\n","Epoch 16/50\n","13/13 [==============================] - 1s 73ms/step - loss: 41.0128 - accuracy: 0.6732 - val_loss: 281.0088 - val_accuracy: 0.5217\n","Epoch 17/50\n","13/13 [==============================] - 1s 74ms/step - loss: 39.8631 - accuracy: 0.6610 - val_loss: 282.3474 - val_accuracy: 0.4783\n","Epoch 18/50\n","13/13 [==============================] - 1s 71ms/step - loss: 38.3941 - accuracy: 0.6610 - val_loss: 282.9782 - val_accuracy: 0.5217\n","Epoch 19/50\n","13/13 [==============================] - 1s 73ms/step - loss: 38.3705 - accuracy: 0.6537 - val_loss: 283.4991 - val_accuracy: 0.5870\n","Epoch 20/50\n","13/13 [==============================] - 1s 91ms/step - loss: 37.3876 - accuracy: 0.6732 - val_loss: 278.4066 - val_accuracy: 0.5435\n","Epoch 21/50\n","13/13 [==============================] - 1s 95ms/step - loss: 36.5486 - accuracy: 0.6366 - val_loss: 289.2464 - val_accuracy: 0.5652\n","Epoch 22/50\n","13/13 [==============================] - 1s 95ms/step - loss: 39.7969 - accuracy: 0.6390 - val_loss: 280.7771 - val_accuracy: 0.5652\n","Epoch 23/50\n","13/13 [==============================] - 1s 103ms/step - loss: 38.6691 - accuracy: 0.6488 - val_loss: 281.6943 - val_accuracy: 0.5870\n","Epoch 24/50\n","13/13 [==============================] - 1s 84ms/step - loss: 35.1274 - accuracy: 0.6439 - val_loss: 283.0749 - val_accuracy: 0.5870\n","Epoch 25/50\n","13/13 [==============================] - 1s 73ms/step - loss: 35.2836 - accuracy: 0.6537 - val_loss: 278.5780 - val_accuracy: 0.5652\n","Epoch 26/50\n","13/13 [==============================] - 1s 73ms/step - loss: 38.7057 - accuracy: 0.6488 - val_loss: 290.2357 - val_accuracy: 0.5652\n","Epoch 27/50\n","13/13 [==============================] - 1s 71ms/step - loss: 31.4456 - accuracy: 0.6512 - val_loss: 279.1157 - val_accuracy: 0.5870\n","Epoch 28/50\n","13/13 [==============================] - 1s 69ms/step - loss: 30.4503 - accuracy: 0.6512 - val_loss: 289.0420 - val_accuracy: 0.5435\n","Epoch 29/50\n","13/13 [==============================] - 1s 74ms/step - loss: 36.2472 - accuracy: 0.6537 - val_loss: 285.9062 - val_accuracy: 0.5652\n","Epoch 30/50\n","13/13 [==============================] - 1s 68ms/step - loss: 34.0230 - accuracy: 0.6585 - val_loss: 290.0412 - val_accuracy: 0.6304\n","Epoch 31/50\n","13/13 [==============================] - 1s 70ms/step - loss: 31.8211 - accuracy: 0.6488 - val_loss: 290.4010 - val_accuracy: 0.5652\n","Epoch 32/50\n","13/13 [==============================] - 1s 69ms/step - loss: 29.8817 - accuracy: 0.6659 - val_loss: 295.4958 - val_accuracy: 0.5870\n","Epoch 33/50\n","13/13 [==============================] - 1s 73ms/step - loss: 30.7472 - accuracy: 0.6317 - val_loss: 293.6608 - val_accuracy: 0.5435\n","Epoch 34/50\n","13/13 [==============================] - 1s 73ms/step - loss: 33.4753 - accuracy: 0.6707 - val_loss: 295.6059 - val_accuracy: 0.5870\n","Epoch 35/50\n","13/13 [==============================] - 1s 94ms/step - loss: 31.7373 - accuracy: 0.6488 - val_loss: 292.9920 - val_accuracy: 0.5000\n","Epoch 36/50\n","13/13 [==============================] - 1s 96ms/step - loss: 30.6764 - accuracy: 0.6634 - val_loss: 296.7852 - val_accuracy: 0.5870\n","Epoch 37/50\n","13/13 [==============================] - 1s 106ms/step - loss: 30.1985 - accuracy: 0.6512 - val_loss: 294.3802 - val_accuracy: 0.5652\n","Epoch 38/50\n","13/13 [==============================] - 1s 94ms/step - loss: 27.5302 - accuracy: 0.6683 - val_loss: 289.4355 - val_accuracy: 0.5870\n","Epoch 39/50\n","13/13 [==============================] - 1s 86ms/step - loss: 23.9841 - accuracy: 0.6707 - val_loss: 298.3786 - val_accuracy: 0.5652\n","Epoch 40/50\n","13/13 [==============================] - 1s 97ms/step - loss: 23.7943 - accuracy: 0.6683 - val_loss: 299.0450 - val_accuracy: 0.4565\n","Epoch 41/50\n","13/13 [==============================] - 1s 99ms/step - loss: 22.8814 - accuracy: 0.6780 - val_loss: 298.3535 - val_accuracy: 0.5870\n","Epoch 42/50\n","13/13 [==============================] - 1s 73ms/step - loss: 21.3817 - accuracy: 0.6683 - val_loss: 295.8977 - val_accuracy: 0.5435\n","Epoch 43/50\n","13/13 [==============================] - 1s 69ms/step - loss: 21.0271 - accuracy: 0.6805 - val_loss: 298.5370 - val_accuracy: 0.5217\n","Epoch 44/50\n","13/13 [==============================] - 1s 71ms/step - loss: 19.6545 - accuracy: 0.6902 - val_loss: 302.9833 - val_accuracy: 0.5217\n","Epoch 45/50\n","13/13 [==============================] - 1s 74ms/step - loss: 28.1972 - accuracy: 0.6732 - val_loss: 289.6871 - val_accuracy: 0.5000\n","Epoch 46/50\n","13/13 [==============================] - 1s 69ms/step - loss: 25.3906 - accuracy: 0.6780 - val_loss: 302.8503 - val_accuracy: 0.4565\n","Epoch 47/50\n","13/13 [==============================] - 1s 71ms/step - loss: 33.8889 - accuracy: 0.7122 - val_loss: 291.7500 - val_accuracy: 0.5652\n","Epoch 48/50\n","13/13 [==============================] - 1s 72ms/step - loss: 29.2466 - accuracy: 0.6707 - val_loss: 305.4065 - val_accuracy: 0.4783\n","Epoch 49/50\n","13/13 [==============================] - 1s 81ms/step - loss: 29.4595 - accuracy: 0.6878 - val_loss: 296.9892 - val_accuracy: 0.5217\n","Epoch 50/50\n","13/13 [==============================] - 1s 91ms/step - loss: 27.1620 - accuracy: 0.6805 - val_loss: 292.6224 - val_accuracy: 0.5435\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c1655c1b490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 43ms/step\n","4/4 [==============================] - 0s 23ms/step - loss: 4.3796 - accuracy: 0.9914\n","Test Loss: 4.3796, Test accuracy : 0.9914\n","Epoch 1/50\n","21/21 [==============================] - 2s 83ms/step - loss: 170.3232 - accuracy: 0.1925 - val_loss: 273.8435 - val_accuracy: 0.1667\n","Epoch 2/50\n","21/21 [==============================] - 2s 72ms/step - loss: 137.5215 - accuracy: 0.2593 - val_loss: 270.3766 - val_accuracy: 0.0833\n","Epoch 3/50\n","21/21 [==============================] - 1s 70ms/step - loss: 106.9128 - accuracy: 0.2780 - val_loss: 264.4376 - val_accuracy: 0.1250\n","Epoch 4/50\n","21/21 [==============================] - 1s 69ms/step - loss: 79.7704 - accuracy: 0.2904 - val_loss: 261.2828 - val_accuracy: 0.2083\n","Epoch 5/50\n","21/21 [==============================] - 2s 79ms/step - loss: 65.6203 - accuracy: 0.2997 - val_loss: 261.8713 - val_accuracy: 0.1806\n","Epoch 6/50\n","21/21 [==============================] - 2s 95ms/step - loss: 65.8690 - accuracy: 0.3090 - val_loss: 262.8732 - val_accuracy: 0.2222\n","Epoch 7/50\n","21/21 [==============================] - 2s 92ms/step - loss: 64.9542 - accuracy: 0.3370 - val_loss: 257.7201 - val_accuracy: 0.1944\n","Epoch 8/50\n","21/21 [==============================] - 2s 75ms/step - loss: 130.7513 - accuracy: 0.3059 - val_loss: 266.0511 - val_accuracy: 0.1389\n","Epoch 9/50\n","21/21 [==============================] - 1s 70ms/step - loss: 74.1097 - accuracy: 0.2438 - val_loss: 261.2553 - val_accuracy: 0.0694\n","Epoch 10/50\n","21/21 [==============================] - 1s 69ms/step - loss: 56.1354 - accuracy: 0.2003 - val_loss: 259.8979 - val_accuracy: 0.1528\n","Epoch 11/50\n","21/21 [==============================] - 1s 68ms/step - loss: 46.8465 - accuracy: 0.2609 - val_loss: 261.8118 - val_accuracy: 0.1111\n","Epoch 12/50\n","21/21 [==============================] - 1s 70ms/step - loss: 40.3819 - accuracy: 0.2748 - val_loss: 259.5584 - val_accuracy: 0.1806\n","Epoch 13/50\n","21/21 [==============================] - 1s 69ms/step - loss: 36.3664 - accuracy: 0.2811 - val_loss: 259.8170 - val_accuracy: 0.2083\n","Epoch 14/50\n","21/21 [==============================] - 1s 69ms/step - loss: 33.8634 - accuracy: 0.2686 - val_loss: 260.0406 - val_accuracy: 0.1944\n","Epoch 15/50\n","21/21 [==============================] - 2s 89ms/step - loss: 31.8743 - accuracy: 0.2422 - val_loss: 262.3995 - val_accuracy: 0.1528\n","Epoch 16/50\n","21/21 [==============================] - 2s 92ms/step - loss: 30.8517 - accuracy: 0.2345 - val_loss: 256.7239 - val_accuracy: 0.2083\n","Epoch 17/50\n","21/21 [==============================] - 2s 95ms/step - loss: 31.1413 - accuracy: 0.2127 - val_loss: 255.2772 - val_accuracy: 0.0972\n","Epoch 18/50\n","21/21 [==============================] - 1s 68ms/step - loss: 29.1720 - accuracy: 0.2205 - val_loss: 258.5983 - val_accuracy: 0.1944\n","Epoch 19/50\n","21/21 [==============================] - 1s 68ms/step - loss: 28.3669 - accuracy: 0.2298 - val_loss: 259.3539 - val_accuracy: 0.1667\n","Epoch 20/50\n","21/21 [==============================] - 1s 69ms/step - loss: 31.7366 - accuracy: 0.1988 - val_loss: 255.5823 - val_accuracy: 0.2083\n","Epoch 21/50\n","21/21 [==============================] - 1s 69ms/step - loss: 24.7751 - accuracy: 0.2127 - val_loss: 258.4156 - val_accuracy: 0.2083\n","Epoch 22/50\n","21/21 [==============================] - 1s 68ms/step - loss: 23.1454 - accuracy: 0.1879 - val_loss: 253.0794 - val_accuracy: 0.2083\n","Epoch 23/50\n","21/21 [==============================] - 1s 69ms/step - loss: 21.8537 - accuracy: 0.1910 - val_loss: 253.6325 - val_accuracy: 0.2083\n","Epoch 24/50\n","21/21 [==============================] - 1s 70ms/step - loss: 22.7819 - accuracy: 0.1708 - val_loss: 259.7494 - val_accuracy: 0.1667\n","Epoch 25/50\n","21/21 [==============================] - 2s 90ms/step - loss: 27.5609 - accuracy: 0.1693 - val_loss: 253.0848 - val_accuracy: 0.2222\n","Epoch 26/50\n","21/21 [==============================] - 2s 91ms/step - loss: 28.6953 - accuracy: 0.1755 - val_loss: 256.1598 - val_accuracy: 0.2083\n","Epoch 27/50\n","21/21 [==============================] - 2s 89ms/step - loss: 34.7441 - accuracy: 0.1739 - val_loss: 255.8566 - val_accuracy: 0.2222\n","Epoch 28/50\n","21/21 [==============================] - 1s 70ms/step - loss: 34.3463 - accuracy: 0.1677 - val_loss: 262.0087 - val_accuracy: 0.1944\n","Epoch 29/50\n","21/21 [==============================] - 1s 69ms/step - loss: 29.9778 - accuracy: 0.1894 - val_loss: 256.0330 - val_accuracy: 0.1944\n","Epoch 30/50\n","21/21 [==============================] - 1s 69ms/step - loss: 25.6821 - accuracy: 0.1832 - val_loss: 259.8572 - val_accuracy: 0.1944\n","Epoch 31/50\n","21/21 [==============================] - 1s 69ms/step - loss: 24.4094 - accuracy: 0.1910 - val_loss: 257.8295 - val_accuracy: 0.1528\n","Epoch 32/50\n","21/21 [==============================] - 1s 67ms/step - loss: 23.8362 - accuracy: 0.2034 - val_loss: 256.7040 - val_accuracy: 0.2222\n","Epoch 33/50\n","21/21 [==============================] - 1s 67ms/step - loss: 21.3389 - accuracy: 0.2220 - val_loss: 258.1807 - val_accuracy: 0.2083\n","Epoch 34/50\n","21/21 [==============================] - 2s 75ms/step - loss: 19.6270 - accuracy: 0.2391 - val_loss: 256.1754 - val_accuracy: 0.2639\n","Epoch 35/50\n","21/21 [==============================] - 2s 90ms/step - loss: 18.3520 - accuracy: 0.2453 - val_loss: 255.4859 - val_accuracy: 0.1944\n","Epoch 36/50\n","21/21 [==============================] - 2s 96ms/step - loss: 17.6428 - accuracy: 0.2252 - val_loss: 257.0689 - val_accuracy: 0.1944\n","Epoch 37/50\n","21/21 [==============================] - 2s 79ms/step - loss: 16.8896 - accuracy: 0.2516 - val_loss: 255.9651 - val_accuracy: 0.1111\n","Epoch 38/50\n","21/21 [==============================] - 1s 70ms/step - loss: 17.0146 - accuracy: 0.2252 - val_loss: 256.2869 - val_accuracy: 0.2361\n","Epoch 39/50\n","21/21 [==============================] - 1s 69ms/step - loss: 16.8488 - accuracy: 0.2081 - val_loss: 257.0987 - val_accuracy: 0.1667\n","Epoch 40/50\n","21/21 [==============================] - 1s 68ms/step - loss: 16.7674 - accuracy: 0.1879 - val_loss: 253.6421 - val_accuracy: 0.2222\n","Epoch 41/50\n","21/21 [==============================] - 1s 70ms/step - loss: 18.1615 - accuracy: 0.1708 - val_loss: 254.8665 - val_accuracy: 0.2083\n","Epoch 42/50\n","21/21 [==============================] - 1s 69ms/step - loss: 19.4651 - accuracy: 0.1724 - val_loss: 253.1002 - val_accuracy: 0.2083\n","Epoch 43/50\n","21/21 [==============================] - 1s 69ms/step - loss: 17.0188 - accuracy: 0.1894 - val_loss: 256.0827 - val_accuracy: 0.2500\n","Epoch 44/50\n","21/21 [==============================] - 2s 85ms/step - loss: 14.9232 - accuracy: 0.1724 - val_loss: 254.6532 - val_accuracy: 0.1944\n","Epoch 45/50\n","21/21 [==============================] - 2s 92ms/step - loss: 13.8344 - accuracy: 0.1615 - val_loss: 254.8223 - val_accuracy: 0.2361\n","Epoch 46/50\n","21/21 [==============================] - 2s 91ms/step - loss: 13.4279 - accuracy: 0.1568 - val_loss: 255.3197 - val_accuracy: 0.2222\n","Epoch 47/50\n","21/21 [==============================] - 2s 74ms/step - loss: 13.2689 - accuracy: 0.1568 - val_loss: 255.0269 - val_accuracy: 0.1389\n","Epoch 48/50\n","21/21 [==============================] - 1s 68ms/step - loss: 16.5435 - accuracy: 0.1739 - val_loss: 257.5793 - val_accuracy: 0.1944\n","Epoch 49/50\n","21/21 [==============================] - 1s 69ms/step - loss: 17.5247 - accuracy: 0.1739 - val_loss: 254.6646 - val_accuracy: 0.2500\n","Epoch 50/50\n","21/21 [==============================] - 1s 68ms/step - loss: 20.8780 - accuracy: 0.1522 - val_loss: 257.0529 - val_accuracy: 0.1944\n","6/6 [==============================] - 0s 13ms/step\n","6/6 [==============================] - 0s 16ms/step - loss: 41.3984 - accuracy: 0.7722\n","Test Loss: 41.3984, Test accuracy : 0.7722\n","Epoch 1/50\n","9/9 [==============================] - 1s 94ms/step - loss: 259.9713 - accuracy: 0.2381 - val_loss: 125.0701 - val_accuracy: 0.5161\n","Epoch 2/50\n","9/9 [==============================] - 1s 74ms/step - loss: 128.0694 - accuracy: 0.4396 - val_loss: 139.7499 - val_accuracy: 0.4839\n","Epoch 3/50\n","9/9 [==============================] - 1s 71ms/step - loss: 85.7112 - accuracy: 0.5092 - val_loss: 116.1528 - val_accuracy: 0.3226\n","Epoch 4/50\n","9/9 [==============================] - 1s 76ms/step - loss: 63.7194 - accuracy: 0.4689 - val_loss: 119.2820 - val_accuracy: 0.3226\n","Epoch 5/50\n","9/9 [==============================] - 1s 72ms/step - loss: 51.5430 - accuracy: 0.4689 - val_loss: 123.2524 - val_accuracy: 0.2903\n","Epoch 6/50\n","9/9 [==============================] - 1s 76ms/step - loss: 41.0611 - accuracy: 0.5531 - val_loss: 117.1038 - val_accuracy: 0.3226\n","Epoch 7/50\n","9/9 [==============================] - 1s 100ms/step - loss: 35.5955 - accuracy: 0.4835 - val_loss: 116.8313 - val_accuracy: 0.2581\n","Epoch 8/50\n","9/9 [==============================] - 1s 97ms/step - loss: 29.8432 - accuracy: 0.5385 - val_loss: 115.0391 - val_accuracy: 0.3226\n","Epoch 9/50\n","9/9 [==============================] - 1s 102ms/step - loss: 25.0357 - accuracy: 0.5458 - val_loss: 116.5510 - val_accuracy: 0.2903\n","Epoch 10/50\n","9/9 [==============================] - 1s 109ms/step - loss: 21.5903 - accuracy: 0.5568 - val_loss: 117.2749 - val_accuracy: 0.2903\n","Epoch 11/50\n","9/9 [==============================] - 1s 104ms/step - loss: 18.9234 - accuracy: 0.5788 - val_loss: 117.2781 - val_accuracy: 0.3226\n","Epoch 12/50\n","9/9 [==============================] - 1s 81ms/step - loss: 16.6976 - accuracy: 0.5897 - val_loss: 117.7115 - val_accuracy: 0.2903\n","Epoch 13/50\n","9/9 [==============================] - 1s 78ms/step - loss: 14.2126 - accuracy: 0.6190 - val_loss: 117.3757 - val_accuracy: 0.2903\n","Epoch 14/50\n","9/9 [==============================] - 1s 73ms/step - loss: 12.4012 - accuracy: 0.6520 - val_loss: 117.8847 - val_accuracy: 0.2903\n","Epoch 15/50\n","9/9 [==============================] - 1s 72ms/step - loss: 10.8905 - accuracy: 0.6557 - val_loss: 119.6657 - val_accuracy: 0.2903\n","Epoch 16/50\n","9/9 [==============================] - 1s 74ms/step - loss: 9.8224 - accuracy: 0.6667 - val_loss: 118.2072 - val_accuracy: 0.2903\n","Epoch 17/50\n","9/9 [==============================] - 1s 72ms/step - loss: 8.7589 - accuracy: 0.6777 - val_loss: 119.3315 - val_accuracy: 0.2903\n","Epoch 18/50\n","9/9 [==============================] - 1s 72ms/step - loss: 7.8702 - accuracy: 0.6337 - val_loss: 116.6825 - val_accuracy: 0.3871\n","Epoch 19/50\n","9/9 [==============================] - 1s 75ms/step - loss: 7.3193 - accuracy: 0.6923 - val_loss: 121.7978 - val_accuracy: 0.2581\n","Epoch 20/50\n","9/9 [==============================] - 1s 69ms/step - loss: 6.7161 - accuracy: 0.7253 - val_loss: 117.7698 - val_accuracy: 0.3548\n","Epoch 21/50\n","9/9 [==============================] - 1s 71ms/step - loss: 6.0762 - accuracy: 0.7179 - val_loss: 120.9146 - val_accuracy: 0.2903\n","Epoch 22/50\n","9/9 [==============================] - 1s 78ms/step - loss: 6.1005 - accuracy: 0.7216 - val_loss: 118.8460 - val_accuracy: 0.2903\n","Epoch 23/50\n","9/9 [==============================] - 1s 72ms/step - loss: 5.7890 - accuracy: 0.6923 - val_loss: 117.6843 - val_accuracy: 0.2903\n","Epoch 24/50\n","9/9 [==============================] - 1s 74ms/step - loss: 5.2072 - accuracy: 0.7766 - val_loss: 121.5037 - val_accuracy: 0.3548\n","Epoch 25/50\n","9/9 [==============================] - 1s 71ms/step - loss: 4.9621 - accuracy: 0.7582 - val_loss: 122.8239 - val_accuracy: 0.3548\n","Epoch 26/50\n","9/9 [==============================] - 1s 72ms/step - loss: 4.8754 - accuracy: 0.7179 - val_loss: 118.6031 - val_accuracy: 0.3548\n","Epoch 27/50\n","9/9 [==============================] - 1s 95ms/step - loss: 4.8899 - accuracy: 0.7912 - val_loss: 123.1593 - val_accuracy: 0.3548\n","Epoch 28/50\n","9/9 [==============================] - 1s 96ms/step - loss: 4.6747 - accuracy: 0.7766 - val_loss: 123.0332 - val_accuracy: 0.3548\n","Epoch 29/50\n","9/9 [==============================] - 1s 98ms/step - loss: 4.7468 - accuracy: 0.7912 - val_loss: 124.2511 - val_accuracy: 0.3871\n","Epoch 30/50\n","9/9 [==============================] - 1s 109ms/step - loss: 4.6653 - accuracy: 0.7912 - val_loss: 118.6195 - val_accuracy: 0.3226\n","Epoch 31/50\n","9/9 [==============================] - 1s 104ms/step - loss: 4.6788 - accuracy: 0.7802 - val_loss: 126.9206 - val_accuracy: 0.3871\n","Epoch 32/50\n","9/9 [==============================] - 1s 102ms/step - loss: 5.7061 - accuracy: 0.7619 - val_loss: 126.7852 - val_accuracy: 0.3226\n","Epoch 33/50\n","9/9 [==============================] - 1s 74ms/step - loss: 6.6978 - accuracy: 0.7509 - val_loss: 117.3460 - val_accuracy: 0.3548\n","Epoch 34/50\n","9/9 [==============================] - 1s 72ms/step - loss: 6.6216 - accuracy: 0.7729 - val_loss: 124.8930 - val_accuracy: 0.3548\n","Epoch 35/50\n","9/9 [==============================] - 1s 73ms/step - loss: 6.3942 - accuracy: 0.7546 - val_loss: 121.5377 - val_accuracy: 0.3548\n","Epoch 36/50\n","9/9 [==============================] - 1s 76ms/step - loss: 6.1601 - accuracy: 0.7949 - val_loss: 129.8240 - val_accuracy: 0.3871\n","Epoch 37/50\n","9/9 [==============================] - 1s 71ms/step - loss: 5.5960 - accuracy: 0.7802 - val_loss: 123.2720 - val_accuracy: 0.3226\n","Epoch 38/50\n","9/9 [==============================] - 1s 71ms/step - loss: 4.9389 - accuracy: 0.8205 - val_loss: 120.1510 - val_accuracy: 0.3548\n","Epoch 39/50\n","9/9 [==============================] - 1s 71ms/step - loss: 5.0423 - accuracy: 0.7839 - val_loss: 122.9128 - val_accuracy: 0.3226\n","Epoch 40/50\n","9/9 [==============================] - 1s 73ms/step - loss: 5.0146 - accuracy: 0.8095 - val_loss: 122.5430 - val_accuracy: 0.3548\n","Epoch 41/50\n","9/9 [==============================] - 1s 75ms/step - loss: 5.4477 - accuracy: 0.7729 - val_loss: 124.7828 - val_accuracy: 0.3871\n","Epoch 42/50\n","9/9 [==============================] - 1s 70ms/step - loss: 5.0809 - accuracy: 0.7875 - val_loss: 130.3288 - val_accuracy: 0.3226\n","Epoch 43/50\n","9/9 [==============================] - 1s 76ms/step - loss: 6.7003 - accuracy: 0.7912 - val_loss: 120.9435 - val_accuracy: 0.3548\n","Epoch 44/50\n","9/9 [==============================] - 1s 74ms/step - loss: 7.5567 - accuracy: 0.7839 - val_loss: 119.4933 - val_accuracy: 0.3226\n","Epoch 45/50\n","9/9 [==============================] - 1s 72ms/step - loss: 8.7223 - accuracy: 0.7692 - val_loss: 120.0916 - val_accuracy: 0.4194\n","Epoch 46/50\n","9/9 [==============================] - 1s 75ms/step - loss: 9.4996 - accuracy: 0.8168 - val_loss: 122.4430 - val_accuracy: 0.3548\n","Epoch 47/50\n","9/9 [==============================] - 1s 73ms/step - loss: 9.9058 - accuracy: 0.7619 - val_loss: 126.9139 - val_accuracy: 0.3871\n","Epoch 48/50\n","9/9 [==============================] - 1s 90ms/step - loss: 8.1965 - accuracy: 0.7802 - val_loss: 129.0335 - val_accuracy: 0.2581\n","Epoch 49/50\n","9/9 [==============================] - 1s 98ms/step - loss: 8.6599 - accuracy: 0.7839 - val_loss: 121.4543 - val_accuracy: 0.3871\n","Epoch 50/50\n","9/9 [==============================] - 1s 102ms/step - loss: 8.1635 - accuracy: 0.7949 - val_loss: 128.2264 - val_accuracy: 0.3871\n","3/3 [==============================] - 0s 12ms/step\n","3/3 [==============================] - 0s 13ms/step - loss: 1476.4644 - accuracy: 0.9625\n","Test Loss: 1476.4644, Test accuracy : 0.9625\n","Epoch 1/50\n","6/6 [==============================] - 1s 82ms/step - loss: 207.5969 - accuracy: 0.4225 - val_loss: 179.9968 - val_accuracy: 0.7619\n","Epoch 2/50\n","6/6 [==============================] - 0s 57ms/step - loss: 89.1975 - accuracy: 0.4973 - val_loss: 172.1167 - val_accuracy: 0.2857\n","Epoch 3/50\n","6/6 [==============================] - 0s 59ms/step - loss: 49.4089 - accuracy: 0.4706 - val_loss: 150.2980 - val_accuracy: 0.7143\n","Epoch 4/50\n","6/6 [==============================] - 0s 54ms/step - loss: 34.0469 - accuracy: 0.6203 - val_loss: 143.1230 - val_accuracy: 0.7143\n","Epoch 5/50\n","6/6 [==============================] - 0s 67ms/step - loss: 24.3855 - accuracy: 0.4118 - val_loss: 133.0637 - val_accuracy: 0.7619\n","Epoch 6/50\n","6/6 [==============================] - 0s 54ms/step - loss: 18.3589 - accuracy: 0.4813 - val_loss: 138.8216 - val_accuracy: 0.7619\n","Epoch 7/50\n","6/6 [==============================] - 0s 54ms/step - loss: 12.7925 - accuracy: 0.4492 - val_loss: 138.2854 - val_accuracy: 0.6667\n","Epoch 8/50\n","6/6 [==============================] - 0s 51ms/step - loss: 9.8640 - accuracy: 0.5989 - val_loss: 137.4775 - val_accuracy: 0.7619\n","Epoch 9/50\n","6/6 [==============================] - 0s 61ms/step - loss: 7.4651 - accuracy: 0.4813 - val_loss: 138.4549 - val_accuracy: 0.7619\n","Epoch 10/50\n","6/6 [==============================] - 0s 55ms/step - loss: 5.9664 - accuracy: 0.6578 - val_loss: 136.7140 - val_accuracy: 0.7143\n","Epoch 11/50\n","6/6 [==============================] - 0s 56ms/step - loss: 4.6752 - accuracy: 0.6471 - val_loss: 139.5702 - val_accuracy: 0.7619\n","Epoch 12/50\n","6/6 [==============================] - 0s 54ms/step - loss: 4.0599 - accuracy: 0.7754 - val_loss: 139.0727 - val_accuracy: 0.7143\n","Epoch 13/50\n","6/6 [==============================] - 0s 54ms/step - loss: 3.4791 - accuracy: 0.6578 - val_loss: 139.4584 - val_accuracy: 0.7619\n","Epoch 14/50\n","6/6 [==============================] - 0s 54ms/step - loss: 3.0418 - accuracy: 0.8075 - val_loss: 139.4512 - val_accuracy: 0.7143\n","Epoch 15/50\n","6/6 [==============================] - 0s 58ms/step - loss: 2.7397 - accuracy: 0.8342 - val_loss: 139.2148 - val_accuracy: 0.7143\n","Epoch 16/50\n","6/6 [==============================] - 0s 53ms/step - loss: 2.4701 - accuracy: 0.7701 - val_loss: 139.6614 - val_accuracy: 0.7143\n","Epoch 17/50\n","6/6 [==============================] - 0s 55ms/step - loss: 2.2042 - accuracy: 0.8610 - val_loss: 139.8448 - val_accuracy: 0.7143\n","Epoch 18/50\n","6/6 [==============================] - 0s 61ms/step - loss: 2.1659 - accuracy: 0.8235 - val_loss: 140.3564 - val_accuracy: 0.7143\n","Epoch 19/50\n","6/6 [==============================] - 0s 60ms/step - loss: 1.9995 - accuracy: 0.8717 - val_loss: 139.3661 - val_accuracy: 0.7143\n","Epoch 20/50\n","6/6 [==============================] - 0s 56ms/step - loss: 1.8414 - accuracy: 0.8610 - val_loss: 140.1497 - val_accuracy: 0.7143\n","Epoch 21/50\n","6/6 [==============================] - 0s 58ms/step - loss: 1.8142 - accuracy: 0.8930 - val_loss: 139.4900 - val_accuracy: 0.7143\n","Epoch 22/50\n","6/6 [==============================] - 0s 57ms/step - loss: 1.6420 - accuracy: 0.8877 - val_loss: 140.0773 - val_accuracy: 0.7143\n","Epoch 23/50\n","6/6 [==============================] - 0s 55ms/step - loss: 1.5090 - accuracy: 0.9037 - val_loss: 138.8619 - val_accuracy: 0.7143\n","Epoch 24/50\n","6/6 [==============================] - 0s 81ms/step - loss: 1.3971 - accuracy: 0.9037 - val_loss: 139.9476 - val_accuracy: 0.7143\n","Epoch 25/50\n","6/6 [==============================] - 0s 81ms/step - loss: 2.0716 - accuracy: 0.9144 - val_loss: 138.7062 - val_accuracy: 0.7143\n","Epoch 26/50\n","6/6 [==============================] - 0s 80ms/step - loss: 1.4599 - accuracy: 0.8824 - val_loss: 140.5709 - val_accuracy: 0.7143\n","Epoch 27/50\n","6/6 [==============================] - 1s 83ms/step - loss: 3.3575 - accuracy: 0.8877 - val_loss: 139.5010 - val_accuracy: 0.7143\n","Epoch 28/50\n","6/6 [==============================] - 0s 74ms/step - loss: 1.8054 - accuracy: 0.8235 - val_loss: 138.3321 - val_accuracy: 0.7619\n","Epoch 29/50\n","6/6 [==============================] - 0s 73ms/step - loss: 2.1697 - accuracy: 0.8824 - val_loss: 140.4009 - val_accuracy: 0.7143\n","Epoch 30/50\n","6/6 [==============================] - 0s 86ms/step - loss: 1.6705 - accuracy: 0.8930 - val_loss: 139.6419 - val_accuracy: 0.7143\n","Epoch 31/50\n","6/6 [==============================] - 0s 77ms/step - loss: 1.8083 - accuracy: 0.9037 - val_loss: 138.9529 - val_accuracy: 0.7143\n","Epoch 32/50\n","6/6 [==============================] - 0s 75ms/step - loss: 1.7449 - accuracy: 0.9144 - val_loss: 138.6779 - val_accuracy: 0.7143\n","Epoch 33/50\n","6/6 [==============================] - 1s 95ms/step - loss: 4.4284 - accuracy: 0.7968 - val_loss: 138.5212 - val_accuracy: 0.7619\n","Epoch 34/50\n","6/6 [==============================] - 0s 77ms/step - loss: 2.1698 - accuracy: 0.8128 - val_loss: 140.9553 - val_accuracy: 0.7143\n","Epoch 35/50\n","6/6 [==============================] - 0s 59ms/step - loss: 4.7124 - accuracy: 0.8396 - val_loss: 140.8391 - val_accuracy: 0.7143\n","Epoch 36/50\n","6/6 [==============================] - 0s 52ms/step - loss: 4.2777 - accuracy: 0.8289 - val_loss: 137.3867 - val_accuracy: 0.7619\n","Epoch 37/50\n","6/6 [==============================] - 0s 56ms/step - loss: 3.7742 - accuracy: 0.7701 - val_loss: 137.3573 - val_accuracy: 0.7619\n","Epoch 38/50\n","6/6 [==============================] - 0s 60ms/step - loss: 3.8445 - accuracy: 0.7754 - val_loss: 142.5469 - val_accuracy: 0.7143\n","Epoch 39/50\n","6/6 [==============================] - 0s 53ms/step - loss: 4.4622 - accuracy: 0.8396 - val_loss: 140.1944 - val_accuracy: 0.7143\n","Epoch 40/50\n","6/6 [==============================] - 0s 55ms/step - loss: 3.9542 - accuracy: 0.7112 - val_loss: 138.9818 - val_accuracy: 0.7619\n","Epoch 41/50\n","6/6 [==============================] - 0s 62ms/step - loss: 6.6770 - accuracy: 0.8182 - val_loss: 138.6652 - val_accuracy: 0.7143\n","Epoch 42/50\n","6/6 [==============================] - 0s 54ms/step - loss: 3.6642 - accuracy: 0.7754 - val_loss: 141.5297 - val_accuracy: 0.7143\n","Epoch 43/50\n","6/6 [==============================] - 0s 56ms/step - loss: 3.7273 - accuracy: 0.7540 - val_loss: 140.3276 - val_accuracy: 0.7619\n","Epoch 44/50\n","6/6 [==============================] - 0s 62ms/step - loss: 2.5051 - accuracy: 0.8128 - val_loss: 140.0660 - val_accuracy: 0.7143\n","Epoch 45/50\n","6/6 [==============================] - 0s 56ms/step - loss: 2.5406 - accuracy: 0.8289 - val_loss: 142.3209 - val_accuracy: 0.7143\n","Epoch 46/50\n","6/6 [==============================] - 0s 53ms/step - loss: 2.1454 - accuracy: 0.8235 - val_loss: 142.6874 - val_accuracy: 0.7619\n","Epoch 47/50\n","6/6 [==============================] - 0s 56ms/step - loss: 2.0237 - accuracy: 0.8877 - val_loss: 142.1952 - val_accuracy: 0.6190\n","Epoch 48/50\n","6/6 [==============================] - 0s 56ms/step - loss: 1.8270 - accuracy: 0.8824 - val_loss: 141.3731 - val_accuracy: 0.7619\n","Epoch 49/50\n","6/6 [==============================] - 0s 53ms/step - loss: 1.7111 - accuracy: 0.8930 - val_loss: 143.1763 - val_accuracy: 0.6190\n","Epoch 50/50\n","6/6 [==============================] - 0s 53ms/step - loss: 1.7014 - accuracy: 0.8984 - val_loss: 142.8529 - val_accuracy: 0.7619\n","2/2 [==============================] - 0s 12ms/step\n","2/2 [==============================] - 0s 16ms/step - loss: 2.3039 - accuracy: 0.9286\n","Test Loss: 2.3039, Test accuracy : 0.9286\n"]}]},{"cell_type":"code","source":["def print_model_summary(loaded_model, tajweed_rule):\n","  print(f'******* Tajweed rule {tajweed_rule} model *******')\n","  loaded_model.summary()\n","  print('\\n')"],"metadata":{"id":"i4FV1w-iDDFU","executionInfo":{"status":"ok","timestamp":1715955263959,"user_tz":-60,"elapsed":17,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for rule in tajweed_rules:\n","    model_filename = f'{rule}_tajweed_rule_model'\n","    model_path = os.path.join(export_dir, model_filename)\n","\n","    # Load the saved model\n","    loaded_model = tf.keras.models.load_model(model_path)\n","\n","    print_model_summary(loaded_model, rule)"],"metadata":{"id":"WbRKnuWnLZTc","executionInfo":{"status":"ok","timestamp":1715955268967,"user_tz":-60,"elapsed":5018,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc4ae582-c965-492c-b0ab-c914b5d72df4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["******* Tajweed rule madd_6_Lazim model *******\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 2004, 13)]        0         \n","                                                                 \n"," flatten (Flatten)           (None, 26052)             0         \n","                                                                 \n"," dense (Dense)               (None, 64)                1667392   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 1667522 (6.36 MB)\n","Trainable params: 1667522 (6.36 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_246 model *******\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 3216, 13)]        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 41808)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                2675776   \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 2675971 (10.21 MB)\n","Trainable params: 2675971 (10.21 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_6 model *******\n","Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_5 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule madd_2 model *******\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_7 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 5214533 (19.89 MB)\n","Trainable params: 5214533 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Ikhfaa model *******\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                5214208   \n","                                                                 \n"," dense_9 (Dense)             (None, 9)                 585       \n","                                                                 \n","=================================================================\n","Total params: 5214793 (19.89 MB)\n","Trainable params: 5214793 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule Idgham model *******\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_11 (Dense)            (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 5215053 (19.89 MB)\n","Trainable params: 5215053 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule tafkhim model *******\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_12 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_13 (Dense)            (None, 24)                1560      \n","                                                                 \n","=================================================================\n","Total params: 5215768 (19.90 MB)\n","Trainable params: 5215768 (19.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule qalqala model *******\n","Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 6267, 13)]        0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 81471)             0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                5214208   \n","                                                                 \n"," dense_15 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 5214598 (19.89 MB)\n","Trainable params: 5214598 (19.89 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n","******* Tajweed rule imala model *******\n","Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 4502, 13)]        0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 58526)             0         \n","                                                                 \n"," dense_16 (Dense)            (None, 64)                3745728   \n","                                                                 \n"," dense_17 (Dense)            (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 3746183 (14.29 MB)\n","Trainable params: 3746183 (14.29 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","\n","\n"]}]},{"cell_type":"code","source":["# how data is splitted\n","columns1 = ['tajweed_rule', 'data_of', 'X_train_nb_samples', 'X_test_nb_samples', 'Y_train_nb_samples', 'X_test_nb_samples']\n","splitted_data_info = pd.DataFrame(data=splitted_data_info_np, columns=columns1)\n","\n","# save models information\n","columns2 = ['Model', 'Loss', 'Accuracy', 'Accuracy %', 'Path_to_the_model']\n","models_information = pd.DataFrame(data=models_information_np, columns=columns2)"],"metadata":{"id":"txrZx0e_4Zmw","executionInfo":{"status":"ok","timestamp":1715955268970,"user_tz":-60,"elapsed":80,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["splitted_data_info"],"metadata":{"id":"8D4mYXj0Rcqb","executionInfo":{"status":"ok","timestamp":1715955268980,"user_tz":-60,"elapsed":87,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7f6b8aa2-b54b-40f8-e337-5325b6d70551"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    tajweed_rule            data_of X_train_nb_samples X_test_nb_samples  \\\n","0   madd_6_Lazim        Abdul Basit                  1                 1   \n","1   madd_6_Lazim  Yassin Al Jazaery                  1                 1   \n","2   madd_6_Lazim   Ibrahim_Aldosary                  1                 1   \n","3   madd_6_Lazim               safa                  1                 1   \n","4   madd_6_Lazim       all reciters                  4                 4   \n","5       madd_246        Abdul Basit                 62                16   \n","6       madd_246  Yassin Al Jazaery                 62                16   \n","7       madd_246   Ibrahim_Aldosary                 62                16   \n","8       madd_246               safa                 62                16   \n","9       madd_246       all reciters                248                64   \n","10        madd_6        Abdul Basit                 47                12   \n","11        madd_6  Yassin Al Jazaery                 47                12   \n","12        madd_6   Ibrahim_Aldosary                 47                12   \n","13        madd_6               safa                 47                12   \n","14        madd_6       all reciters                188                48   \n","15        madd_2        Abdul Basit                 79                20   \n","16        madd_2  Yassin Al Jazaery                 79                20   \n","17        madd_2   Ibrahim_Aldosary                 79                20   \n","18        madd_2               safa                 79                20   \n","19        madd_2       all reciters                316                80   \n","20        Ikhfaa        Abdul Basit                119                30   \n","21        Ikhfaa  Yassin Al Jazaery                119                30   \n","22        Ikhfaa   Ibrahim_Aldosary                119                30   \n","23        Ikhfaa               safa                119                30   \n","24        Ikhfaa       all reciters                476               120   \n","25        Idgham        Abdul Basit                114                29   \n","26        Idgham  Yassin Al Jazaery                114                29   \n","27        Idgham   Ibrahim_Aldosary                114                29   \n","28        Idgham               safa                114                29   \n","29        Idgham       all reciters                456               116   \n","30       tafkhim        Abdul Basit                179                45   \n","31       tafkhim  Yassin Al Jazaery                179                45   \n","32       tafkhim   Ibrahim_Aldosary                179                45   \n","33       tafkhim               safa                179                45   \n","34       tafkhim       all reciters                716               180   \n","35       qalqala        Abdul Basit                 76                20   \n","36       qalqala  Yassin Al Jazaery                 76                20   \n","37       qalqala   Ibrahim_Aldosary                 76                20   \n","38       qalqala               safa                 76                20   \n","39       qalqala       all reciters                304                80   \n","40         imala        Abdul Basit                 52                14   \n","41         imala  Yassin Al Jazaery                 52                14   \n","42         imala   Ibrahim_Aldosary                 52                14   \n","43         imala               safa                 52                14   \n","44         imala       all reciters                208                56   \n","\n","   Y_train_nb_samples X_test_nb_samples  \n","0                   1                 1  \n","1                   1                 1  \n","2                   1                 1  \n","3                   1                 1  \n","4                   4                 4  \n","5                  62                16  \n","6                  62                16  \n","7                  62                16  \n","8                  62                16  \n","9                 248                64  \n","10                 47                12  \n","11                 47                12  \n","12                 47                12  \n","13                 47                12  \n","14                188                48  \n","15                 79                20  \n","16                 79                20  \n","17                 79                20  \n","18                 79                20  \n","19                316                80  \n","20                119                30  \n","21                119                30  \n","22                119                30  \n","23                119                30  \n","24                476               120  \n","25                114                29  \n","26                114                29  \n","27                114                29  \n","28                114                29  \n","29                456               116  \n","30                179                45  \n","31                179                45  \n","32                179                45  \n","33                179                45  \n","34                716               180  \n","35                 76                20  \n","36                 76                20  \n","37                 76                20  \n","38                 76                20  \n","39                304                80  \n","40                 52                14  \n","41                 52                14  \n","42                 52                14  \n","43                 52                14  \n","44                208                56  "],"text/html":["\n","  <div id=\"df-ff144cfb-5a43-4e1a-bb01-ce3858f31d0d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tajweed_rule</th>\n","      <th>data_of</th>\n","      <th>X_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","      <th>Y_train_nb_samples</th>\n","      <th>X_test_nb_samples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Abdul Basit</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_Lazim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_6_Lazim</td>\n","      <td>safa</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>madd_6_Lazim</td>\n","      <td>all reciters</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>madd_246</td>\n","      <td>Abdul Basit</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>madd_246</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>madd_246</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>madd_246</td>\n","      <td>safa</td>\n","      <td>62</td>\n","      <td>16</td>\n","      <td>62</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>madd_246</td>\n","      <td>all reciters</td>\n","      <td>248</td>\n","      <td>64</td>\n","      <td>248</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>madd_6</td>\n","      <td>Abdul Basit</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>madd_6</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>madd_6</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>madd_6</td>\n","      <td>safa</td>\n","      <td>47</td>\n","      <td>12</td>\n","      <td>47</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>madd_6</td>\n","      <td>all reciters</td>\n","      <td>188</td>\n","      <td>48</td>\n","      <td>188</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>madd_2</td>\n","      <td>Abdul Basit</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>madd_2</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>madd_2</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>madd_2</td>\n","      <td>safa</td>\n","      <td>79</td>\n","      <td>20</td>\n","      <td>79</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>madd_2</td>\n","      <td>all reciters</td>\n","      <td>316</td>\n","      <td>80</td>\n","      <td>316</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Ikhfaa</td>\n","      <td>Abdul Basit</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Ikhfaa</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Ikhfaa</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Ikhfaa</td>\n","      <td>safa</td>\n","      <td>119</td>\n","      <td>30</td>\n","      <td>119</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Ikhfaa</td>\n","      <td>all reciters</td>\n","      <td>476</td>\n","      <td>120</td>\n","      <td>476</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Idgham</td>\n","      <td>Abdul Basit</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Idgham</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Idgham</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Idgham</td>\n","      <td>safa</td>\n","      <td>114</td>\n","      <td>29</td>\n","      <td>114</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Idgham</td>\n","      <td>all reciters</td>\n","      <td>456</td>\n","      <td>116</td>\n","      <td>456</td>\n","      <td>116</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>tafkhim</td>\n","      <td>Abdul Basit</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>tafkhim</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>tafkhim</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>tafkhim</td>\n","      <td>safa</td>\n","      <td>179</td>\n","      <td>45</td>\n","      <td>179</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>tafkhim</td>\n","      <td>all reciters</td>\n","      <td>716</td>\n","      <td>180</td>\n","      <td>716</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>qalqala</td>\n","      <td>Abdul Basit</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>qalqala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>qalqala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>qalqala</td>\n","      <td>safa</td>\n","      <td>76</td>\n","      <td>20</td>\n","      <td>76</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>qalqala</td>\n","      <td>all reciters</td>\n","      <td>304</td>\n","      <td>80</td>\n","      <td>304</td>\n","      <td>80</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>imala</td>\n","      <td>Abdul Basit</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>imala</td>\n","      <td>Yassin Al Jazaery</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>imala</td>\n","      <td>Ibrahim_Aldosary</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>imala</td>\n","      <td>safa</td>\n","      <td>52</td>\n","      <td>14</td>\n","      <td>52</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>imala</td>\n","      <td>all reciters</td>\n","      <td>208</td>\n","      <td>56</td>\n","      <td>208</td>\n","      <td>56</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff144cfb-5a43-4e1a-bb01-ce3858f31d0d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ff144cfb-5a43-4e1a-bb01-ce3858f31d0d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ff144cfb-5a43-4e1a-bb01-ce3858f31d0d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c576f74b-0013-40ba-8f24-e29a3e7fa02e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c576f74b-0013-40ba-8f24-e29a3e7fa02e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c576f74b-0013-40ba-8f24-e29a3e7fa02e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"splitted_data_info","summary":"{\n  \"name\": \"splitted_data_info\",\n  \"rows\": 45,\n  \"fields\": [\n    {\n      \"column\": \"tajweed_rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala\",\n          \"madd_246\",\n          \"Idgham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_of\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Yassin Al Jazaery\",\n          \"all reciters\",\n          \"Ibrahim_Aldosary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"48\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_train_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X_test_nb_samples\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"48\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["models_information"],"metadata":{"id":"h3kOCPqVuemS","executionInfo":{"status":"ok","timestamp":1715955268982,"user_tz":-60,"elapsed":51,"user":{"displayName":"Safa BENABDESSADOK","userId":"13084690164500108428"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"e847d576-b786-4643-9367-ca715f36b791"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Model       Loss Accuracy Accuracy %  \\\n","0  madd_6_Lazim_tajweed_rule_model     1.2232   1.0000     100.00   \n","1      madd_246_tajweed_rule_model    10.8406   1.0000     100.00   \n","2        madd_6_tajweed_rule_model    75.4315   0.9167      91.67   \n","3        madd_2_tajweed_rule_model     5.4629   1.0000     100.00   \n","4        Ikhfaa_tajweed_rule_model     1.7323   0.9417      94.17   \n","5        Idgham_tajweed_rule_model     4.3796   0.9914      99.14   \n","6       tafkhim_tajweed_rule_model    41.3984   0.7722      77.22   \n","7       qalqala_tajweed_rule_model  1476.4644   0.9625      96.25   \n","8         imala_tajweed_rule_model     2.3039   0.9286      92.86   \n","\n","                                   Path_to_the_model  \n","0  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","1  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","2  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","3  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","4  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","5  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","6  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","7  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  \n","8  /content/drive/My Drive/M2 GL/PFE/AI_models_v5...  "],"text/html":["\n","  <div id=\"df-92e1f37f-899b-423b-9a94-fc205fdf658b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Loss</th>\n","      <th>Accuracy</th>\n","      <th>Accuracy %</th>\n","      <th>Path_to_the_model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>madd_6_Lazim_tajweed_rule_model</td>\n","      <td>1.2232</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>madd_246_tajweed_rule_model</td>\n","      <td>10.8406</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madd_6_tajweed_rule_model</td>\n","      <td>75.4315</td>\n","      <td>0.9167</td>\n","      <td>91.67</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>madd_2_tajweed_rule_model</td>\n","      <td>5.4629</td>\n","      <td>1.0000</td>\n","      <td>100.00</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ikhfaa_tajweed_rule_model</td>\n","      <td>1.7323</td>\n","      <td>0.9417</td>\n","      <td>94.17</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Idgham_tajweed_rule_model</td>\n","      <td>4.3796</td>\n","      <td>0.9914</td>\n","      <td>99.14</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>tafkhim_tajweed_rule_model</td>\n","      <td>41.3984</td>\n","      <td>0.7722</td>\n","      <td>77.22</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>qalqala_tajweed_rule_model</td>\n","      <td>1476.4644</td>\n","      <td>0.9625</td>\n","      <td>96.25</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>imala_tajweed_rule_model</td>\n","      <td>2.3039</td>\n","      <td>0.9286</td>\n","      <td>92.86</td>\n","      <td>/content/drive/My Drive/M2 GL/PFE/AI_models_v5...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92e1f37f-899b-423b-9a94-fc205fdf658b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-92e1f37f-899b-423b-9a94-fc205fdf658b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-92e1f37f-899b-423b-9a94-fc205fdf658b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-159bfd66-7e70-48d8-bf13-45cc9d0ecfd3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-159bfd66-7e70-48d8-bf13-45cc9d0ecfd3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-159bfd66-7e70-48d8-bf13-45cc9d0ecfd3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"models_information","summary":"{\n  \"name\": \"models_information\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"qalqala_tajweed_rule_model\",\n          \"madd_246_tajweed_rule_model\",\n          \"Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1476.4644\",\n          \"10.8406\",\n          \"4.3796\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1.0000\",\n          \"0.9167\",\n          \"0.9625\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy %\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"100.00\",\n          \"91.67\",\n          \"96.25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path_to_the_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v5/qalqala_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v5/madd_246_tajweed_rule_model\",\n          \"/content/drive/My Drive/M2 GL/PFE/AI_models_v5/Idgham_tajweed_rule_model\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]}]}